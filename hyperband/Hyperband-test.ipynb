{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/javier.mas/hyperband/hyperband')\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from math import log\n",
    "from sklearn.metrics import log_loss, cohen_kappa_score, confusion_matrix\n",
    "from hyperband.hyperband import Hyperband\n",
    "from hyperband.defs.xgb import get_params, try_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t   Hyperband-test.ipynb  notebooks  Untitled.ipynb\r\n",
      "hyperband  __init__.py\t\t tiago\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/HR_comma_sep.csv')\n",
    "data = pd.get_dummies(data)\n",
    "data_dict = dict()\n",
    "feats = [col for col in data.columns if col != 'left']\n",
    "data_dict['x_train'], data_dict['y_train'] = data.loc[int(len(data)*0.8):, feats], data.loc[int(len(data)*0.8):, 'left']\n",
    "data_dict['x_test'], data_dict['y_test'] = data.loc[:int(len(data)*0.8), feats], data.loc[:int(len(data)*0.8), 'left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales_IT</th>\n",
       "      <th>sales_RandD</th>\n",
       "      <th>sales_accounting</th>\n",
       "      <th>sales_hr</th>\n",
       "      <th>sales_management</th>\n",
       "      <th>sales_marketing</th>\n",
       "      <th>sales_product_mng</th>\n",
       "      <th>sales_sales</th>\n",
       "      <th>sales_support</th>\n",
       "      <th>sales_technical</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>6</td>\n",
       "      <td>282</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.95</td>\n",
       "      <td>6</td>\n",
       "      <td>304</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4</td>\n",
       "      <td>239</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11970</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11971</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>5</td>\n",
       "      <td>263</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11980</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11992</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11993</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>253</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11994</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3</td>\n",
       "      <td>259</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>266</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "5                    0.41             0.50               2   \n",
       "6                    0.10             0.77               6   \n",
       "7                    0.92             0.85               5   \n",
       "8                    0.89             1.00               5   \n",
       "9                    0.42             0.53               2   \n",
       "10                   0.45             0.54               2   \n",
       "11                   0.11             0.81               6   \n",
       "12                   0.84             0.92               4   \n",
       "13                   0.41             0.55               2   \n",
       "14                   0.36             0.56               2   \n",
       "15                   0.38             0.54               2   \n",
       "16                   0.45             0.47               2   \n",
       "17                   0.78             0.99               4   \n",
       "18                   0.45             0.51               2   \n",
       "19                   0.76             0.89               5   \n",
       "20                   0.11             0.83               6   \n",
       "21                   0.38             0.55               2   \n",
       "22                   0.09             0.95               6   \n",
       "23                   0.46             0.57               2   \n",
       "24                   0.40             0.53               2   \n",
       "25                   0.89             0.92               5   \n",
       "26                   0.82             0.87               4   \n",
       "27                   0.40             0.49               2   \n",
       "28                   0.41             0.46               2   \n",
       "29                   0.38             0.50               2   \n",
       "...                   ...              ...             ...   \n",
       "11970                0.14             0.38               5   \n",
       "11971                0.85             0.89               4   \n",
       "11972                0.55             0.81               3   \n",
       "11973                0.49             0.71               4   \n",
       "11974                0.82             0.58               5   \n",
       "11975                0.59             0.77               3   \n",
       "11976                0.90             0.82               3   \n",
       "11977                0.62             0.72               3   \n",
       "11978                0.61             0.68               3   \n",
       "11979                0.52             0.55               5   \n",
       "11980                0.79             0.87               4   \n",
       "11981                0.49             0.89               4   \n",
       "11982                0.73             0.67               2   \n",
       "11983                0.67             0.49               5   \n",
       "11984                0.52             0.61               4   \n",
       "11985                0.72             0.64               4   \n",
       "11986                0.48             0.50               5   \n",
       "11987                0.19             0.79               4   \n",
       "11988                0.49             0.49               3   \n",
       "11989                0.90             0.76               3   \n",
       "11990                0.49             0.49               4   \n",
       "11991                0.60             0.53               2   \n",
       "11992                0.62             0.85               3   \n",
       "11993                0.64             0.50               4   \n",
       "11994                0.22             0.94               3   \n",
       "11995                0.90             0.55               3   \n",
       "11996                0.74             0.95               5   \n",
       "11997                0.85             0.54               3   \n",
       "11998                0.33             0.65               3   \n",
       "11999                0.50             0.73               4   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "0                       157                   3              0   \n",
       "1                       262                   6              0   \n",
       "2                       272                   4              0   \n",
       "3                       223                   5              0   \n",
       "4                       159                   3              0   \n",
       "5                       153                   3              0   \n",
       "6                       247                   4              0   \n",
       "7                       259                   5              0   \n",
       "8                       224                   5              0   \n",
       "9                       142                   3              0   \n",
       "10                      135                   3              0   \n",
       "11                      305                   4              0   \n",
       "12                      234                   5              0   \n",
       "13                      148                   3              0   \n",
       "14                      137                   3              0   \n",
       "15                      143                   3              0   \n",
       "16                      160                   3              0   \n",
       "17                      255                   6              0   \n",
       "18                      160                   3              1   \n",
       "19                      262                   5              0   \n",
       "20                      282                   4              0   \n",
       "21                      147                   3              0   \n",
       "22                      304                   4              0   \n",
       "23                      139                   3              0   \n",
       "24                      158                   3              0   \n",
       "25                      242                   5              0   \n",
       "26                      239                   5              0   \n",
       "27                      135                   3              0   \n",
       "28                      128                   3              0   \n",
       "29                      132                   3              0   \n",
       "...                     ...                 ...            ...   \n",
       "11970                   115                   6              1   \n",
       "11971                   150                   3              0   \n",
       "11972                   239                   8              0   \n",
       "11973                   178                   8              0   \n",
       "11974                   263                   8              0   \n",
       "11975                   272                   8              0   \n",
       "11976                   133                   8              0   \n",
       "11977                   149                   3              1   \n",
       "11978                   193                   2              0   \n",
       "11979                   174                   3              1   \n",
       "11980                   223                   5              0   \n",
       "11981                   201                   8              0   \n",
       "11982                   139                   8              0   \n",
       "11983                   241                   8              0   \n",
       "11984                   187                   4              1   \n",
       "11985                   192                   3              0   \n",
       "11986                   142                   4              0   \n",
       "11987                   229                   4              0   \n",
       "11988                   104                   7              0   \n",
       "11989                   255                   7              0   \n",
       "11990                   212                   7              0   \n",
       "11991                   235                   7              0   \n",
       "11992                   237                   3              1   \n",
       "11993                   253                  10              0   \n",
       "11994                   193                  10              0   \n",
       "11995                   259                  10              1   \n",
       "11996                   266                  10              0   \n",
       "11997                   185                  10              0   \n",
       "11998                   172                  10              0   \n",
       "11999                   180                   3              0   \n",
       "\n",
       "       promotion_last_5years  sales_IT  sales_RandD  sales_accounting  \\\n",
       "0                          0         0            0                 0   \n",
       "1                          0         0            0                 0   \n",
       "2                          0         0            0                 0   \n",
       "3                          0         0            0                 0   \n",
       "4                          0         0            0                 0   \n",
       "5                          0         0            0                 0   \n",
       "6                          0         0            0                 0   \n",
       "7                          0         0            0                 0   \n",
       "8                          0         0            0                 0   \n",
       "9                          0         0            0                 0   \n",
       "10                         0         0            0                 0   \n",
       "11                         0         0            0                 0   \n",
       "12                         0         0            0                 0   \n",
       "13                         0         0            0                 0   \n",
       "14                         0         0            0                 0   \n",
       "15                         0         0            0                 0   \n",
       "16                         0         0            0                 0   \n",
       "17                         0         0            0                 0   \n",
       "18                         1         0            0                 0   \n",
       "19                         0         0            0                 0   \n",
       "20                         0         0            0                 0   \n",
       "21                         0         0            0                 0   \n",
       "22                         0         0            0                 0   \n",
       "23                         0         0            0                 0   \n",
       "24                         0         0            0                 0   \n",
       "25                         0         0            0                 0   \n",
       "26                         0         0            0                 0   \n",
       "27                         0         0            0                 0   \n",
       "28                         0         0            0                 1   \n",
       "29                         0         0            0                 1   \n",
       "...                      ...       ...          ...               ...   \n",
       "11970                      0         0            0                 0   \n",
       "11971                      0         0            0                 1   \n",
       "11972                      0         0            0                 1   \n",
       "11973                      0         1            0                 0   \n",
       "11974                      0         1            0                 0   \n",
       "11975                      0         0            0                 0   \n",
       "11976                      0         0            0                 0   \n",
       "11977                      0         0            0                 0   \n",
       "11978                      0         0            0                 0   \n",
       "11979                      0         0            0                 0   \n",
       "11980                      0         0            0                 0   \n",
       "11981                      0         0            0                 0   \n",
       "11982                      0         0            0                 0   \n",
       "11983                      0         0            0                 0   \n",
       "11984                      0         0            0                 0   \n",
       "11985                      0         0            0                 0   \n",
       "11986                      0         1            0                 0   \n",
       "11987                      0         0            0                 0   \n",
       "11988                      0         0            0                 0   \n",
       "11989                      0         0            0                 0   \n",
       "11990                      0         0            0                 0   \n",
       "11991                      0         1            0                 0   \n",
       "11992                      0         1            0                 0   \n",
       "11993                      1         0            0                 0   \n",
       "11994                      1         0            0                 0   \n",
       "11995                      1         0            0                 0   \n",
       "11996                      1         0            0                 0   \n",
       "11997                      1         0            0                 0   \n",
       "11998                      1         0            0                 0   \n",
       "11999                      0         1            0                 0   \n",
       "\n",
       "       sales_hr  sales_management  sales_marketing  sales_product_mng  \\\n",
       "0             0                 0                0                  0   \n",
       "1             0                 0                0                  0   \n",
       "2             0                 0                0                  0   \n",
       "3             0                 0                0                  0   \n",
       "4             0                 0                0                  0   \n",
       "5             0                 0                0                  0   \n",
       "6             0                 0                0                  0   \n",
       "7             0                 0                0                  0   \n",
       "8             0                 0                0                  0   \n",
       "9             0                 0                0                  0   \n",
       "10            0                 0                0                  0   \n",
       "11            0                 0                0                  0   \n",
       "12            0                 0                0                  0   \n",
       "13            0                 0                0                  0   \n",
       "14            0                 0                0                  0   \n",
       "15            0                 0                0                  0   \n",
       "16            0                 0                0                  0   \n",
       "17            0                 0                0                  0   \n",
       "18            0                 0                0                  0   \n",
       "19            0                 0                0                  0   \n",
       "20            0                 0                0                  0   \n",
       "21            0                 0                0                  0   \n",
       "22            0                 0                0                  0   \n",
       "23            0                 0                0                  0   \n",
       "24            0                 0                0                  0   \n",
       "25            0                 0                0                  0   \n",
       "26            0                 0                0                  0   \n",
       "27            0                 0                0                  0   \n",
       "28            0                 0                0                  0   \n",
       "29            0                 0                0                  0   \n",
       "...         ...               ...              ...                ...   \n",
       "11970         0                 0                1                  0   \n",
       "11971         0                 0                0                  0   \n",
       "11972         0                 0                0                  0   \n",
       "11973         0                 0                0                  0   \n",
       "11974         0                 0                0                  0   \n",
       "11975         0                 1                0                  0   \n",
       "11976         0                 0                1                  0   \n",
       "11977         0                 0                1                  0   \n",
       "11978         0                 0                1                  0   \n",
       "11979         0                 0                0                  0   \n",
       "11980         0                 0                0                  0   \n",
       "11981         0                 0                0                  0   \n",
       "11982         0                 0                0                  0   \n",
       "11983         0                 0                0                  0   \n",
       "11984         0                 0                0                  0   \n",
       "11985         0                 0                0                  0   \n",
       "11986         0                 0                0                  0   \n",
       "11987         0                 0                0                  1   \n",
       "11988         0                 0                0                  1   \n",
       "11989         0                 0                0                  1   \n",
       "11990         0                 0                0                  1   \n",
       "11991         0                 0                0                  0   \n",
       "11992         0                 0                0                  0   \n",
       "11993         0                 1                0                  0   \n",
       "11994         0                 1                0                  0   \n",
       "11995         0                 1                0                  0   \n",
       "11996         0                 1                0                  0   \n",
       "11997         0                 1                0                  0   \n",
       "11998         0                 0                1                  0   \n",
       "11999         0                 0                0                  0   \n",
       "\n",
       "       sales_sales  sales_support  sales_technical  salary_high  salary_low  \\\n",
       "0                1              0                0            0           1   \n",
       "1                1              0                0            0           0   \n",
       "2                1              0                0            0           0   \n",
       "3                1              0                0            0           1   \n",
       "4                1              0                0            0           1   \n",
       "5                1              0                0            0           1   \n",
       "6                1              0                0            0           1   \n",
       "7                1              0                0            0           1   \n",
       "8                1              0                0            0           1   \n",
       "9                1              0                0            0           1   \n",
       "10               1              0                0            0           1   \n",
       "11               1              0                0            0           1   \n",
       "12               1              0                0            0           1   \n",
       "13               1              0                0            0           1   \n",
       "14               1              0                0            0           1   \n",
       "15               1              0                0            0           1   \n",
       "16               1              0                0            0           1   \n",
       "17               1              0                0            0           1   \n",
       "18               1              0                0            0           1   \n",
       "19               1              0                0            0           1   \n",
       "20               1              0                0            0           1   \n",
       "21               1              0                0            0           1   \n",
       "22               1              0                0            0           1   \n",
       "23               1              0                0            0           1   \n",
       "24               1              0                0            0           1   \n",
       "25               1              0                0            0           1   \n",
       "26               1              0                0            0           1   \n",
       "27               1              0                0            0           1   \n",
       "28               0              0                0            0           1   \n",
       "29               0              0                0            0           1   \n",
       "...            ...            ...              ...          ...         ...   \n",
       "11970            0              0                0            1           0   \n",
       "11971            0              0                0            1           0   \n",
       "11972            0              0                0            1           0   \n",
       "11973            0              0                0            0           0   \n",
       "11974            0              0                0            0           0   \n",
       "11975            0              0                0            1           0   \n",
       "11976            0              0                0            0           0   \n",
       "11977            0              0                0            0           0   \n",
       "11978            0              0                0            0           0   \n",
       "11979            1              0                0            0           0   \n",
       "11980            1              0                0            0           0   \n",
       "11981            1              0                0            0           0   \n",
       "11982            1              0                0            0           0   \n",
       "11983            1              0                0            0           0   \n",
       "11984            1              0                0            0           0   \n",
       "11985            1              0                0            0           0   \n",
       "11986            0              0                0            0           0   \n",
       "11987            0              0                0            0           0   \n",
       "11988            0              0                0            1           0   \n",
       "11989            0              0                0            0           1   \n",
       "11990            0              0                0            0           0   \n",
       "11991            0              0                0            0           0   \n",
       "11992            0              0                0            0           0   \n",
       "11993            0              0                0            1           0   \n",
       "11994            0              0                0            1           0   \n",
       "11995            0              0                0            1           0   \n",
       "11996            0              0                0            1           0   \n",
       "11997            0              0                0            1           0   \n",
       "11998            0              0                0            1           0   \n",
       "11999            0              0                0            0           1   \n",
       "\n",
       "       salary_medium  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 0  \n",
       "11                 0  \n",
       "12                 0  \n",
       "13                 0  \n",
       "14                 0  \n",
       "15                 0  \n",
       "16                 0  \n",
       "17                 0  \n",
       "18                 0  \n",
       "19                 0  \n",
       "20                 0  \n",
       "21                 0  \n",
       "22                 0  \n",
       "23                 0  \n",
       "24                 0  \n",
       "25                 0  \n",
       "26                 0  \n",
       "27                 0  \n",
       "28                 0  \n",
       "29                 0  \n",
       "...              ...  \n",
       "11970              0  \n",
       "11971              0  \n",
       "11972              0  \n",
       "11973              1  \n",
       "11974              1  \n",
       "11975              0  \n",
       "11976              1  \n",
       "11977              1  \n",
       "11978              1  \n",
       "11979              1  \n",
       "11980              1  \n",
       "11981              1  \n",
       "11982              1  \n",
       "11983              1  \n",
       "11984              1  \n",
       "11985              1  \n",
       "11986              1  \n",
       "11987              1  \n",
       "11988              0  \n",
       "11989              0  \n",
       "11990              1  \n",
       "11991              1  \n",
       "11992              1  \n",
       "11993              0  \n",
       "11994              0  \n",
       "11995              0  \n",
       "11996              0  \n",
       "11997              0  \n",
       "11998              0  \n",
       "11999              0  \n",
       "\n",
       "[12000 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['x_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** 81 configurations x 1.0 iterations each\n",
      "\n",
      "1 | Thu Sep 28 00:13:23 2017 | lowest loss so far: inf (run -1)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10948073658267082,\n",
      " 'max_depth': 2,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9773564962320919}\n",
      "\n",
      "# training | log loss: 50.17%, AUC: 91.96%, accuracy: 91.17%\n",
      "# testing  | log loss: 50.95%, AUC: 91.37%, accuracy: 88.22%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "2 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.5095 (run 1)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.058899244976344516,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8654569276546461}\n",
      "\n",
      "# training | log loss: 49.09%, AUC: 99.73%, accuracy: 97.83%\n",
      "# testing  | log loss: 52.74%, AUC: 98.57%, accuracy: 95.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "3 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.5095 (run 1)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10448357968405217,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.8734034479138724}\n",
      "\n",
      "# training | log loss: 47.34%, AUC: 97.45%, accuracy: 92.53%\n",
      "# testing  | log loss: 49.19%, AUC: 96.95%, accuracy: 90.22%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "4 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.4919 (run 3)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.15609784942438312,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9458587456887256}\n",
      "\n",
      "# training | log loss: 37.56%, AUC: 95.64%, accuracy: 92.17%\n",
      "# testing  | log loss: 40.79%, AUC: 94.38%, accuracy: 89.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "5 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.4079 (run 4)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.17069686082741595,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8139185851430316}\n",
      "\n",
      "# training | log loss: 25.91%, AUC: 99.87%, accuracy: 98.53%\n",
      "# testing  | log loss: 30.90%, AUC: 98.30%, accuracy: 95.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "6 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.14323745355368028,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9789507029177924}\n",
      "\n",
      "# training | log loss: 36.89%, AUC: 99.04%, accuracy: 95.57%\n",
      "# testing  | log loss: 40.09%, AUC: 98.02%, accuracy: 94.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "7 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10289948874412463,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9346719632545584}\n",
      "\n",
      "# training | log loss: 38.48%, AUC: 99.67%, accuracy: 96.73%\n",
      "# testing  | log loss: 42.15%, AUC: 98.22%, accuracy: 94.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "8 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.03658559355455769,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.9397067874103712}\n",
      "\n",
      "# training | log loss: 55.36%, AUC: 99.34%, accuracy: 96.20%\n",
      "# testing  | log loss: 58.99%, AUC: 98.16%, accuracy: 90.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "9 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1036143909806879,\n",
      " 'max_depth': 5,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 2,\n",
      " 'subsample': 0.9022649851727861}\n",
      "\n",
      "# training | log loss: 40.55%, AUC: 98.70%, accuracy: 95.07%\n",
      "# testing  | log loss: 44.06%, AUC: 97.98%, accuracy: 92.70%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "10 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.18861368617982344,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8733090008355578}\n",
      "\n",
      "# training | log loss: 37.12%, AUC: 97.51%, accuracy: 93.10%\n",
      "# testing  | log loss: 39.92%, AUC: 96.65%, accuracy: 90.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "11 | Thu Sep 28 00:13:23 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.07819648181916913,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 18,\n",
      " 'subsample': 0.9677501623270475}\n",
      "\n",
      "# training | log loss: 46.50%, AUC: 99.09%, accuracy: 94.97%\n",
      "# testing  | log loss: 49.29%, AUC: 98.19%, accuracy: 95.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "12 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10434608771666079,\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8194257546806554}\n",
      "\n",
      "# training | log loss: 37.57%, AUC: 99.79%, accuracy: 97.43%\n",
      "# testing  | log loss: 41.40%, AUC: 98.22%, accuracy: 94.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "13 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.19231464207271945,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9570981494669738}\n",
      "\n",
      "# training | log loss: 35.27%, AUC: 97.18%, accuracy: 93.03%\n",
      "# testing  | log loss: 35.60%, AUC: 97.16%, accuracy: 94.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "14 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.04494947937979423,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8552432432042557}\n",
      "\n",
      "# training | log loss: 62.82%, AUC: 94.53%, accuracy: 87.97%\n",
      "# testing  | log loss: 65.95%, AUC: 93.74%, accuracy: 80.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "15 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.06963540543105548,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8188478122070628}\n",
      "\n",
      "# training | log loss: 45.69%, AUC: 99.67%, accuracy: 97.33%\n",
      "# testing  | log loss: 49.22%, AUC: 98.32%, accuracy: 94.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "16 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.058952087381017336,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.9966163338820628}\n",
      "\n",
      "# training | log loss: 52.63%, AUC: 98.29%, accuracy: 94.10%\n",
      "# testing  | log loss: 56.48%, AUC: 97.38%, accuracy: 91.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "17 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.030837502624209374,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.9905455755391733}\n",
      "\n",
      "# training | log loss: 59.65%, AUC: 94.53%, accuracy: 91.63%\n",
      "# testing  | log loss: 63.10%, AUC: 93.11%, accuracy: 86.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "18 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.04495293667927852,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8483862634873441}\n",
      "\n",
      "# training | log loss: 65.21%, AUC: 90.58%, accuracy: 69.80%\n",
      "# testing  | log loss: 69.11%, AUC: 87.29%, accuracy: 41.97%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "19 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10930996743854532,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9661972027540967}\n",
      "\n",
      "# training | log loss: 43.38%, AUC: 98.99%, accuracy: 95.63%\n",
      "# testing  | log loss: 47.81%, AUC: 97.76%, accuracy: 93.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "20 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11018803449152438,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.9427879306033327}\n",
      "\n",
      "# training | log loss: 50.19%, AUC: 96.11%, accuracy: 89.30%\n",
      "# testing  | log loss: 51.87%, AUC: 95.71%, accuracy: 87.36%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "21 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.15485009197981445,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8229184707116074}\n",
      "\n",
      "# training | log loss: 32.13%, AUC: 99.54%, accuracy: 96.70%\n",
      "# testing  | log loss: 36.10%, AUC: 98.24%, accuracy: 95.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "22 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.14896584649131023,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 12,\n",
      " 'subsample': 0.9658775789497799}\n",
      "\n",
      "# training | log loss: 50.32%, AUC: 96.58%, accuracy: 92.43%\n",
      "# testing  | log loss: 54.40%, AUC: 95.54%, accuracy: 87.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "23 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.08102811018330158,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8032146428206114}\n",
      "\n",
      "# training | log loss: 46.73%, AUC: 98.78%, accuracy: 94.83%\n",
      "# testing  | log loss: 49.75%, AUC: 97.79%, accuracy: 94.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "24 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1460354004351075,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.9848457686458227}\n",
      "\n",
      "# training | log loss: 37.62%, AUC: 98.86%, accuracy: 95.27%\n",
      "# testing  | log loss: 40.98%, AUC: 97.70%, accuracy: 95.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "25 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.05379983451678785,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8473913523401649}\n",
      "\n",
      "# training | log loss: 62.70%, AUC: 90.45%, accuracy: 85.13%\n",
      "# testing  | log loss: 66.26%, AUC: 89.17%, accuracy: 83.67%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "26 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.15583855270255634,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9193392775510302}\n",
      "\n",
      "# training | log loss: 37.47%, AUC: 96.20%, accuracy: 92.30%\n",
      "# testing  | log loss: 40.49%, AUC: 95.39%, accuracy: 89.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "27 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.18435730545244297,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9724838814069894}\n",
      "\n",
      "# training | log loss: 33.61%, AUC: 98.32%, accuracy: 94.00%\n",
      "# testing  | log loss: 36.75%, AUC: 97.70%, accuracy: 92.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "28 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.04088893690608235,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 18,\n",
      " 'subsample': 0.9889510222577614}\n",
      "\n",
      "# training | log loss: 61.31%, AUC: 95.44%, accuracy: 87.73%\n",
      "# testing  | log loss: 64.63%, AUC: 94.55%, accuracy: 80.12%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "29 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.09575315309459137,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8689239383594627}\n",
      "\n",
      "# training | log loss: 53.73%, AUC: 96.24%, accuracy: 90.80%\n",
      "# testing  | log loss: 56.42%, AUC: 95.17%, accuracy: 89.02%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "30 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.06114858379194291,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8555222181396234}\n",
      "\n",
      "# training | log loss: 49.59%, AUC: 99.42%, accuracy: 96.10%\n",
      "# testing  | log loss: 53.13%, AUC: 98.06%, accuracy: 94.97%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "31 | Thu Sep 28 00:13:24 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.032630983224506215,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.8327860211439186}\n",
      "\n",
      "# training | log loss: 58.42%, AUC: 99.19%, accuracy: 94.93%\n",
      "# testing  | log loss: 61.70%, AUC: 98.09%, accuracy: 90.89%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "32 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.03355905400659223,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8256680296984114}\n",
      "\n",
      "# training | log loss: 56.40%, AUC: 99.56%, accuracy: 96.53%\n",
      "# testing  | log loss: 59.71%, AUC: 98.42%, accuracy: 92.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "33 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.13987247521336282,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.9389281611550853}\n",
      "\n",
      "# training | log loss: 34.66%, AUC: 99.28%, accuracy: 95.60%\n",
      "# testing  | log loss: 38.12%, AUC: 98.17%, accuracy: 96.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "34 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1806841170282773,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8191090250789204}\n",
      "\n",
      "# training | log loss: 28.53%, AUC: 99.65%, accuracy: 96.93%\n",
      "# testing  | log loss: 32.29%, AUC: 98.29%, accuracy: 95.80%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "35 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.06251156148448722,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.9476898184305961}\n",
      "\n",
      "# training | log loss: 54.27%, AUC: 96.83%, accuracy: 91.53%\n",
      "# testing  | log loss: 57.33%, AUC: 96.18%, accuracy: 87.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "36 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11337387191851031,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.8599813587228342}\n",
      "\n",
      "# training | log loss: 41.59%, AUC: 98.63%, accuracy: 94.53%\n",
      "# testing  | log loss: 44.09%, AUC: 97.90%, accuracy: 93.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "37 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10112729180983848,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8344054228561553}\n",
      "\n",
      "# training | log loss: 42.10%, AUC: 99.09%, accuracy: 96.00%\n",
      "# testing  | log loss: 45.35%, AUC: 98.12%, accuracy: 94.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "38 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11475130940971301,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.9383471680271216}\n",
      "\n",
      "# training | log loss: 44.84%, AUC: 98.23%, accuracy: 92.57%\n",
      "# testing  | log loss: 47.57%, AUC: 97.52%, accuracy: 87.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "39 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.03832868741403112,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.8888156620111787}\n",
      "\n",
      "# training | log loss: 58.82%, AUC: 97.59%, accuracy: 90.30%\n",
      "# testing  | log loss: 61.53%, AUC: 97.09%, accuracy: 85.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "40 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.05196647788590255,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8599211029331365}\n",
      "\n",
      "# training | log loss: 54.60%, AUC: 98.47%, accuracy: 94.00%\n",
      "# testing  | log loss: 57.87%, AUC: 97.61%, accuracy: 90.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "41 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.19398846486298116,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 16,\n",
      " 'subsample': 0.8796724559223199}\n",
      "\n",
      "# training | log loss: 37.32%, AUC: 97.46%, accuracy: 92.47%\n",
      "# testing  | log loss: 41.45%, AUC: 96.04%, accuracy: 89.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "42 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.15042194352721044,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.8774323852562586}\n",
      "\n",
      "# training | log loss: 32.09%, AUC: 99.63%, accuracy: 97.03%\n",
      "# testing  | log loss: 35.54%, AUC: 98.47%, accuracy: 96.11%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "43 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.09289395903036422,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.80628739321905}\n",
      "\n",
      "# training | log loss: 42.03%, AUC: 98.86%, accuracy: 95.33%\n",
      "# testing  | log loss: 46.02%, AUC: 97.94%, accuracy: 91.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "44 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.12051688243322352,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 12,\n",
      " 'subsample': 0.9317533624957337}\n",
      "\n",
      "# training | log loss: 51.02%, AUC: 96.55%, accuracy: 89.87%\n",
      "# testing  | log loss: 56.07%, AUC: 94.24%, accuracy: 82.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "45 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.16680923901424993,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9039515692026208}\n",
      "\n",
      "# training | log loss: 32.14%, AUC: 99.12%, accuracy: 95.83%\n",
      "# testing  | log loss: 36.00%, AUC: 98.08%, accuracy: 94.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "46 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11416623794748747,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8365481052945872}\n",
      "\n",
      "# training | log loss: 40.11%, AUC: 99.07%, accuracy: 95.47%\n",
      "# testing  | log loss: 43.04%, AUC: 98.08%, accuracy: 95.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "47 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.07543728186591725,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 18,\n",
      " 'subsample': 0.828716995241443}\n",
      "\n",
      "# training | log loss: 53.98%, AUC: 96.46%, accuracy: 92.07%\n",
      "# testing  | log loss: 55.16%, AUC: 96.57%, accuracy: 93.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "48 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.18062518717819076,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.9232808884538488}\n",
      "\n",
      "# training | log loss: 46.35%, AUC: 94.98%, accuracy: 90.57%\n",
      "# testing  | log loss: 51.80%, AUC: 93.07%, accuracy: 85.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "49 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.012493809480647353,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.9139591348228023}\n",
      "\n",
      "# training | log loss: 65.12%, AUC: 98.69%, accuracy: 77.30%\n",
      "# testing  | log loss: 68.47%, AUC: 97.83%, accuracy: 56.21%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "50 | Thu Sep 28 00:13:25 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1213723925009975,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9172177222032587}\n",
      "\n",
      "# training | log loss: 44.37%, AUC: 98.17%, accuracy: 93.80%\n",
      "# testing  | log loss: 47.96%, AUC: 97.30%, accuracy: 92.25%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "51 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11878790593045495,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8045936798307327}\n",
      "\n",
      "# training | log loss: 40.31%, AUC: 98.84%, accuracy: 95.10%\n",
      "# testing  | log loss: 42.92%, AUC: 98.04%, accuracy: 94.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "52 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1481604664666325,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.8638638008105615}\n",
      "\n",
      "# training | log loss: 35.35%, AUC: 99.17%, accuracy: 96.30%\n",
      "# testing  | log loss: 39.53%, AUC: 97.91%, accuracy: 94.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "53 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1771437578615261,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8231313694203439}\n",
      "\n",
      "# training | log loss: 28.78%, AUC: 99.04%, accuracy: 95.47%\n",
      "# testing  | log loss: 32.59%, AUC: 98.11%, accuracy: 92.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "54 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1185457477381868,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.8755575296420445}\n",
      "\n",
      "# training | log loss: 37.92%, AUC: 99.39%, accuracy: 95.93%\n",
      "# testing  | log loss: 41.58%, AUC: 98.22%, accuracy: 94.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "55 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.17385220664488754,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8482517645970387}\n",
      "\n",
      "# training | log loss: 32.34%, AUC: 98.92%, accuracy: 95.40%\n",
      "# testing  | log loss: 35.38%, AUC: 98.15%, accuracy: 95.69%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "56 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10454331708679752,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.842972431603815}\n",
      "\n",
      "# training | log loss: 43.89%, AUC: 98.28%, accuracy: 94.13%\n",
      "# testing  | log loss: 47.53%, AUC: 97.28%, accuracy: 90.89%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "57 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11497583866607342,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8261043653430352}\n",
      "\n",
      "# training | log loss: 40.53%, AUC: 98.71%, accuracy: 95.47%\n",
      "# testing  | log loss: 43.46%, AUC: 97.80%, accuracy: 94.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "58 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.011938454802018586,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.8804104038307483}\n",
      "\n",
      "# training | log loss: 64.36%, AUC: 98.94%, accuracy: 92.07%\n",
      "# testing  | log loss: 67.79%, AUC: 98.01%, accuracy: 81.40%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "59 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.08876426639782299,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 16,\n",
      " 'subsample': 0.8812360804183025}\n",
      "\n",
      "# training | log loss: 46.80%, AUC: 95.17%, accuracy: 92.30%\n",
      "# testing  | log loss: 50.50%, AUC: 93.91%, accuracy: 88.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "60 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.10215479632853298,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.975396683453934}\n",
      "\n",
      "# training | log loss: 38.54%, AUC: 99.58%, accuracy: 96.57%\n",
      "# testing  | log loss: 42.06%, AUC: 98.37%, accuracy: 93.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "61 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1616233305323814,\n",
      " 'max_depth': 2,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.9179609519456022}\n",
      "\n",
      "# training | log loss: 45.05%, AUC: 92.68%, accuracy: 91.07%\n",
      "# testing  | log loss: 45.21%, AUC: 92.06%, accuracy: 88.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "62 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1669558400372308,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 18,\n",
      " 'subsample': 0.900307211147659}\n",
      "\n",
      "# training | log loss: 56.42%, AUC: 91.29%, accuracy: 77.10%\n",
      "# testing  | log loss: 63.15%, AUC: 87.76%, accuracy: 53.67%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "63 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.021753205540516955,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.8272459897816197}\n",
      "\n",
      "# training | log loss: 65.48%, AUC: 92.98%, accuracy: 71.13%\n",
      "# testing  | log loss: 69.20%, AUC: 91.21%, accuracy: 42.24%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "64 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1066733053310453,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9959838070161853}\n",
      "\n",
      "# training | log loss: 38.34%, AUC: 99.07%, accuracy: 95.50%\n",
      "# testing  | log loss: 42.06%, AUC: 97.82%, accuracy: 91.20%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "65 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1769846620987672,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.9725755848387072}\n",
      "\n",
      "# training | log loss: 28.42%, AUC: 99.68%, accuracy: 96.83%\n",
      "# testing  | log loss: 32.92%, AUC: 98.32%, accuracy: 95.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "66 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1252669037490443,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.9046079334166649}\n",
      "\n",
      "# training | log loss: 35.60%, AUC: 99.58%, accuracy: 96.67%\n",
      "# testing  | log loss: 38.70%, AUC: 98.44%, accuracy: 96.31%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "67 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.02327624463068417,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.9309274493172528}\n",
      "\n",
      "# training | log loss: 60.89%, AUC: 99.26%, accuracy: 95.53%\n",
      "# testing  | log loss: 64.34%, AUC: 98.13%, accuracy: 89.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "68 | Thu Sep 28 00:13:26 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.12796000518967027,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.9151543750768408}\n",
      "\n",
      "# training | log loss: 39.91%, AUC: 98.68%, accuracy: 94.17%\n",
      "# testing  | log loss: 43.96%, AUC: 97.42%, accuracy: 90.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "69 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.06662353247986495,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.8267103427398937}\n",
      "\n",
      "# training | log loss: 47.58%, AUC: 99.53%, accuracy: 96.93%\n",
      "# testing  | log loss: 51.00%, AUC: 98.44%, accuracy: 95.78%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "70 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.06646005427752509,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.9685195558927422}\n",
      "\n",
      "# training | log loss: 46.45%, AUC: 99.61%, accuracy: 97.03%\n",
      "# testing  | log loss: 50.11%, AUC: 98.28%, accuracy: 93.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "71 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1278271374959585,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.8239165648320492}\n",
      "\n",
      "# training | log loss: 59.00%, AUC: 90.35%, accuracy: 80.63%\n",
      "# testing  | log loss: 63.21%, AUC: 88.35%, accuracy: 74.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "72 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.0636582881651696,\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.9509396961036256}\n",
      "\n",
      "# training | log loss: 50.09%, AUC: 97.37%, accuracy: 93.43%\n",
      "# testing  | log loss: 53.72%, AUC: 96.56%, accuracy: 89.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "73 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.11508053185674742,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9209564230317362}\n",
      "\n",
      "# training | log loss: 44.48%, AUC: 97.98%, accuracy: 93.27%\n",
      "# testing  | log loss: 48.18%, AUC: 96.67%, accuracy: 90.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "74 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.011371186253498363,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8476465245986046}\n",
      "\n",
      "# training | log loss: 65.94%, AUC: 97.31%, accuracy: 63.60%\n",
      "# testing  | log loss: 69.12%, AUC: 96.75%, accuracy: 38.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "75 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1214300054984113,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.8550329665534532}\n",
      "\n",
      "# training | log loss: 50.65%, AUC: 94.19%, accuracy: 87.43%\n",
      "# testing  | log loss: 55.24%, AUC: 92.23%, accuracy: 84.16%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "76 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.05753465147861896,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.8644215773278825}\n",
      "\n",
      "# training | log loss: 48.49%, AUC: 99.76%, accuracy: 97.77%\n",
      "# testing  | log loss: 52.16%, AUC: 98.36%, accuracy: 94.31%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "77 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.08868633262636975,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 12,\n",
      " 'subsample': 0.9970088460191444}\n",
      "\n",
      "# training | log loss: 46.01%, AUC: 98.92%, accuracy: 96.23%\n",
      "# testing  | log loss: 48.95%, AUC: 98.07%, accuracy: 95.69%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "78 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.05388052616236934,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.914203697636145}\n",
      "\n",
      "# training | log loss: 54.15%, AUC: 98.68%, accuracy: 93.73%\n",
      "# testing  | log loss: 57.67%, AUC: 97.64%, accuracy: 90.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "79 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.1971028224793494,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.9075248707002062}\n",
      "\n",
      "# training | log loss: 38.70%, AUC: 97.66%, accuracy: 92.67%\n",
      "# testing  | log loss: 43.63%, AUC: 96.66%, accuracy: 89.21%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "80 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.08315813922879794,\n",
      " 'max_depth': 5,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 16,\n",
      " 'subsample': 0.82477526663618}\n",
      "\n",
      "# training | log loss: 44.91%, AUC: 98.36%, accuracy: 94.00%\n",
      "# testing  | log loss: 48.45%, AUC: 97.42%, accuracy: 90.40%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "81 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 5\n",
      "{'learning_rate': 0.09944727476859969,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.9117156530318209}\n",
      "\n",
      "# training | log loss: 55.99%, AUC: 96.06%, accuracy: 91.47%\n",
      "# testing  | log loss: 60.73%, AUC: 93.91%, accuracy: 83.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 27.0 configurations x 3.0 iterations each\n",
      "\n",
      "82 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.3090 (run 5)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.17069686082741595,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8139185851430316}\n",
      "\n",
      "# training | log loss: 6.77%, AUC: 99.96%, accuracy: 99.37%\n",
      "# testing  | log loss: 13.47%, AUC: 98.73%, accuracy: 96.20%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "83 | Thu Sep 28 00:13:27 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1806841170282773,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8191090250789204}\n",
      "\n",
      "# training | log loss: 9.66%, AUC: 99.93%, accuracy: 98.53%\n",
      "# testing  | log loss: 14.31%, AUC: 98.75%, accuracy: 97.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "84 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1771437578615261,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8231313694203439}\n",
      "\n",
      "# training | log loss: 11.16%, AUC: 99.67%, accuracy: 97.27%\n",
      "# testing  | log loss: 15.28%, AUC: 98.68%, accuracy: 95.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "85 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1769846620987672,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.9725755848387072}\n",
      "\n",
      "# training | log loss: 9.27%, AUC: 99.90%, accuracy: 98.87%\n",
      "# testing  | log loss: 15.12%, AUC: 98.74%, accuracy: 96.67%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "86 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.17385220664488754,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8482517645970387}\n",
      "\n",
      "# training | log loss: 13.14%, AUC: 99.62%, accuracy: 97.10%\n",
      "# testing  | log loss: 17.70%, AUC: 98.49%, accuracy: 95.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "87 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15042194352721044,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.8774323852562586}\n",
      "\n",
      "# training | log loss: 10.97%, AUC: 99.92%, accuracy: 98.73%\n",
      "# testing  | log loss: 15.97%, AUC: 98.90%, accuracy: 97.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "88 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.19231464207271945,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9570981494669738}\n",
      "\n",
      "# training | log loss: 19.76%, AUC: 98.73%, accuracy: 95.20%\n",
      "# testing  | log loss: 21.98%, AUC: 98.23%, accuracy: 95.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "89 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.16680923901424993,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9039515692026208}\n",
      "\n",
      "# training | log loss: 12.83%, AUC: 99.73%, accuracy: 97.43%\n",
      "# testing  | log loss: 17.41%, AUC: 98.59%, accuracy: 96.12%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "90 | Thu Sep 28 00:13:28 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15485009197981445,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8229184707116074}\n",
      "\n",
      "# training | log loss: 11.19%, AUC: 99.85%, accuracy: 98.60%\n",
      "# testing  | log loss: 16.55%, AUC: 98.66%, accuracy: 96.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "91 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.18435730545244297,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9724838814069894}\n",
      "\n",
      "# training | log loss: 18.64%, AUC: 99.16%, accuracy: 95.33%\n",
      "# testing  | log loss: 24.18%, AUC: 98.10%, accuracy: 93.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "92 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.13987247521336282,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.9389281611550853}\n",
      "\n",
      "# training | log loss: 16.61%, AUC: 99.62%, accuracy: 96.90%\n",
      "# testing  | log loss: 21.46%, AUC: 98.46%, accuracy: 95.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "93 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1252669037490443,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.9046079334166649}\n",
      "\n",
      "# training | log loss: 15.37%, AUC: 99.77%, accuracy: 97.83%\n",
      "# testing  | log loss: 19.87%, AUC: 98.63%, accuracy: 96.51%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "94 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1481604664666325,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.8638638008105615}\n",
      "\n",
      "# training | log loss: 13.49%, AUC: 99.67%, accuracy: 97.83%\n",
      "# testing  | log loss: 17.15%, AUC: 98.77%, accuracy: 97.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "95 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.18861368617982344,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8733090008355578}\n",
      "\n",
      "# training | log loss: 17.89%, AUC: 99.03%, accuracy: 95.53%\n",
      "# testing  | log loss: 22.06%, AUC: 98.03%, accuracy: 94.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "96 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.14323745355368028,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9789507029177924}\n",
      "\n",
      "# training | log loss: 15.48%, AUC: 99.56%, accuracy: 97.10%\n",
      "# testing  | log loss: 19.24%, AUC: 98.65%, accuracy: 96.25%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "97 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15583855270255634,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9193392775510302}\n",
      "\n",
      "# training | log loss: 20.61%, AUC: 98.53%, accuracy: 94.00%\n",
      "# testing  | log loss: 23.16%, AUC: 98.07%, accuracy: 91.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "98 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15609784942438312,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.9458587456887256}\n",
      "\n",
      "# training | log loss: 20.00%, AUC: 98.37%, accuracy: 93.83%\n",
      "# testing  | log loss: 21.95%, AUC: 97.88%, accuracy: 91.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "99 | Thu Sep 28 00:13:29 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1460354004351075,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.9848457686458227}\n",
      "\n",
      "# training | log loss: 17.52%, AUC: 99.37%, accuracy: 96.37%\n",
      "# testing  | log loss: 22.00%, AUC: 98.45%, accuracy: 95.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "100 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.10434608771666079,\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8194257546806554}\n",
      "\n",
      "# training | log loss: 14.97%, AUC: 99.91%, accuracy: 98.43%\n",
      "# testing  | log loss: 20.12%, AUC: 98.66%, accuracy: 95.79%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "101 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.19398846486298116,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 16,\n",
      " 'subsample': 0.8796724559223199}\n",
      "\n",
      "# training | log loss: 14.54%, AUC: 99.35%, accuracy: 96.03%\n",
      "# testing  | log loss: 18.00%, AUC: 98.54%, accuracy: 95.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "102 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1185457477381868,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.8755575296420445}\n",
      "\n",
      "# training | log loss: 16.63%, AUC: 99.78%, accuracy: 97.10%\n",
      "# testing  | log loss: 21.29%, AUC: 98.59%, accuracy: 96.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "103 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1066733053310453,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.9959838070161853}\n",
      "\n",
      "# training | log loss: 17.39%, AUC: 99.47%, accuracy: 96.97%\n",
      "# testing  | log loss: 21.51%, AUC: 98.53%, accuracy: 95.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "104 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.10215479632853298,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.975396683453934}\n",
      "\n",
      "# training | log loss: 16.81%, AUC: 99.75%, accuracy: 97.70%\n",
      "# testing  | log loss: 21.11%, AUC: 98.57%, accuracy: 95.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "105 | Thu Sep 28 00:13:30 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.10289948874412463,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9346719632545584}\n",
      "\n",
      "# training | log loss: 16.74%, AUC: 99.79%, accuracy: 97.67%\n",
      "# testing  | log loss: 21.13%, AUC: 98.55%, accuracy: 96.31%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "106 | Thu Sep 28 00:13:31 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.11878790593045495,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8045936798307327}\n",
      "\n",
      "# training | log loss: 21.02%, AUC: 99.18%, accuracy: 95.93%\n",
      "# testing  | log loss: 23.87%, AUC: 98.24%, accuracy: 95.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "107 | Thu Sep 28 00:13:31 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.11416623794748747,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8365481052945872}\n",
      "\n",
      "# training | log loss: 18.28%, AUC: 99.62%, accuracy: 96.73%\n",
      "# testing  | log loss: 22.39%, AUC: 98.62%, accuracy: 96.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "108 | Thu Sep 28 00:13:31 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.11497583866607342,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8261043653430352}\n",
      "\n",
      "# training | log loss: 20.20%, AUC: 99.41%, accuracy: 96.67%\n",
      "# testing  | log loss: 23.62%, AUC: 98.44%, accuracy: 96.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9.0 configurations x 9.0 iterations each\n",
      "\n",
      "109 | Thu Sep 28 00:13:31 2017 | lowest loss so far: 0.1347 (run 82)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.17069686082741595,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8139185851430316}\n",
      "\n",
      "# training | log loss: 0.47%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 8.64%, AUC: 98.97%, accuracy: 97.08%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "110 | Thu Sep 28 00:13:32 2017 | lowest loss so far: 0.0864 (run 109)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1806841170282773,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8191090250789204}\n",
      "\n",
      "# training | log loss: 1.55%, AUC: 100.00%, accuracy: 99.93%\n",
      "# testing  | log loss: 9.27%, AUC: 99.01%, accuracy: 96.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "111 | Thu Sep 28 00:13:32 2017 | lowest loss so far: 0.0864 (run 109)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1769846620987672,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.9725755848387072}\n",
      "\n",
      "# training | log loss: 1.43%, AUC: 100.00%, accuracy: 99.93%\n",
      "# testing  | log loss: 8.61%, AUC: 99.00%, accuracy: 97.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "112 | Thu Sep 28 00:13:33 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1771437578615261,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8231313694203439}\n",
      "\n",
      "# training | log loss: 3.31%, AUC: 99.99%, accuracy: 99.40%\n",
      "# testing  | log loss: 10.68%, AUC: 98.98%, accuracy: 96.25%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "113 | Thu Sep 28 00:13:33 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.15042194352721044,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.8774323852562586}\n",
      "\n",
      "# training | log loss: 2.02%, AUC: 100.00%, accuracy: 99.87%\n",
      "# testing  | log loss: 9.51%, AUC: 99.01%, accuracy: 97.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "114 | Thu Sep 28 00:13:34 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.15485009197981445,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8229184707116074}\n",
      "\n",
      "# training | log loss: 2.02%, AUC: 100.00%, accuracy: 99.90%\n",
      "# testing  | log loss: 9.52%, AUC: 98.93%, accuracy: 97.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "115 | Thu Sep 28 00:13:34 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1481604664666325,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.8638638008105615}\n",
      "\n",
      "# training | log loss: 4.16%, AUC: 99.98%, accuracy: 99.33%\n",
      "# testing  | log loss: 11.19%, AUC: 98.95%, accuracy: 96.59%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "116 | Thu Sep 28 00:13:34 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.16680923901424993,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9039515692026208}\n",
      "\n",
      "# training | log loss: 3.65%, AUC: 99.99%, accuracy: 99.47%\n",
      "# testing  | log loss: 10.97%, AUC: 98.93%, accuracy: 96.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "117 | Thu Sep 28 00:13:35 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.17385220664488754,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8482517645970387}\n",
      "\n",
      "# training | log loss: 4.81%, AUC: 99.94%, accuracy: 98.87%\n",
      "# testing  | log loss: 11.97%, AUC: 98.87%, accuracy: 96.01%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 27.0 iterations each\n",
      "\n",
      "118 | Thu Sep 28 00:13:35 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.1769846620987672,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.9725755848387072}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.62%, AUC: 98.99%, accuracy: 97.13%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "119 | Thu Sep 28 00:13:36 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.17069686082741595,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8139185851430316}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.39%, AUC: 98.98%, accuracy: 97.34%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "120 | Thu Sep 28 00:13:38 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.1806841170282773,\n",
      " 'max_depth': 10,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8191090250789204}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.44%, AUC: 99.00%, accuracy: 97.19%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "*** 1.0 configurations x 81.0 iterations each\n",
      "\n",
      "121 | Thu Sep 28 00:13:39 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.17069686082741595,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8139185851430316}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.12%, AUC: 99.00%, accuracy: 97.31%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "*** 27 configurations x 3.0 iterations each\n",
      "\n",
      "122 | Thu Sep 28 00:13:41 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.11736313453730748,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.971854664482022}\n",
      "\n",
      "# training | log loss: 15.09%, AUC: 99.74%, accuracy: 97.50%\n",
      "# testing  | log loss: 19.70%, AUC: 98.56%, accuracy: 95.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "123 | Thu Sep 28 00:13:41 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.014390640266480993,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.9136969680504571}\n",
      "\n",
      "# training | log loss: 54.56%, AUC: 99.72%, accuracy: 97.53%\n",
      "# testing  | log loss: 58.15%, AUC: 98.76%, accuracy: 95.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "124 | Thu Sep 28 00:13:41 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.19116990619710336,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8525005098343338}\n",
      "\n",
      "# training | log loss: 12.11%, AUC: 99.69%, accuracy: 97.10%\n",
      "# testing  | log loss: 16.16%, AUC: 98.70%, accuracy: 96.76%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "125 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.035019808105702106,\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 5,\n",
      " 'subsample': 0.8545529484684362}\n",
      "\n",
      "# training | log loss: 36.68%, AUC: 99.94%, accuracy: 98.90%\n",
      "# testing  | log loss: 41.24%, AUC: 98.33%, accuracy: 94.99%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "126 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.0906700945101033,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8542743881527751}\n",
      "\n",
      "# training | log loss: 18.59%, AUC: 99.79%, accuracy: 97.57%\n",
      "# testing  | log loss: 22.91%, AUC: 98.69%, accuracy: 95.29%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "127 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.17677822238193847,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8676310595202422}\n",
      "\n",
      "# training | log loss: 8.20%, AUC: 99.92%, accuracy: 98.80%\n",
      "# testing  | log loss: 13.68%, AUC: 98.82%, accuracy: 96.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "128 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.06539113803674845,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8353298955143321}\n",
      "\n",
      "# training | log loss: 31.02%, AUC: 99.13%, accuracy: 95.63%\n",
      "# testing  | log loss: 34.30%, AUC: 98.24%, accuracy: 95.86%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "129 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.036172412107512576,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 4,\n",
      " 'subsample': 0.9663595335664207}\n",
      "\n",
      "# training | log loss: 46.81%, AUC: 98.74%, accuracy: 94.60%\n",
      "# testing  | log loss: 51.91%, AUC: 97.64%, accuracy: 90.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "130 | Thu Sep 28 00:13:42 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.07085305837098604,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 18,\n",
      " 'subsample': 0.8584706290447147}\n",
      "\n",
      "# training | log loss: 26.85%, AUC: 99.59%, accuracy: 96.87%\n",
      "# testing  | log loss: 29.82%, AUC: 98.63%, accuracy: 97.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "131 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.05140346694814492,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8923797586857144}\n",
      "\n",
      "# training | log loss: 34.45%, AUC: 99.39%, accuracy: 95.80%\n",
      "# testing  | log loss: 37.23%, AUC: 98.54%, accuracy: 96.73%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "132 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15853276616681117,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 12,\n",
      " 'subsample': 0.8834939266232357}\n",
      "\n",
      "# training | log loss: 25.04%, AUC: 98.31%, accuracy: 94.30%\n",
      "# testing  | log loss: 29.25%, AUC: 97.55%, accuracy: 92.67%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "133 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.13052201313739414,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8190087352266454}\n",
      "\n",
      "# training | log loss: 24.35%, AUC: 98.91%, accuracy: 95.10%\n",
      "# testing  | log loss: 28.03%, AUC: 97.90%, accuracy: 93.21%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "134 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.019208225900422274,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8976564641184354}\n",
      "\n",
      "# training | log loss: 60.03%, AUC: 96.01%, accuracy: 87.17%\n",
      "# testing  | log loss: 64.00%, AUC: 93.79%, accuracy: 79.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "135 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.09830952699550209,\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.858192481778386}\n",
      "\n",
      "# training | log loss: 17.28%, AUC: 99.82%, accuracy: 97.30%\n",
      "# testing  | log loss: 21.64%, AUC: 98.64%, accuracy: 96.22%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "136 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.15762526041648256,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.883756112950388}\n",
      "\n",
      "# training | log loss: 11.27%, AUC: 99.76%, accuracy: 97.80%\n",
      "# testing  | log loss: 16.03%, AUC: 98.71%, accuracy: 95.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "137 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.11434410905390581,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8756146563921536}\n",
      "\n",
      "# training | log loss: 21.84%, AUC: 99.03%, accuracy: 95.30%\n",
      "# testing  | log loss: 24.41%, AUC: 98.27%, accuracy: 95.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "138 | Thu Sep 28 00:13:43 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.19647690528775552,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.802855622382238}\n",
      "\n",
      "# training | log loss: 10.56%, AUC: 99.79%, accuracy: 97.47%\n",
      "# testing  | log loss: 16.13%, AUC: 98.66%, accuracy: 96.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "139 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.1034983368208853,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.8215671988844168}\n",
      "\n",
      "# training | log loss: 25.25%, AUC: 98.75%, accuracy: 95.53%\n",
      "# testing  | log loss: 27.23%, AUC: 98.25%, accuracy: 95.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "140 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.05794617135564509,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9660883781216264}\n",
      "\n",
      "# training | log loss: 28.64%, AUC: 99.50%, accuracy: 97.10%\n",
      "# testing  | log loss: 32.56%, AUC: 98.35%, accuracy: 93.91%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "141 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.032453639461080416,\n",
      " 'max_depth': 6,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.9264488061324642}\n",
      "\n",
      "# training | log loss: 40.67%, AUC: 99.17%, accuracy: 95.67%\n",
      "# testing  | log loss: 44.37%, AUC: 98.15%, accuracy: 92.20%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "142 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.09374498319162218,\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8135639351525629}\n",
      "\n",
      "# training | log loss: 26.89%, AUC: 98.00%, accuracy: 93.73%\n",
      "# testing  | log loss: 28.39%, AUC: 97.74%, accuracy: 91.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "143 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.06858390252261033,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.876162882081585}\n",
      "\n",
      "# training | log loss: 30.19%, AUC: 99.37%, accuracy: 96.37%\n",
      "# testing  | log loss: 33.79%, AUC: 98.45%, accuracy: 95.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "144 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.10414427810083633,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.8129692016106584}\n",
      "\n",
      "# training | log loss: 23.31%, AUC: 99.14%, accuracy: 95.37%\n",
      "# testing  | log loss: 26.24%, AUC: 98.18%, accuracy: 95.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "145 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.19255277922162595,\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9224934921181591}\n",
      "\n",
      "# training | log loss: 14.18%, AUC: 99.28%, accuracy: 95.40%\n",
      "# testing  | log loss: 17.46%, AUC: 98.52%, accuracy: 93.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "146 | Thu Sep 28 00:13:44 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.06324810731929152,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 3,\n",
      " 'subsample': 0.9763103757990954}\n",
      "\n",
      "# training | log loss: 28.51%, AUC: 99.70%, accuracy: 97.67%\n",
      "# testing  | log loss: 32.00%, AUC: 98.66%, accuracy: 97.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "147 | Thu Sep 28 00:13:45 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.06836428110856868,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 7,\n",
      " 'subsample': 0.8283634550194955}\n",
      "\n",
      "# training | log loss: 28.27%, AUC: 99.53%, accuracy: 96.63%\n",
      "# testing  | log loss: 32.10%, AUC: 98.48%, accuracy: 96.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "148 | Thu Sep 28 00:13:45 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 15\n",
      "{'learning_rate': 0.08353884543961744,\n",
      " 'max_depth': 4,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 16,\n",
      " 'subsample': 0.8497288912715881}\n",
      "\n",
      "# training | log loss: 34.26%, AUC: 98.17%, accuracy: 93.63%\n",
      "# testing  | log loss: 37.80%, AUC: 97.47%, accuracy: 92.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9.0 configurations x 9.0 iterations each\n",
      "\n",
      "149 | Thu Sep 28 00:13:45 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.17677822238193847,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8676310595202422}\n",
      "\n",
      "# training | log loss: 1.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 8.92%, AUC: 98.98%, accuracy: 96.97%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "150 | Thu Sep 28 00:13:45 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.15762526041648256,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.883756112950388}\n",
      "\n",
      "# training | log loss: 2.51%, AUC: 100.00%, accuracy: 99.80%\n",
      "# testing  | log loss: 9.87%, AUC: 99.07%, accuracy: 96.67%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "151 | Thu Sep 28 00:13:46 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.19647690528775552,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.802855622382238}\n",
      "\n",
      "# training | log loss: 2.40%, AUC: 100.00%, accuracy: 99.77%\n",
      "# testing  | log loss: 9.92%, AUC: 99.02%, accuracy: 96.86%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "152 | Thu Sep 28 00:13:46 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.19116990619710336,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8525005098343338}\n",
      "\n",
      "# training | log loss: 3.79%, AUC: 99.98%, accuracy: 99.40%\n",
      "# testing  | log loss: 11.49%, AUC: 98.97%, accuracy: 96.12%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "153 | Thu Sep 28 00:13:47 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.19255277922162595,\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9224934921181591}\n",
      "\n",
      "# training | log loss: 6.92%, AUC: 99.84%, accuracy: 97.83%\n",
      "# testing  | log loss: 12.51%, AUC: 98.82%, accuracy: 95.97%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "154 | Thu Sep 28 00:13:47 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.11736313453730748,\n",
      " 'max_depth': 8,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.971854664482022}\n",
      "\n",
      "# training | log loss: 3.50%, AUC: 99.98%, accuracy: 99.33%\n",
      "# testing  | log loss: 10.15%, AUC: 99.03%, accuracy: 96.57%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "155 | Thu Sep 28 00:13:47 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.09830952699550209,\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.858192481778386}\n",
      "\n",
      "# training | log loss: 3.40%, AUC: 100.00%, accuracy: 99.73%\n",
      "# testing  | log loss: 10.04%, AUC: 99.04%, accuracy: 96.83%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "156 | Thu Sep 28 00:13:48 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.0906700945101033,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.8542743881527751}\n",
      "\n",
      "# training | log loss: 3.99%, AUC: 99.99%, accuracy: 99.70%\n",
      "# testing  | log loss: 10.50%, AUC: 98.98%, accuracy: 96.60%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "157 | Thu Sep 28 00:13:49 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.11434410905390581,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8756146563921536}\n",
      "\n",
      "# training | log loss: 9.75%, AUC: 99.73%, accuracy: 97.47%\n",
      "# testing  | log loss: 15.17%, AUC: 98.81%, accuracy: 95.56%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 27.0 iterations each\n",
      "\n",
      "158 | Thu Sep 28 00:13:49 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.17677822238193847,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 9,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.8676310595202422}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 11.21%, AUC: 98.96%, accuracy: 97.02%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "159 | Thu Sep 28 00:13:51 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.15762526041648256,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.883756112950388}\n",
      "\n",
      "# training | log loss: 0.08%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.21%, AUC: 99.00%, accuracy: 96.85%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "160 | Thu Sep 28 00:13:52 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.19647690528775552,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.802855622382238}\n",
      "\n",
      "# training | log loss: 0.05%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.81%, AUC: 98.96%, accuracy: 96.91%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "*** 1.0 configurations x 81.0 iterations each\n",
      "\n",
      "161 | Thu Sep 28 00:13:53 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.15762526041648256,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 20,\n",
      " 'subsample': 0.883756112950388}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 11.77%, AUC: 98.93%, accuracy: 96.92%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "*** 9 configurations x 9.0 iterations each\n",
      "\n",
      "162 | Thu Sep 28 00:13:55 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.18928467948833075,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8796949603141723}\n",
      "\n",
      "# training | log loss: 1.38%, AUC: 100.00%, accuracy: 99.93%\n",
      "# testing  | log loss: 8.92%, AUC: 99.02%, accuracy: 97.02%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "163 | Thu Sep 28 00:13:56 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1167735094382803,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.9074385955349866}\n",
      "\n",
      "# training | log loss: 6.62%, AUC: 99.90%, accuracy: 98.60%\n",
      "# testing  | log loss: 12.72%, AUC: 98.83%, accuracy: 96.34%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "164 | Thu Sep 28 00:13:56 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.16866148651470175,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8485221073925377}\n",
      "\n",
      "# training | log loss: 5.01%, AUC: 99.96%, accuracy: 99.07%\n",
      "# testing  | log loss: 11.87%, AUC: 98.96%, accuracy: 96.34%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "165 | Thu Sep 28 00:13:56 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.02228114160132352,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 19,\n",
      " 'subsample': 0.8665645408815911}\n",
      "\n",
      "# training | log loss: 29.40%, AUC: 99.50%, accuracy: 96.17%\n",
      "# testing  | log loss: 32.83%, AUC: 98.57%, accuracy: 96.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "166 | Thu Sep 28 00:13:57 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.15987522816264135,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8720633976918732}\n",
      "\n",
      "# training | log loss: 1.92%, AUC: 100.00%, accuracy: 99.83%\n",
      "# testing  | log loss: 9.42%, AUC: 99.06%, accuracy: 96.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "167 | Thu Sep 28 00:13:57 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.03359899578597631,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.8575833225251347}\n",
      "\n",
      "# training | log loss: 24.49%, AUC: 99.14%, accuracy: 95.43%\n",
      "# testing  | log loss: 27.62%, AUC: 98.32%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "168 | Thu Sep 28 00:13:57 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.16132131350735907,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.9769712773105282}\n",
      "\n",
      "# training | log loss: 15.63%, AUC: 98.99%, accuracy: 95.20%\n",
      "# testing  | log loss: 20.53%, AUC: 98.16%, accuracy: 93.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "169 | Thu Sep 28 00:13:57 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.1479825290638138,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8659158155020963}\n",
      "\n",
      "# training | log loss: 9.16%, AUC: 99.72%, accuracy: 97.80%\n",
      "# testing  | log loss: 15.35%, AUC: 98.72%, accuracy: 95.34%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "170 | Thu Sep 28 00:13:57 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 45\n",
      "{'learning_rate': 0.13904925134254617,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 6,\n",
      " 'subsample': 0.8388422068665762}\n",
      "\n",
      "# training | log loss: 22.18%, AUC: 98.25%, accuracy: 94.00%\n",
      "# testing  | log loss: 27.85%, AUC: 97.22%, accuracy: 91.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 27.0 iterations each\n",
      "\n",
      "171 | Thu Sep 28 00:13:58 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.18928467948833075,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8796949603141723}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.69%, AUC: 99.02%, accuracy: 97.27%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "172 | Thu Sep 28 00:13:59 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.15987522816264135,\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8720633976918732}\n",
      "\n",
      "# training | log loss: 0.02%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.15%, AUC: 99.00%, accuracy: 97.23%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "173 | Thu Sep 28 00:14:00 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.16866148651470175,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8485221073925377}\n",
      "\n",
      "# training | log loss: 0.51%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.14%, AUC: 98.93%, accuracy: 96.63%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "*** 1.0 configurations x 81.0 iterations each\n",
      "\n",
      "174 | Thu Sep 28 00:14:01 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.16866148651470175,\n",
      " 'max_depth': 6,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8485221073925377}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 13.80%, AUC: 98.93%, accuracy: 96.71%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "*** 6 configurations x 27.0 iterations each\n",
      "\n",
      "175 | Thu Sep 28 00:14:03 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.13112203077076706,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9822861812148368}\n",
      "\n",
      "# training | log loss: 0.17%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 9.53%, AUC: 99.01%, accuracy: 96.88%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "176 | Thu Sep 28 00:14:04 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.036425694425792535,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 9,\n",
      " 'subsample': 0.8028770616754207}\n",
      "\n",
      "# training | log loss: 11.69%, AUC: 99.52%, accuracy: 96.63%\n",
      "# testing  | log loss: 15.99%, AUC: 98.68%, accuracy: 95.78%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "177 | Thu Sep 28 00:14:05 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.12135318704215547,\n",
      " 'max_depth': 3,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9403485586176605}\n",
      "\n",
      "# training | log loss: 9.04%, AUC: 99.64%, accuracy: 97.13%\n",
      "# testing  | log loss: 14.66%, AUC: 98.75%, accuracy: 95.06%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "178 | Thu Sep 28 00:14:05 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.17521765934274502,\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 15,\n",
      " 'subsample': 0.8221303739564697}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.79%, AUC: 98.99%, accuracy: 97.21%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "179 | Thu Sep 28 00:14:07 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.19289004288231898,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8876144971852449}\n",
      "\n",
      "# training | log loss: 0.04%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.58%, AUC: 98.99%, accuracy: 97.02%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "180 | Thu Sep 28 00:14:08 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 135\n",
      "{'learning_rate': 0.10339224895303195,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 8,\n",
      " 'subsample': 0.8904763290551876}\n",
      "\n",
      "# training | log loss: 4.34%, AUC: 99.96%, accuracy: 98.97%\n",
      "# testing  | log loss: 12.15%, AUC: 98.98%, accuracy: 95.88%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "*** 2.0 configurations x 81.0 iterations each\n",
      "\n",
      "181 | Thu Sep 28 00:14:08 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.13112203077076706,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 14,\n",
      " 'subsample': 0.9822861812148368}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.08%, AUC: 98.94%, accuracy: 96.79%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "182 | Thu Sep 28 00:14:11 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.19289004288231898,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 11,\n",
      " 'subsample': 0.8876144971852449}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.19%, AUC: 98.91%, accuracy: 96.98%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "*** 5 configurations x 81.0 iterations each\n",
      "\n",
      "183 | Thu Sep 28 00:14:12 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.1594420401866271,\n",
      " 'max_depth': 8,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 6,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.8572243765786713}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.00%, AUC: 98.94%, accuracy: 96.93%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "184 | Thu Sep 28 00:14:14 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.11238230171823492,\n",
      " 'max_depth': 7,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_samples_split': 2,\n",
      " 'subsample': 0.9779662118961386}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.63%, AUC: 98.96%, accuracy: 96.80%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "185 | Thu Sep 28 00:14:16 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.12260130852283373,\n",
      " 'max_depth': 2,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 13,\n",
      " 'subsample': 0.9554721442163021}\n",
      "\n",
      "# training | log loss: 7.70%, AUC: 99.73%, accuracy: 97.50%\n",
      "# testing  | log loss: 13.96%, AUC: 98.80%, accuracy: 95.26%\n",
      "\n",
      "1 seconds.\n",
      "\n",
      "186 | Thu Sep 28 00:14:17 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.1862877504155004,\n",
      " 'max_depth': 7,\n",
      " 'max_features': None,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 17,\n",
      " 'subsample': 0.9266528307856066}\n",
      "\n",
      "# training | log loss: 0.01%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.04%, AUC: 98.95%, accuracy: 96.84%\n",
      "\n",
      "2 seconds.\n",
      "\n",
      "187 | Thu Sep 28 00:14:19 2017 | lowest loss so far: 0.0861 (run 111)\n",
      "\n",
      "n_estimators: 405\n",
      "{'learning_rate': 0.09506206039577023,\n",
      " 'max_depth': 5,\n",
      " 'max_features': 'log2',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 10,\n",
      " 'subsample': 0.8948388643386312}\n",
      "\n",
      "# training | log loss: 0.40%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.89%, AUC: 98.93%, accuracy: 96.42%\n",
      "\n",
      "2 seconds.\n"
     ]
    }
   ],
   "source": [
    "hb = Hyperband(get_params, try_params)\n",
    "results = hb.run(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/tictac.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'1.5':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_prop = 0.3\n",
    "n_0 = data[data['target'] == 0].shape[0]\n",
    "n_1 = data[data['target'] == 1].shape[0]\n",
    "train_0 = random.sample(range(n_0), int(n_0*train_prop))\n",
    "train_1 = random.sample(range(n_1), int(n_1*train_prop))\n",
    "test_0 = [i for i in range(n_0) if i not in train_0]\n",
    "test_1 = [i for i in range(n_1) if i not in train_1]\n",
    "train = pd.concat((data[data['target'] == 0].iloc[train_0,:], data[data['target'] == 1].iloc[train_1,:]))\n",
    "test = pd.concat((data[data['target'] == 0].iloc[test_0,:], data[data['target'] == 1].iloc[test_1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'x_train': train.drop('target', axis=1),\n",
    "    'y_train': train['target'],\n",
    "    'x_test': test.drop('target', axis=1),\n",
    "    'y_test': test['target']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** 243 configurations x 1.2 iterations each\n",
      "\n",
      "1 | Thu Oct 26 04:30:47 2017 | lowest loss so far: inf (run -1)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.33567544817114814,\n",
      " 'colsample_bylevel': 0.6287811345948335,\n",
      " 'colsample_bytree': 0.9425677765694029,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_lambda': 8.667336846078264}\n",
      "\n",
      "# training | log loss: 68.27%, AUC: 74.29%, accuracy: 53.50%\n",
      "# testing  | log loss: 68.58%, AUC: 73.32%, accuracy: 52.46%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "2 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.6858 (run 1)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.21032533458460032,\n",
      " 'colsample_bylevel': 0.5323532053238539,\n",
      " 'colsample_bytree': 0.6176629250498963,\n",
      " 'min_child_weight': 9}\n",
      "\n",
      "# training | log loss: 72.99%, AUC: 73.42%, accuracy: 34.62%\n",
      "# testing  | log loss: 74.12%, AUC: 63.39%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "3 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.6858 (run 1)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7898455732075181,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.005179897174721011,\n",
      " 'subsample': 0.7775694999932248}\n",
      "\n",
      "# training | log loss: 52.78%, AUC: 92.93%, accuracy: 83.22%\n",
      "# testing  | log loss: 55.21%, AUC: 87.51%, accuracy: 76.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "4 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.5521 (run 3)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6038238659359236,\n",
      " 'colsample_bylevel': 0.9126925240986197,\n",
      " 'learning_rate': 0.19367007748415568,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 4.319346134769293e-08,\n",
      " 'reg_lambda': 1.5912281395622878,\n",
      " 'subsample': 0.8727066498360705}\n",
      "\n",
      "# training | log loss: 34.78%, AUC: 99.43%, accuracy: 94.41%\n",
      "# testing  | log loss: 39.70%, AUC: 97.44%, accuracy: 89.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "5 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.680774234685352,\n",
      " 'gamma': 0.3277051994474869,\n",
      " 'learning_rate': 0.040424630810696256,\n",
      " 'min_child_weight': 6,\n",
      " 'scale_pos_weight': 6.256861073907913}\n",
      "\n",
      "# training | log loss: 63.61%, AUC: 83.54%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.96%, AUC: 81.50%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "6 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.19610994826347633,\n",
      " 'colsample_bytree': 0.6991861441233569,\n",
      " 'min_child_weight': 1,\n",
      " 'scale_pos_weight': 1.2929290177878994,\n",
      " 'subsample': 0.718983832745139}\n",
      "\n",
      "# training | log loss: 67.52%, AUC: 82.34%, accuracy: 48.95%\n",
      "# testing  | log loss: 69.31%, AUC: 76.44%, accuracy: 46.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "7 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5590605975226096,\n",
      " 'colsample_bytree': 0.9809241790598067,\n",
      " 'gamma': 0.5251930563149484,\n",
      " 'learning_rate': 0.03499182619191116,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 0.47549395458185095,\n",
      " 'reg_lambda': 6.732669922354743,\n",
      " 'scale_pos_weight': 3.409518208895121,\n",
      " 'subsample': 0.64059900855272}\n",
      "\n",
      "# training | log loss: 64.25%, AUC: 73.28%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.38%, AUC: 72.13%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "8 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7750153988584121,\n",
      " 'max_depth': 4,\n",
      " 'reg_alpha': 2.2276143030793972e-08,\n",
      " 'reg_lambda': 8.75768737031957,\n",
      " 'scale_pos_weight': 6.847838664739666,\n",
      " 'subsample': 0.7459159123699757}\n",
      "\n",
      "# training | log loss: 63.77%, AUC: 68.07%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.85%, AUC: 70.60%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "9 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3351592690731464,\n",
      " 'learning_rate': 0.07100164293252578,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 7.542472604342842,\n",
      " 'scale_pos_weight': 1.3058362816318567}\n",
      "\n",
      "# training | log loss: 69.74%, AUC: 72.45%, accuracy: 34.62%\n",
      "# testing  | log loss: 69.74%, AUC: 72.62%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "10 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3057206904082344,\n",
      " 'colsample_bylevel': 0.6958460472965042,\n",
      " 'gamma': 0.503644842846933,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 0.00033615225511458174,\n",
      " 'reg_lambda': 3.7807147127040173,\n",
      " 'scale_pos_weight': 6.540973773969994,\n",
      " 'subsample': 0.7205655626265162}\n",
      "\n",
      "# training | log loss: 64.93%, AUC: 64.71%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.90%, AUC: 68.20%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "11 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.0704427129808098,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 9.58646932283831,\n",
      " 'scale_pos_weight': 2.0046264087036474,\n",
      " 'subsample': 0.5276480563947705}\n",
      "\n",
      "# training | log loss: 63.79%, AUC: 74.05%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.21%, AUC: 72.02%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "12 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9305214031935931,\n",
      " 'reg_lambda': 8.140423106712392,\n",
      " 'scale_pos_weight': 5.649489170677325,\n",
      " 'subsample': 0.936624256497719}\n",
      "\n",
      "# training | log loss: 61.38%, AUC: 73.97%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.49%, AUC: 74.04%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "13 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.456698419430802,\n",
      " 'learning_rate': 0.16680274427701366,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 9.68622474212681}\n",
      "\n",
      "# training | log loss: 45.01%, AUC: 96.82%, accuracy: 77.62%\n",
      "# testing  | log loss: 52.21%, AUC: 89.73%, accuracy: 72.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "14 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.29264604163943175,\n",
      " 'colsample_bylevel': 0.6913849418371426,\n",
      " 'colsample_bytree': 0.6909157618380928,\n",
      " 'gamma': 0.4292079136257444,\n",
      " 'learning_rate': 0.07938166718478941,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.0018116579297466505,\n",
      " 'reg_lambda': 4.7978986354962085,\n",
      " 'scale_pos_weight': 0.5783053925862089,\n",
      " 'subsample': 0.7739048172254065}\n",
      "\n",
      "# training | log loss: 76.75%, AUC: 79.23%, accuracy: 34.62%\n",
      "# testing  | log loss: 76.85%, AUC: 78.16%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "15 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.25138103134411616,\n",
      " 'reg_lambda': 1.6593845850806417,\n",
      " 'scale_pos_weight': 2.366374773111373}\n",
      "\n",
      "# training | log loss: 54.95%, AUC: 85.83%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.31%, AUC: 82.37%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "16 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8213545733862508,\n",
      " 'colsample_bytree': 0.7774351447624301,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 3.9745443971551696e-07,\n",
      " 'reg_lambda': 6.657927162504635,\n",
      " 'scale_pos_weight': 9.028755060492603}\n",
      "\n",
      "# training | log loss: 64.58%, AUC: 66.53%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.76%, AUC: 68.82%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "17 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8159372290234267,\n",
      " 'colsample_bylevel': 0.7810492479489957,\n",
      " 'colsample_bytree': 0.6704872821214201,\n",
      " 'gamma': 0.4979449880234178,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.34436126456694244,\n",
      " 'reg_lambda': 1.1837894078186153,\n",
      " 'subsample': 0.5074268812087578}\n",
      "\n",
      "# training | log loss: 64.71%, AUC: 69.92%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.66%, AUC: 66.31%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "18 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5536583520485607,\n",
      " 'colsample_bylevel': 0.9748165943869673,\n",
      " 'learning_rate': 0.11184278799970034,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.9492131223812632,\n",
      " 'reg_lambda': 2.098674358524316,\n",
      " 'scale_pos_weight': 3.0109258846454754}\n",
      "\n",
      "# training | log loss: 55.44%, AUC: 82.77%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.80%, AUC: 80.03%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "19 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9134447824041024,\n",
      " 'gamma': 0.2780355079281964,\n",
      " 'learning_rate': 0.18960042474254205,\n",
      " 'reg_alpha': 0.0031403321497421553,\n",
      " 'reg_lambda': 7.38765419308214,\n",
      " 'scale_pos_weight': 0.8865184471742475}\n",
      "\n",
      "# training | log loss: 53.46%, AUC: 87.52%, accuracy: 80.42%\n",
      "# testing  | log loss: 55.95%, AUC: 82.76%, accuracy: 74.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "20 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8508365286805406,\n",
      " 'colsample_bylevel': 0.989467074810511,\n",
      " 'colsample_bytree': 0.9825545192173588,\n",
      " 'learning_rate': 0.01570608926633014,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 0.002279837788521286,\n",
      " 'reg_lambda': 4.391059905697367,\n",
      " 'scale_pos_weight': 5.566151687429015}\n",
      "\n",
      "# training | log loss: 75.71%, AUC: 85.42%, accuracy: 65.38%\n",
      "# testing  | log loss: 76.27%, AUC: 81.62%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "21 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9697050378837935,\n",
      " 'colsample_bytree': 0.7302799708530754,\n",
      " 'gamma': 0.06718402577293925,\n",
      " 'scale_pos_weight': 1.290729263743755}\n",
      "\n",
      "# training | log loss: 57.42%, AUC: 87.63%, accuracy: 75.17%\n",
      "# testing  | log loss: 59.80%, AUC: 78.91%, accuracy: 69.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "22 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.011765552855079096,\n",
      " 'reg_alpha': 9.915243632041702e-07,\n",
      " 'reg_lambda': 0.4347572267883614}\n",
      "\n",
      "# training | log loss: 66.79%, AUC: 82.85%, accuracy: 76.57%\n",
      "# testing  | log loss: 67.17%, AUC: 77.63%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "23 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5920519466659606,\n",
      " 'colsample_bytree': 0.5661157553124714,\n",
      " 'learning_rate': 0.19158927863048633,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 1.3764386659535268e-06,\n",
      " 'scale_pos_weight': 2.167014322540696}\n",
      "\n",
      "# training | log loss: 53.00%, AUC: 88.41%, accuracy: 70.28%\n",
      "# testing  | log loss: 58.87%, AUC: 74.01%, accuracy: 67.06%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "24 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.23701479851946916,\n",
      " 'gamma': 0.5843497404029224,\n",
      " 'learning_rate': 0.16952799247564668,\n",
      " 'reg_lambda': 2.611759301118198}\n",
      "\n",
      "# training | log loss: 55.82%, AUC: 91.14%, accuracy: 73.78%\n",
      "# testing  | log loss: 58.05%, AUC: 86.77%, accuracy: 70.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "25 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9978486956335506,\n",
      " 'gamma': 0.9799256810075381,\n",
      " 'scale_pos_weight': 2.0639311413727444,\n",
      " 'subsample': 0.6174570609601246}\n",
      "\n",
      "# training | log loss: 55.45%, AUC: 88.73%, accuracy: 75.87%\n",
      "# testing  | log loss: 57.77%, AUC: 83.11%, accuracy: 71.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "26 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1275410360994414,\n",
      " 'colsample_bylevel': 0.5815856149854609,\n",
      " 'colsample_bytree': 0.9648878729407239,\n",
      " 'max_depth': 8,\n",
      " 'reg_lambda': 2.5168329266370324,\n",
      " 'subsample': 0.8868883220823581}\n",
      "\n",
      "# training | log loss: 75.21%, AUC: 83.68%, accuracy: 34.62%\n",
      "# testing  | log loss: 75.84%, AUC: 82.10%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "27 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.188071528735541,\n",
      " 'colsample_bylevel': 0.7166252964834161,\n",
      " 'colsample_bytree': 0.6104654502669553,\n",
      " 'gamma': 0.2620452321415293,\n",
      " 'learning_rate': 0.1365543752667062,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 6.904998494717827,\n",
      " 'scale_pos_weight': 1.99746413427411,\n",
      " 'subsample': 0.8747551473184454}\n",
      "\n",
      "# training | log loss: 67.37%, AUC: 50.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.39%, AUC: 50.00%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "28 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.4891171059652598,\n",
      " 'colsample_bylevel': 0.8713582867470281,\n",
      " 'gamma': 0.3895675671596641,\n",
      " 'learning_rate': 0.028239686972414878,\n",
      " 'max_depth': 2,\n",
      " 'reg_alpha': 1.0981023299209018e-07,\n",
      " 'reg_lambda': 8.2110023363599}\n",
      "\n",
      "# training | log loss: 67.23%, AUC: 73.45%, accuracy: 67.83%\n",
      "# testing  | log loss: 67.42%, AUC: 73.33%, accuracy: 70.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "29 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.17526187147483882, 'reg_lambda': 1.3563685722513745}\n",
      "\n",
      "# training | log loss: 49.26%, AUC: 89.39%, accuracy: 82.52%\n",
      "# testing  | log loss: 52.00%, AUC: 85.35%, accuracy: 74.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "30 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8387271165817815,\n",
      " 'gamma': 0.6240828283424792,\n",
      " 'learning_rate': 0.03048156433408368,\n",
      " 'reg_alpha': 0.0007820962781985237}\n",
      "\n",
      "# training | log loss: 65.50%, AUC: 83.34%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.14%, AUC: 78.35%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "31 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8457626136571483,\n",
      " 'colsample_bylevel': 0.941063991254329,\n",
      " 'colsample_bytree': 0.88157458789953,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 1.855395659910499e-07,\n",
      " 'scale_pos_weight': 4.742885720239781}\n",
      "\n",
      "# training | log loss: 65.43%, AUC: 87.31%, accuracy: 65.38%\n",
      "# testing  | log loss: 69.88%, AUC: 82.60%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "32 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.603744183183063,\n",
      " 'gamma': 0.9975386841195969,\n",
      " 'learning_rate': 0.13139912393748293,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 1.8074432774547163e-09,\n",
      " 'reg_lambda': 1.6134056134947217,\n",
      " 'scale_pos_weight': 3.8002798006945797}\n",
      "\n",
      "# training | log loss: 54.09%, AUC: 88.81%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.97%, AUC: 84.08%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "33 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.13341982651676068,\n",
      " 'gamma': 0.1634311395451825,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6,\n",
      " 'scale_pos_weight': 9.526270022711012,\n",
      " 'subsample': 0.6617507671025091}\n",
      "\n",
      "# training | log loss: 66.03%, AUC: 73.29%, accuracy: 73.43%\n",
      "# testing  | log loss: 66.61%, AUC: 72.16%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "34 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7018261223034535,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 5.356237041214452e-10,\n",
      " 'scale_pos_weight': 4.150113248320051,\n",
      " 'subsample': 0.6924682074166524}\n",
      "\n",
      "# training | log loss: 60.90%, AUC: 84.64%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.60%, AUC: 76.09%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "35 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5936518727994256,\n",
      " 'gamma': 0.24028138693242151,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 0.004974056521604443,\n",
      " 'scale_pos_weight': 3.1758206172143653,\n",
      " 'subsample': 0.8494657037571602}\n",
      "\n",
      "# training | log loss: 57.56%, AUC: 88.23%, accuracy: 65.38%\n",
      "# testing  | log loss: 58.98%, AUC: 83.23%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "36 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.7537207541406201,\n",
      " 'learning_rate': 0.021520531788335153,\n",
      " 'min_child_weight': 1}\n",
      "\n",
      "# training | log loss: 65.10%, AUC: 82.35%, accuracy: 76.57%\n",
      "# testing  | log loss: 65.73%, AUC: 77.46%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "37 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5386222561588776,\n",
      " 'learning_rate': 0.08845666121475203,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_lambda': 1.6679326841505984,\n",
      " 'scale_pos_weight': 6.992947116364041,\n",
      " 'subsample': 0.5733492489117584}\n",
      "\n",
      "# training | log loss: 62.21%, AUC: 84.29%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.68%, AUC: 82.47%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "38 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.35238793823436554,\n",
      " 'gamma': 0.31706440387887536,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 1.9356907574772485e-10}\n",
      "\n",
      "# training | log loss: 60.90%, AUC: 84.64%, accuracy: 72.38%\n",
      "# testing  | log loss: 61.92%, AUC: 82.45%, accuracy: 72.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "39 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.591080360563649,\n",
      " 'colsample_bytree': 0.7232161473289204,\n",
      " 'learning_rate': 0.01921147037509935,\n",
      " 'max_depth': 3,\n",
      " 'reg_lambda': 5.716650172090366,\n",
      " 'scale_pos_weight': 3.266368350356646}\n",
      "\n",
      "# training | log loss: 63.52%, AUC: 72.61%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.84%, AUC: 74.06%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "40 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9841200653911778,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 1.1319482715079918e-05,\n",
      " 'reg_lambda': 1.3888018989177273,\n",
      " 'scale_pos_weight': 3.0536662660739844,\n",
      " 'subsample': 0.6907884806120264}\n",
      "\n",
      "# training | log loss: 58.96%, AUC: 82.12%, accuracy: 65.38%\n",
      "# testing  | log loss: 60.70%, AUC: 75.37%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "41 | Thu Oct 26 04:30:47 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6800254933379078,\n",
      " 'colsample_bylevel': 0.78670698198998,\n",
      " 'colsample_bytree': 0.8604502590855508,\n",
      " 'gamma': 0.5114068551523995,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 2.295810367082928e-10,\n",
      " 'scale_pos_weight': 6.230590217861569,\n",
      " 'subsample': 0.7459894364725348}\n",
      "\n",
      "# training | log loss: 64.12%, AUC: 79.65%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.74%, AUC: 75.86%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "42 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.6460338255609359,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 10}\n",
      "\n",
      "# training | log loss: 60.13%, AUC: 82.90%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.04%, AUC: 80.08%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "43 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5231861400453404,\n",
      " 'colsample_bytree': 0.6626209376661133,\n",
      " 'gamma': 0.11329962311965014,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 3.651641501704362e-09,\n",
      " 'reg_lambda': 0.9936432974862974}\n",
      "\n",
      "# training | log loss: 51.84%, AUC: 97.05%, accuracy: 86.36%\n",
      "# testing  | log loss: 56.12%, AUC: 88.66%, accuracy: 77.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "44 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.148179241090053,\n",
      " 'colsample_bylevel': 0.5083695381918429,\n",
      " 'gamma': 0.18859899716938855,\n",
      " 'learning_rate': 0.17727300527672635,\n",
      " 'min_child_weight': 4,\n",
      " 'scale_pos_weight': 1.2717600369898503,\n",
      " 'subsample': 0.9921810717761956}\n",
      "\n",
      "# training | log loss: 56.06%, AUC: 86.95%, accuracy: 79.72%\n",
      "# testing  | log loss: 58.39%, AUC: 82.56%, accuracy: 73.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "45 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.84789387004466,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 7,\n",
      " 'subsample': 0.6872826863982214}\n",
      "\n",
      "# training | log loss: 60.63%, AUC: 81.45%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.06%, AUC: 80.75%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "46 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5991697063037329,\n",
      " 'learning_rate': 0.06767737290272234,\n",
      " 'reg_lambda': 9.838767724472145,\n",
      " 'scale_pos_weight': 0.690497812661265,\n",
      " 'subsample': 0.8298425809821035}\n",
      "\n",
      "# training | log loss: 64.64%, AUC: 83.80%, accuracy: 72.03%\n",
      "# testing  | log loss: 65.26%, AUC: 78.87%, accuracy: 70.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "47 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7740490613148105,\n",
      " 'colsample_bytree': 0.856023648219723,\n",
      " 'learning_rate': 0.07575487158510982,\n",
      " 'reg_alpha': 1.435452506813921e-09,\n",
      " 'scale_pos_weight': 0.1428678497044101}\n",
      "\n",
      "# training | log loss: 68.22%, AUC: 80.06%, accuracy: 55.59%\n",
      "# testing  | log loss: 67.74%, AUC: 78.88%, accuracy: 57.97%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "48 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.20885706642773397,\n",
      " 'colsample_bylevel': 0.5943070388279799,\n",
      " 'gamma': 0.4357929356229341,\n",
      " 'learning_rate': 0.049096970968366016,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_lambda': 4.018776804773015,\n",
      " 'scale_pos_weight': 2.505588131585445,\n",
      " 'subsample': 0.5654419975983648}\n",
      "\n",
      "# training | log loss: 81.05%, AUC: 65.55%, accuracy: 34.62%\n",
      "# testing  | log loss: 81.14%, AUC: 56.68%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "49 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.61619239784906,\n",
      " 'colsample_bylevel': 0.6265461700979215,\n",
      " 'gamma': 0.7009643555530735,\n",
      " 'learning_rate': 0.012290487759257361,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 0.03701405671707634,\n",
      " 'reg_lambda': 0.8999754354238153}\n",
      "\n",
      "# training | log loss: 63.53%, AUC: 81.62%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.70%, AUC: 80.76%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "50 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.33245971124396423,\n",
      " 'colsample_bylevel': 0.733095994818369,\n",
      " 'colsample_bytree': 0.6504084146048545,\n",
      " 'min_child_weight': 2,\n",
      " 'scale_pos_weight': 0.3834680753517953,\n",
      " 'subsample': 0.831879827360638}\n",
      "\n",
      "# training | log loss: 71.58%, AUC: 86.03%, accuracy: 45.10%\n",
      "# testing  | log loss: 72.90%, AUC: 81.18%, accuracy: 42.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "51 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.7727931398654377,\n",
      " 'gamma': 0.8105299724688886,\n",
      " 'min_child_weight': 4,\n",
      " 'subsample': 0.5585782353475099}\n",
      "\n",
      "# training | log loss: 60.07%, AUC: 83.27%, accuracy: 76.57%\n",
      "# testing  | log loss: 61.09%, AUC: 79.08%, accuracy: 70.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "52 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5113026802198888,\n",
      " 'colsample_bylevel': 0.7262821851431096,\n",
      " 'gamma': 0.07444416308921997,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 4.3561150798818505e-08}\n",
      "\n",
      "# training | log loss: 50.33%, AUC: 96.72%, accuracy: 88.11%\n",
      "# testing  | log loss: 53.40%, AUC: 92.84%, accuracy: 81.82%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "53 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6833175479693611,\n",
      " 'reg_alpha': 7.436168702985275e-08,\n",
      " 'scale_pos_weight': 5.367990373767937}\n",
      "\n",
      "# training | log loss: 57.03%, AUC: 85.95%, accuracy: 72.73%\n",
      "# testing  | log loss: 59.28%, AUC: 82.97%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "54 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.43359499639893273,\n",
      " 'colsample_bylevel': 0.6299719413702991,\n",
      " 'colsample_bytree': 0.8549103834994787,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 7.99990071404941e-09,\n",
      " 'scale_pos_weight': 0.9249022255735391}\n",
      "\n",
      "# training | log loss: 60.27%, AUC: 85.96%, accuracy: 72.03%\n",
      "# testing  | log loss: 61.84%, AUC: 80.62%, accuracy: 66.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "55 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5682073971657562,\n",
      " 'colsample_bytree': 0.9386849160326098,\n",
      " 'learning_rate': 0.1332303945130079,\n",
      " 'max_depth': 3,\n",
      " 'reg_lambda': 6.391191651114294,\n",
      " 'scale_pos_weight': 8.22947615557534,\n",
      " 'subsample': 0.5808521517987372}\n",
      "\n",
      "# training | log loss: 65.51%, AUC: 76.57%, accuracy: 65.38%\n",
      "# testing  | log loss: 66.17%, AUC: 73.99%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "56 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7368615134269348,\n",
      " 'colsample_bylevel': 0.7535425721941528,\n",
      " 'colsample_bytree': 0.7195737460240303,\n",
      " 'gamma': 0.9765209625702386,\n",
      " 'learning_rate': 0.195436754972363,\n",
      " 'scale_pos_weight': 5.6056099562827875,\n",
      " 'subsample': 0.9221751200667616}\n",
      "\n",
      "# training | log loss: 62.43%, AUC: 88.56%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.86%, AUC: 84.71%, accuracy: 65.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "57 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.675455307784429,\n",
      " 'gamma': 0.451358833958166,\n",
      " 'learning_rate': 0.12474901938438772,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 1.638881456304343e-08,\n",
      " 'scale_pos_weight': 6.9102047312877595,\n",
      " 'subsample': 0.5165454157815021}\n",
      "\n",
      "# training | log loss: 57.54%, AUC: 81.63%, accuracy: 68.53%\n",
      "# testing  | log loss: 60.31%, AUC: 78.05%, accuracy: 65.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "58 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6700857395436024,\n",
      " 'colsample_bytree': 0.5433877816365627,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.0003842075440363449,\n",
      " 'reg_lambda': 8.270984289938166,\n",
      " 'scale_pos_weight': 4.209673572108498}\n",
      "\n",
      "# training | log loss: 64.07%, AUC: 78.07%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.82%, AUC: 71.63%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "59 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6725893347474801,\n",
      " 'colsample_bytree': 0.6793138645037046,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 4.492254372686206,\n",
      " 'subsample': 0.9079775403227915}\n",
      "\n",
      "# training | log loss: 60.50%, AUC: 81.85%, accuracy: 79.02%\n",
      "# testing  | log loss: 61.78%, AUC: 77.78%, accuracy: 73.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "60 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5573417241818385,\n",
      " 'gamma': 0.5640493098667669,\n",
      " 'learning_rate': 0.10066363258730485,\n",
      " 'max_depth': 7,\n",
      " 'reg_lambda': 4.815133760485877,\n",
      " 'scale_pos_weight': 9.24347962554065,\n",
      " 'subsample': 0.9082952068709662}\n",
      "\n",
      "# training | log loss: 62.17%, AUC: 68.45%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.66%, AUC: 69.66%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "61 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9981755862655967,\n",
      " 'gamma': 0.44976230295733133,\n",
      " 'learning_rate': 0.11593813595826681,\n",
      " 'reg_alpha': 0.00040422592171716654,\n",
      " 'reg_lambda': 0.4000947121237788,\n",
      " 'subsample': 0.619269940493826}\n",
      "\n",
      "# training | log loss: 54.20%, AUC: 91.33%, accuracy: 83.22%\n",
      "# testing  | log loss: 56.49%, AUC: 87.00%, accuracy: 78.24%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "62 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9685631751001437,\n",
      " 'gamma': 0.6150072674310296,\n",
      " 'reg_alpha': 0.0006196730651802148}\n",
      "\n",
      "# training | log loss: 55.24%, AUC: 86.62%, accuracy: 78.32%\n",
      "# testing  | log loss: 57.61%, AUC: 82.04%, accuracy: 73.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "63 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7708439000734213,\n",
      " 'colsample_bytree': 0.738715720146893,\n",
      " 'learning_rate': 0.1801298128400288,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 7,\n",
      " 'scale_pos_weight': 0.5015152882436018,\n",
      " 'subsample': 0.584573780430909}\n",
      "\n",
      "# training | log loss: 59.86%, AUC: 73.75%, accuracy: 70.98%\n",
      "# testing  | log loss: 60.14%, AUC: 75.04%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "64 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.47121689223510443,\n",
      " 'gamma': 0.7021976546534872,\n",
      " 'reg_alpha': 5.963924874353878e-08,\n",
      " 'reg_lambda': 7.063046011390596,\n",
      " 'scale_pos_weight': 4.549243009696246}\n",
      "\n",
      "# training | log loss: 59.89%, AUC: 67.15%, accuracy: 72.73%\n",
      "# testing  | log loss: 61.13%, AUC: 69.13%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "65 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5120281261418549,\n",
      " 'colsample_bytree': 0.5183665730682878,\n",
      " 'gamma': 0.27666449770941515,\n",
      " 'learning_rate': 0.08826336722273721,\n",
      " 'max_depth': 4,\n",
      " 'reg_alpha': 1.2483025027872138e-05,\n",
      " 'reg_lambda': 9.51742541547004}\n",
      "\n",
      "# training | log loss: 63.40%, AUC: 81.33%, accuracy: 72.03%\n",
      "# testing  | log loss: 64.47%, AUC: 71.31%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "66 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5393611783687096,\n",
      " 'colsample_bytree': 0.7384576356891304,\n",
      " 'max_depth': 9,\n",
      " 'reg_lambda': 2.2740695909113917}\n",
      "\n",
      "# training | log loss: 56.47%, AUC: 95.21%, accuracy: 83.57%\n",
      "# testing  | log loss: 58.58%, AUC: 91.08%, accuracy: 76.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "67 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6813221914026364,\n",
      " 'gamma': 0.33640016088587754,\n",
      " 'learning_rate': 0.06286298217376576,\n",
      " 'max_depth': 5,\n",
      " 'reg_lambda': 5.003894525145231,\n",
      " 'scale_pos_weight': 1.6986917614735075,\n",
      " 'subsample': 0.6561704563573457}\n",
      "\n",
      "# training | log loss: 60.04%, AUC: 92.23%, accuracy: 76.22%\n",
      "# testing  | log loss: 61.18%, AUC: 88.62%, accuracy: 71.09%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "68 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7619624598977952,\n",
      " 'colsample_bytree': 0.9810660179429012,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 3.891601614828777}\n",
      "\n",
      "# training | log loss: 51.04%, AUC: 95.71%, accuracy: 80.42%\n",
      "# testing  | log loss: 53.09%, AUC: 91.32%, accuracy: 79.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "69 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.41958409352769566,\n",
      " 'colsample_bytree': 0.6013374044889424,\n",
      " 'reg_lambda': 4.011311775471425}\n",
      "\n",
      "# training | log loss: 60.92%, AUC: 87.09%, accuracy: 75.52%\n",
      "# testing  | log loss: 62.64%, AUC: 82.15%, accuracy: 72.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "70 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6549002572753695,\n",
      " 'colsample_bytree': 0.8009806047623019,\n",
      " 'learning_rate': 0.09558881171990298,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 1.0699682460506518e-10,\n",
      " 'reg_lambda': 5.421137054306514,\n",
      " 'scale_pos_weight': 6.1210184147498286,\n",
      " 'subsample': 0.6088611425699013}\n",
      "\n",
      "# training | log loss: 64.68%, AUC: 75.57%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.58%, AUC: 74.17%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "71 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3644217306441927,\n",
      " 'colsample_bylevel': 0.637714716393913,\n",
      " 'colsample_bytree': 0.9841934886181919,\n",
      " 'gamma': 0.6135377168890187,\n",
      " 'learning_rate': 0.13661884800208296,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 1.2436548982224541e-08,\n",
      " 'reg_lambda': 4.698740770608061,\n",
      " 'scale_pos_weight': 6.971155152220466,\n",
      " 'subsample': 0.6337110397591565}\n",
      "\n",
      "# training | log loss: 63.13%, AUC: 72.52%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.60%, AUC: 70.54%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "72 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'min_child_weight': 1,\n",
      " 'reg_lambda': 5.680403762911145,\n",
      " 'scale_pos_weight': 6.924889778880553,\n",
      " 'subsample': 0.74383038645125}\n",
      "\n",
      "# training | log loss: 62.77%, AUC: 68.68%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.05%, AUC: 70.99%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "73 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5420459166908425,\n",
      " 'gamma': 0.010126317533560858,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 4.856923138710331e-06,\n",
      " 'scale_pos_weight': 0.10258945656375738}\n",
      "\n",
      "# training | log loss: 77.64%, AUC: 70.47%, accuracy: 34.62%\n",
      "# testing  | log loss: 77.25%, AUC: 72.13%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "74 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7001712627920197,\n",
      " 'colsample_bylevel': 0.8454734509600338,\n",
      " 'colsample_bytree': 0.5209235660844403,\n",
      " 'learning_rate': 0.03778173348671473,\n",
      " 'max_depth': 4,\n",
      " 'reg_alpha': 1.2382778708724731e-05,\n",
      " 'scale_pos_weight': 8.299744115247716,\n",
      " 'subsample': 0.726028281329478}\n",
      "\n",
      "# training | log loss: 64.60%, AUC: 82.88%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.46%, AUC: 74.93%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "75 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5777174461906869,\n",
      " 'colsample_bytree': 0.7913208027619905,\n",
      " 'gamma': 0.8724127061974302,\n",
      " 'learning_rate': 0.19584124144251125,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 5.046195583774196e-10}\n",
      "\n",
      "# training | log loss: 42.23%, AUC: 97.78%, accuracy: 91.26%\n",
      "# testing  | log loss: 47.58%, AUC: 91.98%, accuracy: 84.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "76 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5322200822074987,\n",
      " 'colsample_bytree': 0.955030550047298,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 7.284976367173886e-10,\n",
      " 'reg_lambda': 8.172768684916607,\n",
      " 'scale_pos_weight': 3.936680018923548,\n",
      " 'subsample': 0.6972701955707636}\n",
      "\n",
      "# training | log loss: 61.38%, AUC: 73.89%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.18%, AUC: 74.32%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "77 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7732049013669928,\n",
      " 'learning_rate': 0.06718514756655851,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 8.636717649977388}\n",
      "\n",
      "# training | log loss: 60.22%, AUC: 96.88%, accuracy: 89.16%\n",
      "# testing  | log loss: 61.34%, AUC: 92.91%, accuracy: 83.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "78 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.6913542347382062,\n",
      " 'max_depth': 10,\n",
      " 'reg_alpha': 7.371418880814282e-09,\n",
      " 'reg_lambda': 2.5060816032488917,\n",
      " 'scale_pos_weight': 5.465759395399685,\n",
      " 'subsample': 0.6466522758319695}\n",
      "\n",
      "# training | log loss: 60.25%, AUC: 73.53%, accuracy: 65.73%\n",
      "# testing  | log loss: 61.32%, AUC: 74.76%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "79 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.932976925330389,\n",
      " 'colsample_bytree': 0.8448968996227626,\n",
      " 'learning_rate': 0.08584593307836327,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 3.089649703078951}\n",
      "\n",
      "# training | log loss: 56.82%, AUC: 86.90%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.96%, AUC: 82.39%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "80 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 3, 'min_child_weight': 5, 'reg_lambda': 3.4486315476430485}\n",
      "\n",
      "# training | log loss: 57.14%, AUC: 84.89%, accuracy: 75.87%\n",
      "# testing  | log loss: 58.64%, AUC: 81.22%, accuracy: 73.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "81 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.971659299922879,\n",
      " 'gamma': 0.4954291803400268,\n",
      " 'max_depth': 4,\n",
      " 'subsample': 0.632685101381262}\n",
      "\n",
      "# training | log loss: 52.62%, AUC: 96.05%, accuracy: 90.21%\n",
      "# testing  | log loss: 55.84%, AUC: 91.06%, accuracy: 83.01%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "82 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.34379317864100845,\n",
      " 'colsample_bylevel': 0.5790949556261807,\n",
      " 'colsample_bytree': 0.5783083628801295,\n",
      " 'learning_rate': 0.15452021632167656,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 5,\n",
      " 'scale_pos_weight': 4.326436492173106,\n",
      " 'subsample': 0.5834074399868703}\n",
      "\n",
      "# training | log loss: 60.91%, AUC: 79.48%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.69%, AUC: 73.68%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "83 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6096820488397859,\n",
      " 'colsample_bylevel': 0.967449982500649,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 9.795186819113866,\n",
      " 'scale_pos_weight': 4.127371490720042,\n",
      " 'subsample': 0.9883556485176215}\n",
      "\n",
      "# training | log loss: 59.08%, AUC: 80.36%, accuracy: 72.03%\n",
      "# testing  | log loss: 60.49%, AUC: 80.08%, accuracy: 69.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "84 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.2178633687548427,\n",
      " 'colsample_bylevel': 0.6642581611118783,\n",
      " 'colsample_bytree': 0.7349745921964088,\n",
      " 'gamma': 0.7249227686457121,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2,\n",
      " 'subsample': 0.6332765019734425}\n",
      "\n",
      "# training | log loss: 69.81%, AUC: 80.97%, accuracy: 41.96%\n",
      "# testing  | log loss: 71.13%, AUC: 75.64%, accuracy: 40.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "85 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.36729695209121405,\n",
      " 'gamma': 0.6612604648241419,\n",
      " 'learning_rate': 0.08629205067561249,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 1.7784964835184819e-09,\n",
      " 'reg_lambda': 3.799867250977016,\n",
      " 'scale_pos_weight': 6.912427107023398,\n",
      " 'subsample': 0.8730391999491409}\n",
      "\n",
      "# training | log loss: 64.05%, AUC: 67.15%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.43%, AUC: 69.13%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "86 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8735342296042882,\n",
      " 'scale_pos_weight': 9.439817548424625,\n",
      " 'subsample': 0.6655825349475998}\n",
      "\n",
      "# training | log loss: 58.87%, AUC: 80.95%, accuracy: 67.13%\n",
      "# testing  | log loss: 61.13%, AUC: 78.35%, accuracy: 65.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "87 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.7448019433726507,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 0.1033609725685377,\n",
      " 'reg_lambda': 2.5174865613394424,\n",
      " 'scale_pos_weight': 5.817098898913454}\n",
      "\n",
      "# training | log loss: 62.26%, AUC: 71.95%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.92%, AUC: 71.54%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "88 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.03785791614932413,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5,\n",
      " 'scale_pos_weight': 9.689115357007898,\n",
      " 'subsample': 0.8076117872845676}\n",
      "\n",
      "# training | log loss: 64.13%, AUC: 76.91%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.51%, AUC: 73.77%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "89 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5733228772630871,\n",
      " 'colsample_bylevel': 0.9977312032580481,\n",
      " 'colsample_bytree': 0.9409611390045189,\n",
      " 'learning_rate': 0.11249968584646895,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 3.056729234388235e-06,\n",
      " 'reg_lambda': 0.7092805899117693,\n",
      " 'subsample': 0.8670359987458345}\n",
      "\n",
      "# training | log loss: 56.57%, AUC: 83.90%, accuracy: 73.43%\n",
      "# testing  | log loss: 58.18%, AUC: 81.95%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "90 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1420254436123287,\n",
      " 'colsample_bylevel': 0.7961465942390266,\n",
      " 'learning_rate': 0.027877504745267567,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.00025917259179010136,\n",
      " 'reg_lambda': 2.8304843381604563}\n",
      "\n",
      "# training | log loss: 107.22%, AUC: 70.47%, accuracy: 34.62%\n",
      "# testing  | log loss: 106.71%, AUC: 72.13%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "91 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.022185609774200095,\n",
      " 'reg_lambda': 1.6624414837546277,\n",
      " 'subsample': 0.9944635547288765}\n",
      "\n",
      "# training | log loss: 65.18%, AUC: 82.35%, accuracy: 76.57%\n",
      "# testing  | log loss: 65.78%, AUC: 77.46%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "92 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.692784839087586,\n",
      " 'gamma': 0.1335444581485956,\n",
      " 'learning_rate': 0.025967317175151515,\n",
      " 'max_depth': 4,\n",
      " 'reg_alpha': 0.0026215466596898533,\n",
      " 'scale_pos_weight': 5.031806583188005,\n",
      " 'subsample': 0.9886444310813751}\n",
      "\n",
      "# training | log loss: 59.07%, AUC: 92.41%, accuracy: 65.38%\n",
      "# testing  | log loss: 60.65%, AUC: 86.19%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "93 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7739418899658518,\n",
      " 'colsample_bytree': 0.8437222931157657,\n",
      " 'gamma': 0.48788830497429114,\n",
      " 'reg_alpha': 6.536250774959184e-08,\n",
      " 'reg_lambda': 4.163964333195748}\n",
      "\n",
      "# training | log loss: 58.62%, AUC: 85.40%, accuracy: 75.52%\n",
      "# testing  | log loss: 60.11%, AUC: 80.19%, accuracy: 70.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "94 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.8036267766238064,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 0.00027289997450528057,\n",
      " 'reg_lambda': 3.6061822230420137}\n",
      "\n",
      "# training | log loss: 58.48%, AUC: 83.26%, accuracy: 71.68%\n",
      "# testing  | log loss: 59.46%, AUC: 80.50%, accuracy: 66.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "95 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7613109548097081,\n",
      " 'learning_rate': 0.1734103330345164,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 3.0067872786956198e-05,\n",
      " 'reg_lambda': 9.376597446028025,\n",
      " 'subsample': 0.7737373903262383}\n",
      "\n",
      "# training | log loss: 57.52%, AUC: 85.51%, accuracy: 80.77%\n",
      "# testing  | log loss: 58.96%, AUC: 82.67%, accuracy: 76.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "96 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 4,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 9.4943851725337,\n",
      " 'subsample': 0.8845733318362934}\n",
      "\n",
      "# training | log loss: 60.43%, AUC: 85.25%, accuracy: 73.78%\n",
      "# testing  | log loss: 61.42%, AUC: 80.99%, accuracy: 70.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "97 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.12535926227159502,\n",
      " 'colsample_bytree': 0.5994384171883469,\n",
      " 'gamma': 0.015831972149909723,\n",
      " 'learning_rate': 0.18712026294307543,\n",
      " 'max_depth': 7,\n",
      " 'reg_lambda': 9.160768575892106,\n",
      " 'scale_pos_weight': 4.866884049671453,\n",
      " 'subsample': 0.6540630479237246}\n",
      "\n",
      "# training | log loss: 64.70%, AUC: 50.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.79%, AUC: 50.00%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "98 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7067354787007608,\n",
      " 'colsample_bylevel': 0.9183479691501358,\n",
      " 'colsample_bytree': 0.5162812196151187,\n",
      " 'gamma': 0.49831893595708665,\n",
      " 'learning_rate': 0.12462218339599088,\n",
      " 'max_depth': 3}\n",
      "\n",
      "# training | log loss: 57.93%, AUC: 85.86%, accuracy: 65.73%\n",
      "# testing  | log loss: 59.73%, AUC: 78.96%, accuracy: 65.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "99 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 42.19%, AUC: 98.66%, accuracy: 90.56%\n",
      "# testing  | log loss: 45.10%, AUC: 96.03%, accuracy: 88.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "100 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5663079229907911,\n",
      " 'colsample_bylevel': 0.7262871771760104,\n",
      " 'reg_lambda': 9.86932990162833,\n",
      " 'subsample': 0.6744441981375257}\n",
      "\n",
      "# training | log loss: 60.61%, AUC: 84.85%, accuracy: 65.38%\n",
      "# testing  | log loss: 61.55%, AUC: 81.08%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "101 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.24170493316609207,\n",
      " 'gamma': 0.6230312500866276,\n",
      " 'learning_rate': 0.10298166329568471,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 0.8312648902952859,\n",
      " 'subsample': 0.690957726860491}\n",
      "\n",
      "# training | log loss: 66.76%, AUC: 85.02%, accuracy: 55.94%\n",
      "# testing  | log loss: 67.94%, AUC: 82.13%, accuracy: 50.97%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "102 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.10059672079180144,\n",
      " 'colsample_bylevel': 0.584721902795804,\n",
      " 'colsample_bytree': 0.5086172762312551,\n",
      " 'scale_pos_weight': 9.104437169841823}\n",
      "\n",
      "# training | log loss: 67.82%, AUC: 50.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.83%, AUC: 50.00%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "103 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9556344402730059,\n",
      " 'colsample_bytree': 0.507584701250676,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 6.788878724839042e-05,\n",
      " 'reg_lambda': 3.296918710827441,\n",
      " 'subsample': 0.7240418456607745}\n",
      "\n",
      "# training | log loss: 60.88%, AUC: 82.84%, accuracy: 74.48%\n",
      "# testing  | log loss: 62.20%, AUC: 78.29%, accuracy: 70.64%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "104 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5668431921560755,\n",
      " 'gamma': 0.17986463582112366,\n",
      " 'learning_rate': 0.04758569939207717,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 0.8072766719451299,\n",
      " 'scale_pos_weight': 4.254462195431029,\n",
      " 'subsample': 0.7497848536481669}\n",
      "\n",
      "# training | log loss: 62.92%, AUC: 83.60%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.57%, AUC: 78.51%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "105 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8043503553771844, 'max_depth': 4}\n",
      "\n",
      "# training | log loss: 49.31%, AUC: 95.99%, accuracy: 88.81%\n",
      "# testing  | log loss: 52.66%, AUC: 92.09%, accuracy: 82.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "106 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.37209383894678605,\n",
      " 'gamma': 0.8724676310373436,\n",
      " 'learning_rate': 0.1118874573094324,\n",
      " 'reg_lambda': 9.176667888917725,\n",
      " 'scale_pos_weight': 2.4382988522249187,\n",
      " 'subsample': 0.7764062217809352}\n",
      "\n",
      "# training | log loss: 61.80%, AUC: 81.81%, accuracy: 72.73%\n",
      "# testing  | log loss: 62.60%, AUC: 78.72%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "107 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6768717664054877,\n",
      " 'reg_alpha': 0.46341921708206535,\n",
      " 'reg_lambda': 8.637519478156712,\n",
      " 'scale_pos_weight': 5.394407028503751}\n",
      "\n",
      "# training | log loss: 62.99%, AUC: 67.15%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.46%, AUC: 69.11%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "108 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8174186003253705,\n",
      " 'colsample_bytree': 0.5715886433168647,\n",
      " 'gamma': 0.4710597299002043,\n",
      " 'reg_alpha': 0.00011234544506176456,\n",
      " 'reg_lambda': 4.119748120900596}\n",
      "\n",
      "# training | log loss: 60.13%, AUC: 85.52%, accuracy: 75.87%\n",
      "# testing  | log loss: 61.98%, AUC: 77.79%, accuracy: 70.79%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "109 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.11338573582141179,\n",
      " 'gamma': 0.7834847156815874,\n",
      " 'learning_rate': 0.17357223411818085,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 0.06812778326555435,\n",
      " 'reg_lambda': 4.728322193526698}\n",
      "\n",
      "# training | log loss: 57.69%, AUC: 96.58%, accuracy: 75.52%\n",
      "# testing  | log loss: 60.11%, AUC: 92.96%, accuracy: 72.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "110 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.5752137146864645,\n",
      " 'gamma': 0.5731065365574965,\n",
      " 'min_child_weight': 4,\n",
      " 'scale_pos_weight': 7.203530379944765}\n",
      "\n",
      "# training | log loss: 59.02%, AUC: 83.39%, accuracy: 72.73%\n",
      "# testing  | log loss: 61.15%, AUC: 78.44%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "111 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8819826592499596,\n",
      " 'colsample_bylevel': 0.8881726892084983,\n",
      " 'learning_rate': 0.0599463143388135,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.00018730317417368572,\n",
      " 'reg_lambda': 3.1670151124836434,\n",
      " 'scale_pos_weight': 9.260745660516788,\n",
      " 'subsample': 0.7491293133372303}\n",
      "\n",
      "# training | log loss: 80.83%, AUC: 83.74%, accuracy: 65.38%\n",
      "# testing  | log loss: 82.24%, AUC: 79.62%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "112 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.517831828564604,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 0.18594717573020467,\n",
      " 'reg_lambda': 5.396958195028692,\n",
      " 'scale_pos_weight': 4.575635253995775}\n",
      "\n",
      "# training | log loss: 61.49%, AUC: 73.70%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.80%, AUC: 69.71%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "113 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1579805085469478,\n",
      " 'colsample_bytree': 0.9129416361903196,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 3.1293333633813757e-10,\n",
      " 'reg_lambda': 0.2682332401760261}\n",
      "\n",
      "# training | log loss: 66.90%, AUC: 89.39%, accuracy: 54.55%\n",
      "# testing  | log loss: 68.60%, AUC: 83.78%, accuracy: 52.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "114 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5470905243853916,\n",
      " 'colsample_bylevel': 0.7014212344010553,\n",
      " 'gamma': 0.6169433797781145,\n",
      " 'learning_rate': 0.011255269061868495,\n",
      " 'reg_alpha': 1.260511729172339e-09,\n",
      " 'subsample': 0.9273858039635337}\n",
      "\n",
      "# training | log loss: 65.18%, AUC: 84.64%, accuracy: 65.38%\n",
      "# testing  | log loss: 65.50%, AUC: 79.60%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "115 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5851841401028498,\n",
      " 'learning_rate': 0.06815503287278157,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 1.842129711029562e-08,\n",
      " 'reg_lambda': 8.797771906262025}\n",
      "\n",
      "# training | log loss: 59.51%, AUC: 83.44%, accuracy: 65.38%\n",
      "# testing  | log loss: 60.62%, AUC: 79.56%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "116 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9416697828315144,\n",
      " 'gamma': 0.04373116085380224,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 6.322767531985038e-05,\n",
      " 'reg_lambda': 4.67971017879393,\n",
      " 'scale_pos_weight': 3.443447525980241,\n",
      " 'subsample': 0.5903631984262014}\n",
      "\n",
      "# training | log loss: 61.73%, AUC: 74.54%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.69%, AUC: 72.49%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "117 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7179469599897778,\n",
      " 'gamma': 0.480621024940986,\n",
      " 'learning_rate': 0.16337681307900698,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 3.3298698690019415e-09,\n",
      " 'reg_lambda': 3.905974270599137}\n",
      "\n",
      "# training | log loss: 46.87%, AUC: 93.97%, accuracy: 77.62%\n",
      "# testing  | log loss: 50.70%, AUC: 88.90%, accuracy: 72.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "118 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7963286086467167,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 4.751486756650194e-06,\n",
      " 'reg_lambda': 1.13546172286901,\n",
      " 'subsample': 0.8415621755378428}\n",
      "\n",
      "# training | log loss: 46.75%, AUC: 98.22%, accuracy: 65.38%\n",
      "# testing  | log loss: 50.06%, AUC: 96.69%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "119 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7625514578288017,\n",
      " 'colsample_bytree': 0.9178801919637061,\n",
      " 'gamma': 0.532750285659207,\n",
      " 'reg_alpha': 1.693351413597292e-07}\n",
      "\n",
      "# training | log loss: 56.20%, AUC: 88.32%, accuracy: 76.57%\n",
      "# testing  | log loss: 58.01%, AUC: 82.95%, accuracy: 73.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "120 | Thu Oct 26 04:30:48 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.5148630588244002,\n",
      " 'learning_rate': 0.1171239161985604,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_lambda': 7.096044566817256,\n",
      " 'scale_pos_weight': 4.726323780424985}\n",
      "\n",
      "# training | log loss: 62.05%, AUC: 72.05%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.32%, AUC: 68.56%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "121 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'min_child_weight': 7, 'subsample': 0.5594501525809006}\n",
      "\n",
      "# training | log loss: 61.00%, AUC: 81.50%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.49%, AUC: 79.91%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "122 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3798523831040156, 'max_depth': 6}\n",
      "\n",
      "# training | log loss: 45.60%, AUC: 98.84%, accuracy: 93.36%\n",
      "# testing  | log loss: 47.46%, AUC: 98.00%, accuracy: 90.46%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "123 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8666102967218439,\n",
      " 'colsample_bytree': 0.8330801478209799,\n",
      " 'learning_rate': 0.05284424247709347,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 0.003315625947868575,\n",
      " 'scale_pos_weight': 2.71223724005082,\n",
      " 'subsample': 0.93804061815038}\n",
      "\n",
      "# training | log loss: 62.04%, AUC: 82.70%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.74%, AUC: 79.30%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "124 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5589795716360969,\n",
      " 'colsample_bytree': 0.5656800810406213,\n",
      " 'gamma': 0.7455151739511904,\n",
      " 'learning_rate': 0.08813414514243938,\n",
      " 'min_child_weight': 2,\n",
      " 'scale_pos_weight': 6.815832368855435,\n",
      " 'subsample': 0.6733228089745803}\n",
      "\n",
      "# training | log loss: 60.91%, AUC: 81.71%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.44%, AUC: 77.90%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "125 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.6833256584860847,\n",
      " 'gamma': 0.5238581649620367,\n",
      " 'learning_rate': 0.08868452421171762,\n",
      " 'reg_alpha': 5.771181461148983e-09,\n",
      " 'reg_lambda': 2.8790100697166645,\n",
      " 'scale_pos_weight': 5.982279345990257,\n",
      " 'subsample': 0.8032503503137263}\n",
      "\n",
      "# training | log loss: 61.16%, AUC: 73.25%, accuracy: 66.78%\n",
      "# testing  | log loss: 62.29%, AUC: 72.59%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "126 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7815056417494192,\n",
      " 'colsample_bylevel': 0.7836876916623623,\n",
      " 'colsample_bytree': 0.9023854919137722,\n",
      " 'learning_rate': 0.13014150218131532,\n",
      " 'reg_lambda': 3.7350689586312904,\n",
      " 'scale_pos_weight': 5.850852526244734,\n",
      " 'subsample': 0.8667561004230115}\n",
      "\n",
      "# training | log loss: 64.91%, AUC: 86.56%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.22%, AUC: 84.37%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "127 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7941672690269314,\n",
      " 'colsample_bylevel': 0.8211776468956117,\n",
      " 'learning_rate': 0.06536490780377958,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 0.0005298812849253648,\n",
      " 'reg_lambda': 7.288688095578762}\n",
      "\n",
      "# training | log loss: 61.92%, AUC: 81.50%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.23%, AUC: 81.48%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "128 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.7311349743333434,\n",
      " 'reg_lambda': 5.926403989101486,\n",
      " 'scale_pos_weight': 1.7927312523261}\n",
      "\n",
      "# training | log loss: 56.95%, AUC: 85.26%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.51%, AUC: 82.22%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "129 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.21192796875183603,\n",
      " 'colsample_bytree': 0.8955437166901223,\n",
      " 'gamma': 0.08643768206181857,\n",
      " 'learning_rate': 0.1387261416281383,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 1.7063586584660046e-07}\n",
      "\n",
      "# training | log loss: 59.88%, AUC: 86.74%, accuracy: 74.48%\n",
      "# testing  | log loss: 61.74%, AUC: 82.32%, accuracy: 74.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "130 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8244580358233088,\n",
      " 'colsample_bytree': 0.7096156514585483,\n",
      " 'learning_rate': 0.09546842064377069,\n",
      " 'max_depth': 9,\n",
      " 'subsample': 0.5542256804844368}\n",
      "\n",
      "# training | log loss: 56.68%, AUC: 89.97%, accuracy: 85.31%\n",
      "# testing  | log loss: 60.35%, AUC: 78.51%, accuracy: 76.01%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "131 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8324726821585812,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 4.871354923609551e-07,\n",
      " 'scale_pos_weight': 2.649572288768033}\n",
      "\n",
      "# training | log loss: 41.96%, AUC: 98.77%, accuracy: 72.73%\n",
      "# testing  | log loss: 46.57%, AUC: 96.58%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "132 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.743550589435233,\n",
      " 'colsample_bytree': 0.6739971239869498,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 8.616571202513311e-07,\n",
      " 'scale_pos_weight': 0.6446529587618857}\n",
      "\n",
      "# training | log loss: 54.77%, AUC: 97.20%, accuracy: 89.86%\n",
      "# testing  | log loss: 58.20%, AUC: 91.20%, accuracy: 82.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "133 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7458910496701082,\n",
      " 'colsample_bylevel': 0.7166355994076681,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.07050721754965068}\n",
      "\n",
      "# training | log loss: 58.15%, AUC: 79.91%, accuracy: 65.38%\n",
      "# testing  | log loss: 59.15%, AUC: 79.56%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "134 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.715185309193016,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 3.3152632137913076,\n",
      " 'subsample': 0.6981198459610889}\n",
      "\n",
      "# training | log loss: 61.62%, AUC: 78.80%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.84%, AUC: 78.70%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "135 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3970 (run 4)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.8955964486499088,\n",
      " 'learning_rate': 0.1822287061793478,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 5.151870309734203e-06}\n",
      "\n",
      "# training | log loss: 33.51%, AUC: 99.45%, accuracy: 96.50%\n",
      "# testing  | log loss: 37.08%, AUC: 98.93%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "136 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9757562340360666,\n",
      " 'colsample_bytree': 0.5229949046919793,\n",
      " 'gamma': 0.5099818817923082,\n",
      " 'scale_pos_weight': 9.088874330345853}\n",
      "\n",
      "# training | log loss: 61.59%, AUC: 80.24%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.81%, AUC: 76.39%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "137 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.698227075651539,\n",
      " 'colsample_bytree': 0.5609119272091825,\n",
      " 'gamma': 0.9553926189002803,\n",
      " 'max_depth': 3,\n",
      " 'reg_lambda': 6.636829119927822}\n",
      "\n",
      "# training | log loss: 61.37%, AUC: 82.29%, accuracy: 72.73%\n",
      "# testing  | log loss: 62.72%, AUC: 77.33%, accuracy: 69.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "138 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7261618570651576,\n",
      " 'reg_alpha': 0.07908296482856761,\n",
      " 'reg_lambda': 8.31501257794639,\n",
      " 'scale_pos_weight': 7.163634892386902}\n",
      "\n",
      "# training | log loss: 63.15%, AUC: 67.15%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.69%, AUC: 69.11%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "139 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3661645557587426,\n",
      " 'gamma': 0.45031377991236576,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 1.3062672539931609e-05,\n",
      " 'reg_lambda': 3.617740190976021}\n",
      "\n",
      "# training | log loss: 53.48%, AUC: 97.94%, accuracy: 76.92%\n",
      "# testing  | log loss: 55.21%, AUC: 97.38%, accuracy: 71.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "140 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5411142087511054,\n",
      " 'gamma': 0.5694531124537084,\n",
      " 'learning_rate': 0.04845075591478361,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 0.059267805525848614,\n",
      " 'reg_lambda': 7.483393839428104,\n",
      " 'scale_pos_weight': 8.674999134188663}\n",
      "\n",
      "# training | log loss: 64.88%, AUC: 50.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.93%, AUC: 50.00%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "141 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.572673625959155,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 2.356304897780655}\n",
      "\n",
      "# training | log loss: 59.34%, AUC: 83.32%, accuracy: 77.62%\n",
      "# testing  | log loss: 60.83%, AUC: 78.43%, accuracy: 70.64%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "142 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9479239700346893,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 5.133347471643192}\n",
      "\n",
      "# training | log loss: 52.32%, AUC: 99.17%, accuracy: 93.01%\n",
      "# testing  | log loss: 53.99%, AUC: 99.18%, accuracy: 91.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "143 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9145080077905342,\n",
      " 'colsample_bytree': 0.9087944374854828,\n",
      " 'learning_rate': 0.04939614128844285,\n",
      " 'subsample': 0.8287848341073285}\n",
      "\n",
      "# training | log loss: 61.59%, AUC: 86.83%, accuracy: 75.87%\n",
      "# testing  | log loss: 62.44%, AUC: 84.44%, accuracy: 72.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "144 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1960297296423856,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 0.0007481377111748302,\n",
      " 'reg_lambda': 4.473200876926737,\n",
      " 'scale_pos_weight': 1.9614193399051154}\n",
      "\n",
      "# training | log loss: 66.18%, AUC: 82.69%, accuracy: 34.62%\n",
      "# testing  | log loss: 67.07%, AUC: 82.21%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "145 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.31552384536770833,\n",
      " 'colsample_bylevel': 0.7610974263744591,\n",
      " 'colsample_bytree': 0.7062767971655837,\n",
      " 'scale_pos_weight': 2.549934660703572,\n",
      " 'subsample': 0.688339510479582}\n",
      "\n",
      "# training | log loss: 61.51%, AUC: 84.28%, accuracy: 78.67%\n",
      "# testing  | log loss: 62.79%, AUC: 80.47%, accuracy: 73.32%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "146 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.8425459455907589,\n",
      " 'colsample_bytree': 0.9809727432998179,\n",
      " 'learning_rate': 0.03333242006219655,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 1.0210437865399776e-07,\n",
      " 'reg_lambda': 7.941430694445771}\n",
      "\n",
      "# training | log loss: 66.29%, AUC: 77.93%, accuracy: 70.98%\n",
      "# testing  | log loss: 66.32%, AUC: 77.49%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "147 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.6255292873810094,\n",
      " 'gamma': 0.3974817006500798,\n",
      " 'reg_alpha': 1.0374076509189266e-06,\n",
      " 'subsample': 0.8499235857290247}\n",
      "\n",
      "# training | log loss: 57.65%, AUC: 90.01%, accuracy: 80.42%\n",
      "# testing  | log loss: 59.77%, AUC: 85.24%, accuracy: 73.32%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "148 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.8141073684912563,\n",
      " 'gamma': 0.36743830513100406,\n",
      " 'learning_rate': 0.1196752531948293,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 1.8786485941323767}\n",
      "\n",
      "# training | log loss: 54.94%, AUC: 88.61%, accuracy: 80.07%\n",
      "# testing  | log loss: 57.24%, AUC: 84.11%, accuracy: 73.32%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "149 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7772710214498053,\n",
      " 'colsample_bylevel': 0.9115114142679617,\n",
      " 'colsample_bytree': 0.6286212318358056,\n",
      " 'gamma': 0.7563990692128088,\n",
      " 'learning_rate': 0.17803434037067914,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 0.00027769952471964427,\n",
      " 'scale_pos_weight': 6.396275081168672}\n",
      "\n",
      "# training | log loss: 70.07%, AUC: 85.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 73.55%, AUC: 75.75%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "150 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.8609618451883119}\n",
      "\n",
      "# training | log loss: 55.50%, AUC: 87.14%, accuracy: 78.32%\n",
      "# testing  | log loss: 57.90%, AUC: 82.62%, accuracy: 74.22%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "151 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6179655051303428,\n",
      " 'colsample_bytree': 0.8479450694691918,\n",
      " 'gamma': 0.6378692501491362,\n",
      " 'learning_rate': 0.09279063856660422,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 8.10855601253821e-09,\n",
      " 'reg_lambda': 3.1141558583347435,\n",
      " 'scale_pos_weight': 0.8675833377943077,\n",
      " 'subsample': 0.9041252342269195}\n",
      "\n",
      "# training | log loss: 57.52%, AUC: 93.12%, accuracy: 86.71%\n",
      "# testing  | log loss: 59.83%, AUC: 85.62%, accuracy: 78.09%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "152 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.16423971101100393,\n",
      " 'gamma': 0.060430933235350204,\n",
      " 'max_depth': 3}\n",
      "\n",
      "# training | log loss: 66.55%, AUC: 91.93%, accuracy: 54.20%\n",
      "# testing  | log loss: 68.50%, AUC: 87.61%, accuracy: 50.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "153 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.579981833655904,\n",
      " 'colsample_bytree': 0.7144211497722452,\n",
      " 'learning_rate': 0.050967419158568054,\n",
      " 'reg_alpha': 0.40409907490388225,\n",
      " 'scale_pos_weight': 1.2346728818663846,\n",
      " 'subsample': 0.7893164342765393}\n",
      "\n",
      "# training | log loss: 63.05%, AUC: 85.01%, accuracy: 74.83%\n",
      "# testing  | log loss: 63.60%, AUC: 82.70%, accuracy: 71.24%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "154 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.0006876224413118469,\n",
      " 'scale_pos_weight': 5.0575258348762455}\n",
      "\n",
      "# training | log loss: 46.77%, AUC: 96.84%, accuracy: 82.52%\n",
      "# testing  | log loss: 51.95%, AUC: 91.11%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "155 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.973758654846358,\n",
      " 'gamma': 0.16912749704842467,\n",
      " 'learning_rate': 0.16483230916573147,\n",
      " 'reg_lambda': 7.8347279556460085,\n",
      " 'subsample': 0.741903542353}\n",
      "\n",
      "# training | log loss: 56.81%, AUC: 84.57%, accuracy: 81.47%\n",
      "# testing  | log loss: 58.90%, AUC: 79.66%, accuracy: 77.50%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "156 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6214556278105031,\n",
      " 'gamma': 0.08857306486642313,\n",
      " 'reg_alpha': 0.0030970253826619293,\n",
      " 'subsample': 0.7536853054784386}\n",
      "\n",
      "# training | log loss: 54.01%, AUC: 90.96%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.35%, AUC: 86.45%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "157 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.07363801268680353, 'scale_pos_weight': 8.263339042745622}\n",
      "\n",
      "# training | log loss: 58.38%, AUC: 82.61%, accuracy: 72.73%\n",
      "# testing  | log loss: 60.47%, AUC: 79.92%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "158 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.27920314953036185,\n",
      " 'colsample_bylevel': 0.9316520432294007,\n",
      " 'colsample_bytree': 0.9059247043068235,\n",
      " 'learning_rate': 0.06524037257967917,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 6.529264344107226e-07,\n",
      " 'reg_lambda': 3.4553759900929513}\n",
      "\n",
      "# training | log loss: 72.82%, AUC: 85.95%, accuracy: 34.62%\n",
      "# testing  | log loss: 73.60%, AUC: 83.34%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "159 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'min_child_weight': 8,\n",
      " 'reg_alpha': 0.028525568802265026,\n",
      " 'reg_lambda': 3.0656313688904047}\n",
      "\n",
      "# training | log loss: 59.04%, AUC: 80.64%, accuracy: 69.23%\n",
      "# testing  | log loss: 59.91%, AUC: 79.49%, accuracy: 67.21%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "160 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8095593172451278,\n",
      " 'colsample_bylevel': 0.6397050259470526,\n",
      " 'colsample_bytree': 0.6488099342398626,\n",
      " 'gamma': 0.05107583973119101,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_lambda': 4.139799982482919,\n",
      " 'subsample': 0.5306594857139422}\n",
      "\n",
      "# training | log loss: 66.07%, AUC: 61.76%, accuracy: 65.38%\n",
      "# testing  | log loss: 66.69%, AUC: 54.79%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "161 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.9021653047877848,\n",
      " 'learning_rate': 0.09993735426935815,\n",
      " 'min_child_weight': 10,\n",
      " 'scale_pos_weight': 6.285349827229268}\n",
      "\n",
      "# training | log loss: 60.04%, AUC: 82.33%, accuracy: 65.38%\n",
      "# testing  | log loss: 61.32%, AUC: 76.55%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "162 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5259663830096387,\n",
      " 'colsample_bytree': 0.574099410306363,\n",
      " 'gamma': 0.18438452328778387,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 1.0079505459022345e-06,\n",
      " 'scale_pos_weight': 2.9905303842848134,\n",
      " 'subsample': 0.9721145577639636}\n",
      "\n",
      "# training | log loss: 54.28%, AUC: 94.76%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.58%, AUC: 88.76%, accuracy: 67.66%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "163 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7199762594995522,\n",
      " 'colsample_bytree': 0.7863232710194841,\n",
      " 'learning_rate': 0.05151763226537718,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 0.013311017789210334,\n",
      " 'reg_lambda': 5.59620036533948,\n",
      " 'scale_pos_weight': 5.75953304095346,\n",
      " 'subsample': 0.6654209565652565}\n",
      "\n",
      "# training | log loss: 64.25%, AUC: 66.98%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.41%, AUC: 68.66%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "164 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6522655151247928,\n",
      " 'colsample_bylevel': 0.9148186901656441,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 0.0019599660117358654,\n",
      " 'reg_lambda': 5.1035830960624065}\n",
      "\n",
      "# training | log loss: 58.31%, AUC: 79.96%, accuracy: 65.38%\n",
      "# testing  | log loss: 58.16%, AUC: 81.15%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "165 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6776665644241656,\n",
      " 'colsample_bytree': 0.7003632363483203,\n",
      " 'gamma': 0.6800611482134338,\n",
      " 'learning_rate': 0.056658081894155776,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 3.366819116795581}\n",
      "\n",
      "# training | log loss: 64.95%, AUC: 80.27%, accuracy: 70.28%\n",
      "# testing  | log loss: 65.51%, AUC: 73.01%, accuracy: 69.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "166 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5147348640565046,\n",
      " 'colsample_bylevel': 0.5419452765628369,\n",
      " 'colsample_bytree': 0.7999523588528433,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 4}\n",
      "\n",
      "# training | log loss: 58.18%, AUC: 85.20%, accuracy: 75.17%\n",
      "# testing  | log loss: 59.91%, AUC: 81.22%, accuracy: 71.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "167 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.4686918643216551,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_lambda': 4.652146572627956,\n",
      " 'scale_pos_weight': 0.8569269837315651,\n",
      " 'subsample': 0.7236622214291855}\n",
      "\n",
      "# training | log loss: 62.59%, AUC: 84.12%, accuracy: 72.73%\n",
      "# testing  | log loss: 63.29%, AUC: 81.22%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "168 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 5,\n",
      " 'reg_lambda': 3.3396078576316404,\n",
      " 'subsample': 0.8420720530888733}\n",
      "\n",
      "# training | log loss: 50.22%, AUC: 98.26%, accuracy: 93.36%\n",
      "# testing  | log loss: 52.33%, AUC: 96.53%, accuracy: 91.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "169 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5884799866744319,\n",
      " 'colsample_bytree': 0.8981384397082255,\n",
      " 'gamma': 0.19868067387075172,\n",
      " 'learning_rate': 0.0970384928356008,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 3.4740193646731456,\n",
      " 'subsample': 0.558147151066593}\n",
      "\n",
      "# training | log loss: 61.89%, AUC: 81.19%, accuracy: 73.08%\n",
      "# testing  | log loss: 62.86%, AUC: 76.72%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "170 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.565521724304594,\n",
      " 'gamma': 0.7692719856163077,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 10}\n",
      "\n",
      "# training | log loss: 57.61%, AUC: 82.31%, accuracy: 70.98%\n",
      "# testing  | log loss: 58.84%, AUC: 81.25%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "171 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.5311351119408004,\n",
      " 'gamma': 0.3100498057420912,\n",
      " 'learning_rate': 0.07566885375630218,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 2.9312156334175905e-10,\n",
      " 'scale_pos_weight': 6.605711562158374}\n",
      "\n",
      "# training | log loss: 61.65%, AUC: 82.95%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.11%, AUC: 73.35%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "172 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1735806959466168,\n",
      " 'colsample_bytree': 0.7265238953420023,\n",
      " 'gamma': 0.6666376788495465,\n",
      " 'learning_rate': 0.10821543909724149,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 8.593415624282116e-08,\n",
      " 'subsample': 0.6183629560659876}\n",
      "\n",
      "# training | log loss: 71.16%, AUC: 79.33%, accuracy: 48.95%\n",
      "# testing  | log loss: 71.99%, AUC: 76.01%, accuracy: 46.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "173 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.1432025872809206,\n",
      " 'learning_rate': 0.19211835848743014,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 5.0239978681558045e-08}\n",
      "\n",
      "# training | log loss: 47.82%, AUC: 90.31%, accuracy: 84.62%\n",
      "# testing  | log loss: 50.79%, AUC: 86.07%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "174 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8035331368840558,\n",
      " 'colsample_bylevel': 0.5227031391127477,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 7,\n",
      " 'scale_pos_weight': 1.707266688414571}\n",
      "\n",
      "# training | log loss: 60.47%, AUC: 82.02%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.54%, AUC: 79.71%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "175 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6930146539461786,\n",
      " 'colsample_bytree': 0.9026106633487083,\n",
      " 'gamma': 0.6591390964925301,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 0.0035153680836902987,\n",
      " 'reg_lambda': 3.347304696779787,\n",
      " 'scale_pos_weight': 8.530074693465135}\n",
      "\n",
      "# training | log loss: 63.33%, AUC: 74.17%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.29%, AUC: 69.25%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "176 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6305826750143709, 'subsample': 0.7898162725699245}\n",
      "\n",
      "# training | log loss: 53.54%, AUC: 88.11%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.68%, AUC: 82.15%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "177 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.9280453164487553,\n",
      " 'colsample_bytree': 0.6896327999380305,\n",
      " 'gamma': 0.061021933473984435,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 1.0660014517252863e-06,\n",
      " 'reg_lambda': 6.349996170435664,\n",
      " 'subsample': 0.8165321099995808}\n",
      "\n",
      "# training | log loss: 60.13%, AUC: 87.31%, accuracy: 75.87%\n",
      "# testing  | log loss: 61.86%, AUC: 81.27%, accuracy: 70.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "178 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5545094101683343,\n",
      " 'reg_alpha': 1.7769480776717158e-09,\n",
      " 'reg_lambda': 9.77761396161463,\n",
      " 'subsample': 0.6896782618384992}\n",
      "\n",
      "# training | log loss: 59.85%, AUC: 86.69%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.08%, AUC: 81.34%, accuracy: 69.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "179 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5669554460371318,\n",
      " 'colsample_bylevel': 0.7320543818276694,\n",
      " 'learning_rate': 0.03677089940076357,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 5.549872234756205,\n",
      " 'subsample': 0.5495745835391925}\n",
      "\n",
      "# training | log loss: 63.95%, AUC: 77.79%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.44%, AUC: 69.35%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "180 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8766584543430351,\n",
      " 'gamma': 0.92943924901798,\n",
      " 'learning_rate': 0.07973083863218751,\n",
      " 'reg_lambda': 0.28699900486615854,\n",
      " 'scale_pos_weight': 1.7255747032394881}\n",
      "\n",
      "# training | log loss: 58.78%, AUC: 88.61%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.18%, AUC: 84.83%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "181 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5310129934777329,\n",
      " 'colsample_bylevel': 0.9641445894945309,\n",
      " 'colsample_bytree': 0.8445781675752966,\n",
      " 'learning_rate': 0.05750717503602967,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 4.092397856089625e-07,\n",
      " 'scale_pos_weight': 9.058103234085118,\n",
      " 'subsample': 0.8268545182310567}\n",
      "\n",
      "# training | log loss: 62.63%, AUC: 79.37%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.00%, AUC: 77.59%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "182 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.585980253173216,\n",
      " 'colsample_bytree': 0.674659072066635,\n",
      " 'gamma': 0.6888508056322232,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 5,\n",
      " 'scale_pos_weight': 1.9140542377010263}\n",
      "\n",
      "# training | log loss: 52.90%, AUC: 91.39%, accuracy: 72.73%\n",
      "# testing  | log loss: 55.59%, AUC: 86.00%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "183 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.21381610422814568,\n",
      " 'colsample_bylevel': 0.9134317824767677,\n",
      " 'colsample_bytree': 0.9925702438435415,\n",
      " 'learning_rate': 0.08748052159119772,\n",
      " 'reg_alpha': 4.3635325343478955e-05,\n",
      " 'reg_lambda': 9.293296398880733}\n",
      "\n",
      "# training | log loss: 77.44%, AUC: 72.83%, accuracy: 34.62%\n",
      "# testing  | log loss: 77.39%, AUC: 72.94%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "184 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.49378639277054015,\n",
      " 'colsample_bylevel': 0.8945132919352095,\n",
      " 'colsample_bytree': 0.9014095722354097,\n",
      " 'gamma': 0.710602406500149,\n",
      " 'learning_rate': 0.19950488474220546,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 3.8977961208074253e-10}\n",
      "\n",
      "# training | log loss: 33.43%, AUC: 99.36%, accuracy: 96.85%\n",
      "# testing  | log loss: 37.50%, AUC: 98.60%, accuracy: 95.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "185 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7123655050905816,\n",
      " 'gamma': 0.46222413155476316,\n",
      " 'learning_rate': 0.0722696205921452,\n",
      " 'reg_lambda': 9.794011643113883,\n",
      " 'subsample': 0.8619861076047117}\n",
      "\n",
      "# training | log loss: 62.63%, AUC: 83.24%, accuracy: 76.92%\n",
      "# testing  | log loss: 63.42%, AUC: 80.53%, accuracy: 74.22%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "186 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6193456884647703,\n",
      " 'colsample_bytree': 0.5912281656531306,\n",
      " 'learning_rate': 0.1044313310640784,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 5.827863720758555e-09}\n",
      "\n",
      "# training | log loss: 61.55%, AUC: 80.28%, accuracy: 73.08%\n",
      "# testing  | log loss: 62.35%, AUC: 77.57%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "187 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.9349430561411711,\n",
      " 'learning_rate': 0.0524303266203179,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 1.918812493945078e-10,\n",
      " 'reg_lambda': 6.5023965501833585,\n",
      " 'scale_pos_weight': 7.085038046264254,\n",
      " 'subsample': 0.7664237095726125}\n",
      "\n",
      "# training | log loss: 64.81%, AUC: 50.00%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.86%, AUC: 50.00%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "188 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.2125084555628538,\n",
      " 'colsample_bylevel': 0.6534142447363389,\n",
      " 'colsample_bytree': 0.9283365335458096,\n",
      " 'gamma': 0.40424333034627846,\n",
      " 'learning_rate': 0.03557488897726857,\n",
      " 'reg_alpha': 9.103579941764222e-06,\n",
      " 'reg_lambda': 4.739076575619503,\n",
      " 'subsample': 0.812500464351197}\n",
      "\n",
      "# training | log loss: 91.64%, AUC: 72.44%, accuracy: 34.62%\n",
      "# testing  | log loss: 91.55%, AUC: 72.38%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "189 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5900643882915451,\n",
      " 'learning_rate': 0.18101135758033604,\n",
      " 'reg_alpha': 0.0002920421123215135}\n",
      "\n",
      "# training | log loss: 47.70%, AUC: 90.31%, accuracy: 76.92%\n",
      "# testing  | log loss: 50.68%, AUC: 86.01%, accuracy: 74.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "190 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.652049390483421,\n",
      " 'reg_alpha': 3.6910112518923366e-09,\n",
      " 'reg_lambda': 0.923226578132168,\n",
      " 'subsample': 0.9843631982427985}\n",
      "\n",
      "# training | log loss: 55.83%, AUC: 91.07%, accuracy: 81.47%\n",
      "# testing  | log loss: 57.60%, AUC: 86.39%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "191 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3807565479492939, 'learning_rate': 0.16336723712254608}\n",
      "\n",
      "# training | log loss: 51.19%, AUC: 89.91%, accuracy: 78.67%\n",
      "# testing  | log loss: 53.81%, AUC: 85.52%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "192 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.7922479493299884,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 7,\n",
      " 'subsample': 0.7248298498715386}\n",
      "\n",
      "# training | log loss: 60.75%, AUC: 78.25%, accuracy: 70.98%\n",
      "# testing  | log loss: 61.05%, AUC: 78.02%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "193 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7552722275815652,\n",
      " 'colsample_bylevel': 0.9512297075529536,\n",
      " 'colsample_bytree': 0.9421311223833008,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 0.747870416011159,\n",
      " 'subsample': 0.8909931589895714}\n",
      "\n",
      "# training | log loss: 45.77%, AUC: 98.60%, accuracy: 68.88%\n",
      "# testing  | log loss: 49.25%, AUC: 94.53%, accuracy: 68.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "194 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.8940846002449393,\n",
      " 'colsample_bylevel': 0.9333577227301526,\n",
      " 'colsample_bytree': 0.9768964437474639,\n",
      " 'gamma': 0.5353302124422097,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4,\n",
      " 'scale_pos_weight': 4.403891036649379,\n",
      " 'subsample': 0.7633314873536443}\n",
      "\n",
      "# training | log loss: 69.42%, AUC: 88.73%, accuracy: 65.38%\n",
      "# testing  | log loss: 74.12%, AUC: 81.47%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "195 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6497320758203631,\n",
      " 'colsample_bylevel': 0.7290137170888236,\n",
      " 'gamma': 0.33029717475365805,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 4.6935082719925125e-09}\n",
      "\n",
      "# training | log loss: 57.35%, AUC: 81.84%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.67%, AUC: 79.27%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "196 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.7907764530452526,\n",
      " 'gamma': 0.5193856918556472,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 0.0007403837078075275,\n",
      " 'reg_lambda': 4.126024480025989,\n",
      " 'scale_pos_weight': 7.839544279565341,\n",
      " 'subsample': 0.7833456368024253}\n",
      "\n",
      "# training | log loss: 63.29%, AUC: 67.85%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.60%, AUC: 69.49%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "197 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.5661595787625048}\n",
      "\n",
      "# training | log loss: 56.41%, AUC: 89.47%, accuracy: 79.72%\n",
      "# testing  | log loss: 59.02%, AUC: 82.97%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "198 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.4712047255820909,\n",
      " 'reg_alpha': 0.6927515294729237,\n",
      " 'subsample': 0.7462738985799453}\n",
      "\n",
      "# training | log loss: 56.56%, AUC: 90.51%, accuracy: 82.17%\n",
      "# testing  | log loss: 58.55%, AUC: 84.88%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "199 | Thu Oct 26 04:30:49 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.8639728628005077,\n",
      " 'gamma': 0.6389337162866344,\n",
      " 'reg_lambda': 9.789905439784551,\n",
      " 'scale_pos_weight': 4.977243768459168,\n",
      " 'subsample': 0.9004591642721901}\n",
      "\n",
      "# training | log loss: 62.86%, AUC: 67.80%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.28%, AUC: 69.90%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "200 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5550685673015441,\n",
      " 'colsample_bytree': 0.5768692337126999,\n",
      " 'learning_rate': 0.1920015021205661,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 1.0128819685666848,\n",
      " 'subsample': 0.517755540810801}\n",
      "\n",
      "# training | log loss: 53.48%, AUC: 88.52%, accuracy: 78.67%\n",
      "# testing  | log loss: 56.61%, AUC: 82.79%, accuracy: 73.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "201 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.8001750274633264,\n",
      " 'learning_rate': 0.09443674131981379,\n",
      " 'reg_alpha': 2.042947011329953e-08,\n",
      " 'reg_lambda': 1.1015838238873206,\n",
      " 'subsample': 0.6420005676867206}\n",
      "\n",
      "# training | log loss: 56.43%, AUC: 90.98%, accuracy: 84.97%\n",
      "# testing  | log loss: 58.11%, AUC: 86.36%, accuracy: 78.84%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "202 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.6452204368933598,\n",
      " 'gamma': 0.1486876661773907,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 0.017884202520187777,\n",
      " 'reg_lambda': 3.386759759315152,\n",
      " 'scale_pos_weight': 1.269129012674397,\n",
      " 'subsample': 0.6516416822065937}\n",
      "\n",
      "# training | log loss: 60.67%, AUC: 81.54%, accuracy: 72.38%\n",
      "# testing  | log loss: 61.81%, AUC: 77.02%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "203 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6090086916336588,\n",
      " 'colsample_bytree': 0.6386066668601112,\n",
      " 'gamma': 0.5511884135055976,\n",
      " 'learning_rate': 0.07532929942251507,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 6.854704486685382,\n",
      " 'subsample': 0.830208103331299}\n",
      "\n",
      "# training | log loss: 63.63%, AUC: 78.73%, accuracy: 73.08%\n",
      "# testing  | log loss: 64.53%, AUC: 73.07%, accuracy: 69.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "204 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6289563094579596,\n",
      " 'learning_rate': 0.038844939228988115,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 0.00011820061417439812}\n",
      "\n",
      "# training | log loss: 62.72%, AUC: 87.72%, accuracy: 77.27%\n",
      "# testing  | log loss: 63.56%, AUC: 82.31%, accuracy: 70.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "205 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.072185059739043,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 5.647619051307334}\n",
      "\n",
      "# training | log loss: 57.83%, AUC: 84.78%, accuracy: 72.73%\n",
      "# testing  | log loss: 59.92%, AUC: 80.89%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "206 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7807403065280979, 'reg_lambda': 9.073072415194304}\n",
      "\n",
      "# training | log loss: 59.09%, AUC: 85.35%, accuracy: 78.67%\n",
      "# testing  | log loss: 60.25%, AUC: 81.81%, accuracy: 74.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "207 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.18803800731569595,\n",
      " 'learning_rate': 0.010185298574160652,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.3174322156730097,\n",
      " 'reg_lambda': 1.5079718132497162,\n",
      " 'scale_pos_weight': 7.2847402968153805,\n",
      " 'subsample': 0.6645432967947775}\n",
      "\n",
      "# training | log loss: 104.54%, AUC: 50.00%, accuracy: 34.62%\n",
      "# testing  | log loss: 104.41%, AUC: 50.00%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "208 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7197140709371942,\n",
      " 'colsample_bytree': 0.6911126070766427,\n",
      " 'gamma': 0.8002640084065132,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 4.937291236022107}\n",
      "\n",
      "# training | log loss: 61.17%, AUC: 82.46%, accuracy: 72.73%\n",
      "# testing  | log loss: 62.11%, AUC: 77.62%, accuracy: 68.70%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "209 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7010673111337775,\n",
      " 'colsample_bytree': 0.7792339448000096,\n",
      " 'learning_rate': 0.031147608888925288,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 4.026516359570291e-10,\n",
      " 'scale_pos_weight': 2.2514745341388593}\n",
      "\n",
      "# training | log loss: 62.37%, AUC: 96.42%, accuracy: 78.67%\n",
      "# testing  | log loss: 64.12%, AUC: 84.68%, accuracy: 71.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "210 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6314286961651645,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 0.07007089997424135,\n",
      " 'reg_lambda': 2.363077821438641,\n",
      " 'scale_pos_weight': 5.115157684397852,\n",
      " 'subsample': 0.564519730466505}\n",
      "\n",
      "# training | log loss: 62.08%, AUC: 77.86%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.02%, AUC: 74.35%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "211 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5300353783924089,\n",
      " 'colsample_bylevel': 0.9933061282531038,\n",
      " 'colsample_bytree': 0.5330508986753448,\n",
      " 'gamma': 0.1155586788699483,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.03699509993187725,\n",
      " 'subsample': 0.9625501603675383}\n",
      "\n",
      "# training | log loss: 61.24%, AUC: 79.34%, accuracy: 72.73%\n",
      "# testing  | log loss: 61.76%, AUC: 78.87%, accuracy: 70.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "212 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7182067724636336,\n",
      " 'colsample_bylevel': 0.7091051866916851,\n",
      " 'gamma': 0.9057179505486894,\n",
      " 'learning_rate': 0.030082452638418897,\n",
      " 'reg_alpha': 1.2035506330912045e-08,\n",
      " 'subsample': 0.7929399853584067}\n",
      "\n",
      "# training | log loss: 61.40%, AUC: 86.27%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.42%, AUC: 81.46%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "213 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6865233854371785,\n",
      " 'reg_lambda': 3.0867926873456804,\n",
      " 'scale_pos_weight': 3.5854180215919977,\n",
      " 'subsample': 0.7740326413549652}\n",
      "\n",
      "# training | log loss: 58.94%, AUC: 81.36%, accuracy: 67.48%\n",
      "# testing  | log loss: 60.29%, AUC: 76.15%, accuracy: 65.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "214 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.4161990851268482,\n",
      " 'colsample_bylevel': 0.560044927397201,\n",
      " 'colsample_bytree': 0.8163058831679743,\n",
      " 'learning_rate': 0.17255768066400928,\n",
      " 'max_depth': 5,\n",
      " 'reg_lambda': 7.4103600989476925,\n",
      " 'subsample': 0.7884642223443247}\n",
      "\n",
      "# training | log loss: 57.74%, AUC: 90.30%, accuracy: 82.52%\n",
      "# testing  | log loss: 59.57%, AUC: 85.18%, accuracy: 77.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "215 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'max_depth': 3,\n",
      " 'scale_pos_weight': 8.156588552271563,\n",
      " 'subsample': 0.8805333697234919}\n",
      "\n",
      "# training | log loss: 56.73%, AUC: 86.13%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.76%, AUC: 81.72%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "216 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.24705682268534784,\n",
      " 'colsample_bytree': 0.8333329461733328,\n",
      " 'learning_rate': 0.11860992120109111,\n",
      " 'max_depth': 8,\n",
      " 'scale_pos_weight': 3.104388421405455}\n",
      "\n",
      "# training | log loss: 49.44%, AUC: 98.28%, accuracy: 93.01%\n",
      "# testing  | log loss: 53.18%, AUC: 94.47%, accuracy: 88.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "217 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'learning_rate': 0.08216940733052262,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 7.618114182347841,\n",
      " 'subsample': 0.7258788019975251}\n",
      "\n",
      "# training | log loss: 54.84%, AUC: 96.68%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.49%, AUC: 94.44%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "218 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6938126250107913,\n",
      " 'colsample_bylevel': 0.8923453366396987,\n",
      " 'colsample_bytree': 0.5592468734807898,\n",
      " 'gamma': 0.6036965215014533,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 3.936925997972951e-06,\n",
      " 'scale_pos_weight': 5.251439082882346}\n",
      "\n",
      "# training | log loss: 56.99%, AUC: 92.69%, accuracy: 66.08%\n",
      "# testing  | log loss: 61.63%, AUC: 81.38%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "219 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.3044761112143142,\n",
      " 'colsample_bylevel': 0.510574577789088,\n",
      " 'gamma': 0.032371082398018336,\n",
      " 'learning_rate': 0.031115810556449637,\n",
      " 'scale_pos_weight': 9.442771774718087,\n",
      " 'subsample': 0.7149543879692268}\n",
      "\n",
      "# training | log loss: 75.84%, AUC: 64.71%, accuracy: 34.62%\n",
      "# testing  | log loss: 75.79%, AUC: 68.20%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "220 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.13457457393469785,\n",
      " 'learning_rate': 0.06401335025533951,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 2.990041214396552,\n",
      " 'scale_pos_weight': 2.7572125664005687}\n",
      "\n",
      "# training | log loss: 79.36%, AUC: 67.23%, accuracy: 34.62%\n",
      "# testing  | log loss: 79.56%, AUC: 69.17%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "221 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.7049097708535832,\n",
      " 'gamma': 0.011323970309743081,\n",
      " 'learning_rate': 0.09122528761863397,\n",
      " 'subsample': 0.5318865539851318}\n",
      "\n",
      "# training | log loss: 58.73%, AUC: 88.17%, accuracy: 78.32%\n",
      "# testing  | log loss: 60.51%, AUC: 82.33%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "222 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.27085182854075207,\n",
      " 'colsample_bylevel': 0.7485422890600639,\n",
      " 'colsample_bytree': 0.5670961129152876,\n",
      " 'gamma': 0.9166432770616333,\n",
      " 'subsample': 0.8602983002732826}\n",
      "\n",
      "# training | log loss: 66.84%, AUC: 83.16%, accuracy: 62.24%\n",
      "# testing  | log loss: 67.71%, AUC: 81.60%, accuracy: 58.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "223 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6918384800122424,\n",
      " 'colsample_bytree': 0.8312109133175791,\n",
      " 'gamma': 0.4149990611731843,\n",
      " 'learning_rate': 0.1628149208407977,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_lambda': 2.283516363867086,\n",
      " 'scale_pos_weight': 5.870703365003626,\n",
      " 'subsample': 0.9213967205088873}\n",
      "\n",
      "# training | log loss: 64.35%, AUC: 84.23%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.08%, AUC: 79.35%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "224 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.615696304422504,\n",
      " 'colsample_bylevel': 0.7984719839716032,\n",
      " 'colsample_bytree': 0.8983906557039267,\n",
      " 'gamma': 0.44475965946898577,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 6.207052418606882e-06,\n",
      " 'reg_lambda': 2.0563404216344336,\n",
      " 'scale_pos_weight': 7.158540420641577}\n",
      "\n",
      "# training | log loss: 55.56%, AUC: 93.62%, accuracy: 70.98%\n",
      "# testing  | log loss: 58.88%, AUC: 85.68%, accuracy: 67.66%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "225 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.69320990721886,\n",
      " 'learning_rate': 0.11097412090435686,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 3.3420007049129664e-07,\n",
      " 'reg_lambda': 4.356665313321582,\n",
      " 'scale_pos_weight': 1.4126621621456603,\n",
      " 'subsample': 0.7323852689164327}\n",
      "\n",
      "# training | log loss: 56.61%, AUC: 89.60%, accuracy: 80.07%\n",
      "# testing  | log loss: 59.03%, AUC: 83.43%, accuracy: 74.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "226 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'min_child_weight': 2,\n",
      " 'reg_lambda': 8.203141302180395,\n",
      " 'scale_pos_weight': 2.2723972857848573}\n",
      "\n",
      "# training | log loss: 57.99%, AUC: 80.93%, accuracy: 72.73%\n",
      "# testing  | log loss: 59.24%, AUC: 79.51%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "227 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'min_child_weight': 6,\n",
      " 'reg_lambda': 2.1792999314923187,\n",
      " 'scale_pos_weight': 5.439506199090512}\n",
      "\n",
      "# training | log loss: 59.67%, AUC: 81.80%, accuracy: 65.38%\n",
      "# testing  | log loss: 60.87%, AUC: 78.75%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "228 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6849378810072908,\n",
      " 'colsample_bytree': 0.8861021988506685,\n",
      " 'learning_rate': 0.023473540880591417,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 8.284277947217591}\n",
      "\n",
      "# training | log loss: 65.12%, AUC: 86.38%, accuracy: 65.73%\n",
      "# testing  | log loss: 65.50%, AUC: 82.40%, accuracy: 65.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "229 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7155966658048305,\n",
      " 'colsample_bytree': 0.7839190409481855,\n",
      " 'learning_rate': 0.18561696557352284,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 4.114670207304841,\n",
      " 'subsample': 0.7454502463391672}\n",
      "\n",
      "# training | log loss: 43.21%, AUC: 97.86%, accuracy: 76.22%\n",
      "# testing  | log loss: 46.26%, AUC: 95.88%, accuracy: 74.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "230 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.7583244988230854,\n",
      " 'colsample_bytree': 0.844430283214491,\n",
      " 'gamma': 0.7622968315785392,\n",
      " 'learning_rate': 0.13297486904778505,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.004584683438398393,\n",
      " 'scale_pos_weight': 6.204891250795607,\n",
      " 'subsample': 0.9051573434948106}\n",
      "\n",
      "# training | log loss: 58.09%, AUC: 95.37%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.87%, AUC: 87.05%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "231 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.1430260737933593,\n",
      " 'colsample_bylevel': 0.6103603705032503,\n",
      " 'gamma': 0.20412611331199593,\n",
      " 'reg_lambda': 2.33792801313999,\n",
      " 'subsample': 0.6416301095676724}\n",
      "\n",
      "# training | log loss: 75.06%, AUC: 81.39%, accuracy: 34.62%\n",
      "# testing  | log loss: 75.31%, AUC: 79.90%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "232 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bytree': 0.5476887616140268,\n",
      " 'learning_rate': 0.15841893063509035,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_lambda': 2.7268817327751256}\n",
      "\n",
      "# training | log loss: 58.92%, AUC: 81.50%, accuracy: 70.98%\n",
      "# testing  | log loss: 60.70%, AUC: 74.21%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "233 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5601176657836565,\n",
      " 'colsample_bytree': 0.5373357322499597,\n",
      " 'gamma': 0.3323129772610405,\n",
      " 'learning_rate': 0.06845688731124334,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 0.04893109714779312,\n",
      " 'scale_pos_weight': 8.096032994419902,\n",
      " 'subsample': 0.9971934898708248}\n",
      "\n",
      "# training | log loss: 63.10%, AUC: 80.13%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.53%, AUC: 75.19%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "234 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.5884753120414983,\n",
      " 'colsample_bytree': 0.9695470618278745,\n",
      " 'gamma': 0.40540105595282017,\n",
      " 'learning_rate': 0.05282081215307206,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.061424110610917494,\n",
      " 'reg_lambda': 7.77233372775822,\n",
      " 'subsample': 0.5678481986459172}\n",
      "\n",
      "# training | log loss: 65.81%, AUC: 77.10%, accuracy: 73.43%\n",
      "# testing  | log loss: 66.14%, AUC: 72.97%, accuracy: 70.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "235 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.10216115593357636,\n",
      " 'colsample_bylevel': 0.6397213688774168,\n",
      " 'gamma': 0.4795620744667696,\n",
      " 'learning_rate': 0.12184861865065183,\n",
      " 'reg_lambda': 8.211104979268082,\n",
      " 'subsample': 0.9461736075579622}\n",
      "\n",
      "# training | log loss: 78.52%, AUC: 67.10%, accuracy: 34.62%\n",
      "# testing  | log loss: 78.33%, AUC: 69.67%, accuracy: 34.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "236 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'gamma': 0.34994785147289675,\n",
      " 'reg_alpha': 0.003585950168654223,\n",
      " 'reg_lambda': 5.826735874932379,\n",
      " 'scale_pos_weight': 4.2855202219110575,\n",
      " 'subsample': 0.9489943412746051}\n",
      "\n",
      "# training | log loss: 58.66%, AUC: 75.75%, accuracy: 72.73%\n",
      "# testing  | log loss: 60.02%, AUC: 75.57%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "237 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6021307839615629,\n",
      " 'learning_rate': 0.01663467973947675,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.03327447968673735,\n",
      " 'reg_lambda': 1.6991017152505439,\n",
      " 'scale_pos_weight': 7.608538653930323,\n",
      " 'subsample': 0.8278691002562186}\n",
      "\n",
      "# training | log loss: 64.02%, AUC: 68.68%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.13%, AUC: 70.63%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "238 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.6327787475748521,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.009977237348724044}\n",
      "\n",
      "# training | log loss: 58.83%, AUC: 80.35%, accuracy: 70.98%\n",
      "# testing  | log loss: 59.24%, AUC: 81.43%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "239 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.6381651879931324,\n",
      " 'colsample_bylevel': 0.6793995423349652,\n",
      " 'learning_rate': 0.17941139175497536,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 1.0160496057369019e-07,\n",
      " 'reg_lambda': 4.074384968769464}\n",
      "\n",
      "# training | log loss: 50.93%, AUC: 91.25%, accuracy: 72.73%\n",
      "# testing  | log loss: 53.64%, AUC: 85.36%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "240 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.32553317026694895,\n",
      " 'colsample_bytree': 0.6348698876069405,\n",
      " 'gamma': 0.41562894566527986,\n",
      " 'reg_lambda': 2.484137918516361}\n",
      "\n",
      "# training | log loss: 63.34%, AUC: 87.22%, accuracy: 69.23%\n",
      "# testing  | log loss: 65.08%, AUC: 82.11%, accuracy: 67.06%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "241 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'scale_pos_weight': 3.1630778755630256, 'subsample': 0.6610190958953701}\n",
      "\n",
      "# training | log loss: 55.08%, AUC: 89.60%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.79%, AUC: 83.73%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "242 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'base_score': 0.5471451162671814,\n",
      " 'gamma': 0.6388624569536315,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 1.785888759098008e-10}\n",
      "\n",
      "# training | log loss: 46.84%, AUC: 95.01%, accuracy: 83.57%\n",
      "# testing  | log loss: 49.55%, AUC: 93.23%, accuracy: 77.79%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "243 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 6\n",
      "{'colsample_bylevel': 0.7326562144396576,\n",
      " 'gamma': 0.4954365576173848,\n",
      " 'learning_rate': 0.10188433871371089,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 3.1015821426083723,\n",
      " 'scale_pos_weight': 7.260529535276947}\n",
      "\n",
      "# training | log loss: 62.18%, AUC: 72.59%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.21%, AUC: 69.65%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 81.0 configurations x 3.7 iterations each\n",
      "\n",
      "244 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.3708 (run 135)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.8955964486499088,\n",
      " 'learning_rate': 0.1822287061793478,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 5.151870309734203e-06}\n",
      "\n",
      "# training | log loss: 15.27%, AUC: 99.97%, accuracy: 98.25%\n",
      "# testing  | log loss: 20.69%, AUC: 99.19%, accuracy: 96.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "245 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.49378639277054015,\n",
      " 'colsample_bylevel': 0.8945132919352095,\n",
      " 'colsample_bytree': 0.9014095722354097,\n",
      " 'gamma': 0.710602406500149,\n",
      " 'learning_rate': 0.19950488474220546,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 3.8977961208074253e-10}\n",
      "\n",
      "# training | log loss: 16.30%, AUC: 99.87%, accuracy: 98.25%\n",
      "# testing  | log loss: 21.82%, AUC: 99.08%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "246 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6038238659359236,\n",
      " 'colsample_bylevel': 0.9126925240986197,\n",
      " 'learning_rate': 0.19367007748415568,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 4.319346134769293e-08,\n",
      " 'reg_lambda': 1.5912281395622878,\n",
      " 'subsample': 0.8727066498360705}\n",
      "\n",
      "# training | log loss: 17.52%, AUC: 99.86%, accuracy: 98.60%\n",
      "# testing  | log loss: 24.19%, AUC: 98.85%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "247 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 22.54%, AUC: 99.47%, accuracy: 93.01%\n",
      "# testing  | log loss: 27.05%, AUC: 98.35%, accuracy: 89.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "248 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7155966658048305,\n",
      " 'colsample_bytree': 0.7839190409481855,\n",
      " 'learning_rate': 0.18561696557352284,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 4.114670207304841,\n",
      " 'subsample': 0.7454502463391672}\n",
      "\n",
      "# training | log loss: 23.24%, AUC: 99.82%, accuracy: 92.31%\n",
      "# testing  | log loss: 32.25%, AUC: 98.06%, accuracy: 85.99%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "249 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.8324726821585812,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 4.871354923609551e-07,\n",
      " 'scale_pos_weight': 2.649572288768033}\n",
      "\n",
      "# training | log loss: 20.31%, AUC: 99.91%, accuracy: 94.41%\n",
      "# testing  | log loss: 25.50%, AUC: 98.76%, accuracy: 90.76%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "250 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3798523831040156, 'max_depth': 6}\n",
      "\n",
      "# training | log loss: 22.43%, AUC: 99.69%, accuracy: 97.55%\n",
      "# testing  | log loss: 26.55%, AUC: 98.71%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "251 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5777174461906869,\n",
      " 'colsample_bytree': 0.7913208027619905,\n",
      " 'gamma': 0.8724127061974302,\n",
      " 'learning_rate': 0.19584124144251125,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 5.046195583774196e-10}\n",
      "\n",
      "# training | log loss: 25.23%, AUC: 99.77%, accuracy: 96.15%\n",
      "# testing  | log loss: 33.29%, AUC: 96.17%, accuracy: 87.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "252 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7552722275815652,\n",
      " 'colsample_bylevel': 0.9512297075529536,\n",
      " 'colsample_bytree': 0.9421311223833008,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 0.747870416011159,\n",
      " 'subsample': 0.8909931589895714}\n",
      "\n",
      "# training | log loss: 29.38%, AUC: 99.58%, accuracy: 96.15%\n",
      "# testing  | log loss: 35.52%, AUC: 97.44%, accuracy: 90.16%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "253 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5471451162671814,\n",
      " 'gamma': 0.6388624569536315,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 1.785888759098008e-10}\n",
      "\n",
      "# training | log loss: 28.96%, AUC: 99.11%, accuracy: 94.76%\n",
      "# testing  | log loss: 33.48%, AUC: 97.01%, accuracy: 90.16%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "254 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7963286086467167,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 4.751486756650194e-06,\n",
      " 'reg_lambda': 1.13546172286901,\n",
      " 'subsample': 0.8415621755378428}\n",
      "\n",
      "# training | log loss: 28.15%, AUC: 99.88%, accuracy: 94.06%\n",
      "# testing  | log loss: 34.59%, AUC: 97.55%, accuracy: 86.59%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "255 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5900643882915451,\n",
      " 'learning_rate': 0.18101135758033604,\n",
      " 'reg_alpha': 0.0002920421123215135}\n",
      "\n",
      "# training | log loss: 33.63%, AUC: 97.50%, accuracy: 89.86%\n",
      "# testing  | log loss: 38.86%, AUC: 93.27%, accuracy: 83.01%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "256 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7179469599897778,\n",
      " 'gamma': 0.480621024940986,\n",
      " 'learning_rate': 0.16337681307900698,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 3.3298698690019415e-09,\n",
      " 'reg_lambda': 3.905974270599137}\n",
      "\n",
      "# training | log loss: 32.50%, AUC: 98.14%, accuracy: 90.21%\n",
      "# testing  | log loss: 38.72%, AUC: 93.66%, accuracy: 85.54%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "257 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.1432025872809206,\n",
      " 'learning_rate': 0.19211835848743014,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 5.0239978681558045e-08}\n",
      "\n",
      "# training | log loss: 34.16%, AUC: 96.59%, accuracy: 89.86%\n",
      "# testing  | log loss: 39.32%, AUC: 91.81%, accuracy: 81.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "258 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.0006876224413118469,\n",
      " 'scale_pos_weight': 5.0575258348762455}\n",
      "\n",
      "# training | log loss: 34.15%, AUC: 98.90%, accuracy: 83.92%\n",
      "# testing  | log loss: 42.94%, AUC: 93.40%, accuracy: 77.50%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "259 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'learning_rate': 0.17526187147483882, 'reg_lambda': 1.3563685722513745}\n",
      "\n",
      "# training | log loss: 34.50%, AUC: 96.37%, accuracy: 88.46%\n",
      "# testing  | log loss: 39.57%, AUC: 92.16%, accuracy: 80.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "260 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.456698419430802,\n",
      " 'learning_rate': 0.16680274427701366,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 9.68622474212681}\n",
      "\n",
      "# training | log loss: 33.55%, AUC: 99.54%, accuracy: 81.47%\n",
      "# testing  | log loss: 45.64%, AUC: 94.40%, accuracy: 76.30%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "261 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'max_depth': 5,\n",
      " 'reg_lambda': 3.3396078576316404,\n",
      " 'subsample': 0.8420720530888733}\n",
      "\n",
      "# training | log loss: 32.71%, AUC: 99.50%, accuracy: 97.20%\n",
      "# testing  | log loss: 37.34%, AUC: 97.66%, accuracy: 92.40%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "262 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.8043503553771844, 'max_depth': 4}\n",
      "\n",
      "# training | log loss: 32.55%, AUC: 99.13%, accuracy: 94.41%\n",
      "# testing  | log loss: 36.85%, AUC: 98.16%, accuracy: 92.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "263 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7619624598977952,\n",
      " 'colsample_bytree': 0.9810660179429012,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 3.891601614828777}\n",
      "\n",
      "# training | log loss: 35.10%, AUC: 98.22%, accuracy: 83.92%\n",
      "# testing  | log loss: 40.17%, AUC: 96.44%, accuracy: 77.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "264 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.24705682268534784,\n",
      " 'colsample_bytree': 0.8333329461733328,\n",
      " 'learning_rate': 0.11860992120109111,\n",
      " 'max_depth': 8,\n",
      " 'scale_pos_weight': 3.104388421405455}\n",
      "\n",
      "# training | log loss: 24.05%, AUC: 99.86%, accuracy: 96.50%\n",
      "# testing  | log loss: 31.09%, AUC: 98.49%, accuracy: 92.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "265 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5113026802198888,\n",
      " 'colsample_bylevel': 0.7262821851431096,\n",
      " 'gamma': 0.07444416308921997,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 4.3561150798818505e-08}\n",
      "\n",
      "# training | log loss: 30.56%, AUC: 99.69%, accuracy: 96.15%\n",
      "# testing  | log loss: 35.81%, AUC: 97.42%, accuracy: 90.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "266 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6381651879931324,\n",
      " 'colsample_bylevel': 0.6793995423349652,\n",
      " 'learning_rate': 0.17941139175497536,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 1.0160496057369019e-07,\n",
      " 'reg_lambda': 4.074384968769464}\n",
      "\n",
      "# training | log loss: 39.74%, AUC: 95.27%, accuracy: 84.62%\n",
      "# testing  | log loss: 45.35%, AUC: 88.82%, accuracy: 78.24%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "267 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3807565479492939, 'learning_rate': 0.16336723712254608}\n",
      "\n",
      "# training | log loss: 34.21%, AUC: 97.16%, accuracy: 90.21%\n",
      "# testing  | log loss: 39.22%, AUC: 92.72%, accuracy: 82.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "268 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9479239700346893,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 5.133347471643192}\n",
      "\n",
      "# training | log loss: 34.99%, AUC: 99.44%, accuracy: 97.20%\n",
      "# testing  | log loss: 38.67%, AUC: 99.20%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "269 | Thu Oct 26 04:30:50 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7898455732075181,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.005179897174721011,\n",
      " 'subsample': 0.7775694999932248}\n",
      "\n",
      "# training | log loss: 39.81%, AUC: 96.09%, accuracy: 89.51%\n",
      "# testing  | log loss: 44.52%, AUC: 90.58%, accuracy: 81.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "270 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3661645557587426,\n",
      " 'gamma': 0.45031377991236576,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 1.3062672539931609e-05,\n",
      " 'reg_lambda': 3.617740190976021}\n",
      "\n",
      "# training | log loss: 30.87%, AUC: 99.11%, accuracy: 96.50%\n",
      "# testing  | log loss: 34.15%, AUC: 98.47%, accuracy: 93.59%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "271 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.585980253173216,\n",
      " 'colsample_bytree': 0.674659072066635,\n",
      " 'gamma': 0.6888508056322232,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 5,\n",
      " 'scale_pos_weight': 1.9140542377010263}\n",
      "\n",
      "# training | log loss: 44.51%, AUC: 93.82%, accuracy: 74.48%\n",
      "# testing  | log loss: 49.43%, AUC: 88.58%, accuracy: 70.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "272 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.971659299922879,\n",
      " 'gamma': 0.4954291803400268,\n",
      " 'max_depth': 4,\n",
      " 'subsample': 0.632685101381262}\n",
      "\n",
      "# training | log loss: 36.09%, AUC: 98.93%, accuracy: 93.01%\n",
      "# testing  | log loss: 41.38%, AUC: 95.16%, accuracy: 86.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "273 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9134447824041024,\n",
      " 'gamma': 0.2780355079281964,\n",
      " 'learning_rate': 0.18960042474254205,\n",
      " 'reg_alpha': 0.0031403321497421553,\n",
      " 'reg_lambda': 7.38765419308214,\n",
      " 'scale_pos_weight': 0.8865184471742475}\n",
      "\n",
      "# training | log loss: 41.46%, AUC: 93.87%, accuracy: 87.41%\n",
      "# testing  | log loss: 46.05%, AUC: 88.31%, accuracy: 77.79%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "274 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5231861400453404,\n",
      " 'colsample_bytree': 0.6626209376661133,\n",
      " 'gamma': 0.11329962311965014,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 3.651641501704362e-09,\n",
      " 'reg_lambda': 0.9936432974862974}\n",
      "\n",
      "# training | log loss: 34.92%, AUC: 99.48%, accuracy: 95.10%\n",
      "# testing  | log loss: 44.14%, AUC: 94.27%, accuracy: 84.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "275 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6214556278105031,\n",
      " 'gamma': 0.08857306486642313,\n",
      " 'reg_alpha': 0.0030970253826619293,\n",
      " 'subsample': 0.7536853054784386}\n",
      "\n",
      "# training | log loss: 42.07%, AUC: 94.67%, accuracy: 85.66%\n",
      "# testing  | log loss: 45.89%, AUC: 88.92%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "276 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9981755862655967,\n",
      " 'gamma': 0.44976230295733133,\n",
      " 'learning_rate': 0.11593813595826681,\n",
      " 'reg_alpha': 0.00040422592171716654,\n",
      " 'reg_lambda': 0.4000947121237788,\n",
      " 'subsample': 0.619269940493826}\n",
      "\n",
      "# training | log loss: 40.38%, AUC: 95.61%, accuracy: 87.06%\n",
      "# testing  | log loss: 44.94%, AUC: 91.08%, accuracy: 80.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "277 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'learning_rate': 0.08216940733052262,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 7.618114182347841,\n",
      " 'subsample': 0.7258788019975251}\n",
      "\n",
      "# training | log loss: 39.14%, AUC: 98.55%, accuracy: 79.02%\n",
      "# testing  | log loss: 43.73%, AUC: 97.53%, accuracy: 74.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "278 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5550685673015441,\n",
      " 'colsample_bytree': 0.5768692337126999,\n",
      " 'learning_rate': 0.1920015021205661,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 1.0128819685666848,\n",
      " 'subsample': 0.517755540810801}\n",
      "\n",
      "# training | log loss: 38.49%, AUC: 95.93%, accuracy: 86.01%\n",
      "# testing  | log loss: 45.48%, AUC: 89.10%, accuracy: 78.69%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "279 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6305826750143709, 'subsample': 0.7898162725699245}\n",
      "\n",
      "# training | log loss: 42.03%, AUC: 94.09%, accuracy: 84.27%\n",
      "# testing  | log loss: 46.69%, AUC: 88.20%, accuracy: 77.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "280 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.603744183183063,\n",
      " 'gamma': 0.9975386841195969,\n",
      " 'learning_rate': 0.13139912393748293,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 1.8074432774547163e-09,\n",
      " 'reg_lambda': 1.6134056134947217,\n",
      " 'scale_pos_weight': 3.8002798006945797}\n",
      "\n",
      "# training | log loss: 42.37%, AUC: 98.10%, accuracy: 73.43%\n",
      "# testing  | log loss: 49.15%, AUC: 93.42%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "281 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.8141073684912563,\n",
      " 'gamma': 0.36743830513100406,\n",
      " 'learning_rate': 0.1196752531948293,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 1.8786485941323767}\n",
      "\n",
      "# training | log loss: 43.56%, AUC: 92.51%, accuracy: 85.66%\n",
      "# testing  | log loss: 48.06%, AUC: 87.09%, accuracy: 79.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "282 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.25138103134411616,\n",
      " 'reg_lambda': 1.6593845850806417,\n",
      " 'scale_pos_weight': 2.366374773111373}\n",
      "\n",
      "# training | log loss: 45.30%, AUC: 92.26%, accuracy: 74.13%\n",
      "# testing  | log loss: 49.73%, AUC: 87.65%, accuracy: 71.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "283 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5259663830096387,\n",
      " 'colsample_bytree': 0.574099410306363,\n",
      " 'gamma': 0.18438452328778387,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 1.0079505459022345e-06,\n",
      " 'scale_pos_weight': 2.9905303842848134,\n",
      " 'subsample': 0.9721145577639636}\n",
      "\n",
      "# training | log loss: 39.75%, AUC: 99.30%, accuracy: 74.83%\n",
      "# testing  | log loss: 46.14%, AUC: 95.85%, accuracy: 71.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "284 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.652049390483421,\n",
      " 'reg_alpha': 3.6910112518923366e-09,\n",
      " 'reg_lambda': 0.923226578132168,\n",
      " 'subsample': 0.9843631982427985}\n",
      "\n",
      "# training | log loss: 44.63%, AUC: 93.47%, accuracy: 83.92%\n",
      "# testing  | log loss: 49.26%, AUC: 87.76%, accuracy: 76.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "285 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9685631751001437,\n",
      " 'gamma': 0.6150072674310296,\n",
      " 'reg_alpha': 0.0006196730651802148}\n",
      "\n",
      "# training | log loss: 42.42%, AUC: 93.69%, accuracy: 84.27%\n",
      "# testing  | log loss: 47.27%, AUC: 87.85%, accuracy: 76.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "286 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9978486956335506,\n",
      " 'gamma': 0.9799256810075381,\n",
      " 'scale_pos_weight': 2.0639311413727444,\n",
      " 'subsample': 0.6174570609601246}\n",
      "\n",
      "# training | log loss: 44.76%, AUC: 93.42%, accuracy: 76.92%\n",
      "# testing  | log loss: 49.31%, AUC: 88.04%, accuracy: 72.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "287 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'scale_pos_weight': 3.1630778755630256, 'subsample': 0.6610190958953701}\n",
      "\n",
      "# training | log loss: 44.98%, AUC: 95.86%, accuracy: 73.08%\n",
      "# testing  | log loss: 49.36%, AUC: 91.94%, accuracy: 70.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "288 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5536583520485607,\n",
      " 'colsample_bylevel': 0.9748165943869673,\n",
      " 'learning_rate': 0.11184278799970034,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.9492131223812632,\n",
      " 'reg_lambda': 2.098674358524316,\n",
      " 'scale_pos_weight': 3.0109258846454754}\n",
      "\n",
      "# training | log loss: 47.85%, AUC: 92.89%, accuracy: 72.73%\n",
      "# testing  | log loss: 53.16%, AUC: 87.19%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "289 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.8609618451883119}\n",
      "\n",
      "# training | log loss: 43.81%, AUC: 93.49%, accuracy: 85.66%\n",
      "# testing  | log loss: 48.26%, AUC: 87.77%, accuracy: 78.09%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "290 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7625514578288017,\n",
      " 'colsample_bytree': 0.9178801919637061,\n",
      " 'gamma': 0.532750285659207,\n",
      " 'reg_alpha': 1.693351413597292e-07}\n",
      "\n",
      "# training | log loss: 43.64%, AUC: 94.00%, accuracy: 86.36%\n",
      "# testing  | log loss: 48.49%, AUC: 88.37%, accuracy: 78.09%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "291 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.23701479851946916,\n",
      " 'gamma': 0.5843497404029224,\n",
      " 'learning_rate': 0.16952799247564668,\n",
      " 'reg_lambda': 2.611759301118198}\n",
      "\n",
      "# training | log loss: 37.57%, AUC: 96.23%, accuracy: 89.16%\n",
      "# testing  | log loss: 42.06%, AUC: 91.11%, accuracy: 80.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "292 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.8001750274633264,\n",
      " 'learning_rate': 0.09443674131981379,\n",
      " 'reg_alpha': 2.042947011329953e-08,\n",
      " 'reg_lambda': 1.1015838238873206,\n",
      " 'subsample': 0.6420005676867206}\n",
      "\n",
      "# training | log loss: 43.71%, AUC: 94.54%, accuracy: 87.06%\n",
      "# testing  | log loss: 47.16%, AUC: 89.37%, accuracy: 80.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "293 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6522655151247928,\n",
      " 'colsample_bylevel': 0.9148186901656441,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_alpha': 0.0019599660117358654,\n",
      " 'reg_lambda': 5.1035830960624065}\n",
      "\n",
      "# training | log loss: 51.91%, AUC: 84.92%, accuracy: 73.43%\n",
      "# testing  | log loss: 53.78%, AUC: 81.44%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "294 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5733228772630871,\n",
      " 'colsample_bylevel': 0.9977312032580481,\n",
      " 'colsample_bytree': 0.9409611390045189,\n",
      " 'learning_rate': 0.11249968584646895,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 3.056729234388235e-06,\n",
      " 'reg_lambda': 0.7092805899117693,\n",
      " 'subsample': 0.8670359987458345}\n",
      "\n",
      "# training | log loss: 49.20%, AUC: 87.55%, accuracy: 75.17%\n",
      "# testing  | log loss: 52.29%, AUC: 82.82%, accuracy: 69.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "295 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.743550589435233,\n",
      " 'colsample_bytree': 0.6739971239869498,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 8.616571202513311e-07,\n",
      " 'scale_pos_weight': 0.6446529587618857}\n",
      "\n",
      "# training | log loss: 37.64%, AUC: 99.27%, accuracy: 96.15%\n",
      "# testing  | log loss: 44.13%, AUC: 96.17%, accuracy: 89.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "296 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.148179241090053,\n",
      " 'colsample_bylevel': 0.5083695381918429,\n",
      " 'gamma': 0.18859899716938855,\n",
      " 'learning_rate': 0.17727300527672635,\n",
      " 'min_child_weight': 4,\n",
      " 'scale_pos_weight': 1.2717600369898503,\n",
      " 'subsample': 0.9921810717761956}\n",
      "\n",
      "# training | log loss: 41.04%, AUC: 93.57%, accuracy: 81.47%\n",
      "# testing  | log loss: 46.32%, AUC: 87.87%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "297 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.7311349743333434,\n",
      " 'reg_lambda': 5.926403989101486,\n",
      " 'scale_pos_weight': 1.7927312523261}\n",
      "\n",
      "# training | log loss: 46.97%, AUC: 91.27%, accuracy: 72.73%\n",
      "# testing  | log loss: 50.77%, AUC: 86.27%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "298 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.4712047255820909,\n",
      " 'reg_alpha': 0.6927515294729237,\n",
      " 'subsample': 0.7462738985799453}\n",
      "\n",
      "# training | log loss: 44.21%, AUC: 93.85%, accuracy: 87.06%\n",
      "# testing  | log loss: 47.83%, AUC: 88.01%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "299 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5393611783687096,\n",
      " 'colsample_bytree': 0.7384576356891304,\n",
      " 'max_depth': 9,\n",
      " 'reg_lambda': 2.2740695909113917}\n",
      "\n",
      "# training | log loss: 40.06%, AUC: 99.00%, accuracy: 90.56%\n",
      "# testing  | log loss: 46.24%, AUC: 95.35%, accuracy: 84.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "300 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'max_depth': 3, 'min_child_weight': 5, 'reg_lambda': 3.4486315476430485}\n",
      "\n",
      "# training | log loss: 46.41%, AUC: 90.80%, accuracy: 83.92%\n",
      "# testing  | log loss: 49.70%, AUC: 85.52%, accuracy: 76.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "301 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6497320758203631,\n",
      " 'colsample_bylevel': 0.7290137170888236,\n",
      " 'gamma': 0.33029717475365805,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 4.6935082719925125e-09}\n",
      "\n",
      "# training | log loss: 49.73%, AUC: 84.71%, accuracy: 74.48%\n",
      "# testing  | log loss: 52.55%, AUC: 81.37%, accuracy: 70.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "302 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'max_depth': 3,\n",
      " 'scale_pos_weight': 8.156588552271563,\n",
      " 'subsample': 0.8805333697234919}\n",
      "\n",
      "# training | log loss: 52.90%, AUC: 93.64%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.14%, AUC: 89.77%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "303 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.565521724304594,\n",
      " 'gamma': 0.7692719856163077,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 10}\n",
      "\n",
      "# training | log loss: 50.05%, AUC: 84.82%, accuracy: 70.98%\n",
      "# testing  | log loss: 52.43%, AUC: 80.95%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "304 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5920519466659606,\n",
      " 'colsample_bytree': 0.5661157553124714,\n",
      " 'learning_rate': 0.19158927863048633,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 1.3764386659535268e-06,\n",
      " 'scale_pos_weight': 2.167014322540696}\n",
      "\n",
      "# training | log loss: 39.11%, AUC: 97.57%, accuracy: 80.07%\n",
      "# testing  | log loss: 52.71%, AUC: 84.61%, accuracy: 71.54%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "305 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.615696304422504,\n",
      " 'colsample_bylevel': 0.7984719839716032,\n",
      " 'colsample_bytree': 0.8983906557039267,\n",
      " 'gamma': 0.44475965946898577,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 6.207052418606882e-06,\n",
      " 'reg_lambda': 2.0563404216344336,\n",
      " 'scale_pos_weight': 7.158540420641577}\n",
      "\n",
      "# training | log loss: 50.20%, AUC: 97.34%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.36%, AUC: 90.05%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "306 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.973758654846358,\n",
      " 'gamma': 0.16912749704842467,\n",
      " 'learning_rate': 0.16483230916573147,\n",
      " 'reg_lambda': 7.8347279556460085,\n",
      " 'subsample': 0.741903542353}\n",
      "\n",
      "# training | log loss: 45.20%, AUC: 92.65%, accuracy: 80.77%\n",
      "# testing  | log loss: 50.46%, AUC: 85.39%, accuracy: 74.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "307 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.932976925330389,\n",
      " 'colsample_bytree': 0.8448968996227626,\n",
      " 'learning_rate': 0.08584593307836327,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 3.089649703078951}\n",
      "\n",
      "# training | log loss: 49.70%, AUC: 92.05%, accuracy: 72.73%\n",
      "# testing  | log loss: 55.10%, AUC: 85.73%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "308 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7613109548097081,\n",
      " 'learning_rate': 0.1734103330345164,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 3.0067872786956198e-05,\n",
      " 'reg_lambda': 9.376597446028025,\n",
      " 'subsample': 0.7737373903262383}\n",
      "\n",
      "# training | log loss: 48.12%, AUC: 89.70%, accuracy: 80.07%\n",
      "# testing  | log loss: 52.15%, AUC: 83.67%, accuracy: 71.39%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "309 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5936518727994256,\n",
      " 'gamma': 0.24028138693242151,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 0.004974056521604443,\n",
      " 'scale_pos_weight': 3.1758206172143653,\n",
      " 'subsample': 0.8494657037571602}\n",
      "\n",
      "# training | log loss: 51.11%, AUC: 90.54%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.08%, AUC: 84.56%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "310 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.5661595787625048}\n",
      "\n",
      "# training | log loss: 45.10%, AUC: 93.91%, accuracy: 84.62%\n",
      "# testing  | log loss: 50.34%, AUC: 87.55%, accuracy: 76.30%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "311 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.69320990721886,\n",
      " 'learning_rate': 0.11097412090435686,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 3.3420007049129664e-07,\n",
      " 'reg_lambda': 4.356665313321582,\n",
      " 'scale_pos_weight': 1.4126621621456603,\n",
      " 'subsample': 0.7323852689164327}\n",
      "\n",
      "# training | log loss: 42.39%, AUC: 98.38%, accuracy: 84.62%\n",
      "# testing  | log loss: 48.41%, AUC: 91.89%, accuracy: 77.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "312 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7458910496701082,\n",
      " 'colsample_bylevel': 0.7166355994076681,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.07050721754965068}\n",
      "\n",
      "# training | log loss: 50.67%, AUC: 84.09%, accuracy: 74.48%\n",
      "# testing  | log loss: 53.59%, AUC: 81.30%, accuracy: 70.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "313 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6327787475748521,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.009977237348724044}\n",
      "\n",
      "# training | log loss: 50.61%, AUC: 85.68%, accuracy: 72.73%\n",
      "# testing  | log loss: 52.83%, AUC: 82.42%, accuracy: 69.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "314 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'min_child_weight': 2,\n",
      " 'reg_lambda': 8.203141302180395,\n",
      " 'scale_pos_weight': 2.2723972857848573}\n",
      "\n",
      "# training | log loss: 49.13%, AUC: 90.41%, accuracy: 72.73%\n",
      "# testing  | log loss: 53.12%, AUC: 85.29%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "315 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6833175479693611,\n",
      " 'reg_alpha': 7.436168702985275e-08,\n",
      " 'scale_pos_weight': 5.367990373767937}\n",
      "\n",
      "# training | log loss: 52.17%, AUC: 92.78%, accuracy: 72.73%\n",
      "# testing  | log loss: 57.41%, AUC: 87.19%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "316 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.8036267766238064,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 0.00027289997450528057,\n",
      " 'reg_lambda': 3.6061822230420137}\n",
      "\n",
      "# training | log loss: 48.29%, AUC: 88.81%, accuracy: 77.97%\n",
      "# testing  | log loss: 51.28%, AUC: 84.17%, accuracy: 71.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "317 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.4161990851268482,\n",
      " 'colsample_bylevel': 0.560044927397201,\n",
      " 'colsample_bytree': 0.8163058831679743,\n",
      " 'learning_rate': 0.17255768066400928,\n",
      " 'max_depth': 5,\n",
      " 'reg_lambda': 7.4103600989476925,\n",
      " 'subsample': 0.7884642223443247}\n",
      "\n",
      "# training | log loss: 43.60%, AUC: 95.20%, accuracy: 86.36%\n",
      "# testing  | log loss: 48.46%, AUC: 90.13%, accuracy: 76.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "318 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7067354787007608,\n",
      " 'colsample_bylevel': 0.9183479691501358,\n",
      " 'colsample_bytree': 0.5162812196151187,\n",
      " 'gamma': 0.49831893595708665,\n",
      " 'learning_rate': 0.12462218339599088,\n",
      " 'max_depth': 3}\n",
      "\n",
      "# training | log loss: 47.85%, AUC: 90.63%, accuracy: 77.27%\n",
      "# testing  | log loss: 52.53%, AUC: 83.94%, accuracy: 71.39%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "319 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.6255292873810094,\n",
      " 'gamma': 0.3974817006500798,\n",
      " 'reg_alpha': 1.0374076509189266e-06,\n",
      " 'subsample': 0.8499235857290247}\n",
      "\n",
      "# training | log loss: 45.95%, AUC: 93.44%, accuracy: 79.37%\n",
      "# testing  | log loss: 50.54%, AUC: 87.30%, accuracy: 73.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "320 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.9697050378837935,\n",
      " 'colsample_bytree': 0.7302799708530754,\n",
      " 'gamma': 0.06718402577293925,\n",
      " 'scale_pos_weight': 1.290729263743755}\n",
      "\n",
      "# training | log loss: 45.36%, AUC: 93.92%, accuracy: 80.42%\n",
      "# testing  | log loss: 49.84%, AUC: 88.61%, accuracy: 75.86%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "321 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6179655051303428,\n",
      " 'colsample_bytree': 0.8479450694691918,\n",
      " 'gamma': 0.6378692501491362,\n",
      " 'learning_rate': 0.09279063856660422,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 8.10855601253821e-09,\n",
      " 'reg_lambda': 3.1141558583347435,\n",
      " 'scale_pos_weight': 0.8675833377943077,\n",
      " 'subsample': 0.9041252342269195}\n",
      "\n",
      "# training | log loss: 43.19%, AUC: 97.60%, accuracy: 89.86%\n",
      "# testing  | log loss: 47.96%, AUC: 92.89%, accuracy: 82.12%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "322 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'min_child_weight': 8,\n",
      " 'reg_alpha': 0.028525568802265026,\n",
      " 'reg_lambda': 3.0656313688904047}\n",
      "\n",
      "# training | log loss: 49.50%, AUC: 85.80%, accuracy: 73.43%\n",
      "# testing  | log loss: 52.16%, AUC: 81.80%, accuracy: 68.41%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "323 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5147348640565046,\n",
      " 'colsample_bylevel': 0.5419452765628369,\n",
      " 'colsample_bytree': 0.7999523588528433,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 4}\n",
      "\n",
      "# training | log loss: 46.06%, AUC: 92.67%, accuracy: 85.66%\n",
      "# testing  | log loss: 50.76%, AUC: 87.24%, accuracy: 78.54%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "324 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 19\n",
      "{'learning_rate': 0.072185059739043,\n",
      " 'min_child_weight': 3,\n",
      " 'scale_pos_weight': 5.647619051307334}\n",
      "\n",
      "# training | log loss: 53.36%, AUC: 88.15%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.07%, AUC: 82.75%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 27.0 configurations x 11.1 iterations each\n",
      "\n",
      "325 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.2069 (run 244)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.8955964486499088,\n",
      " 'learning_rate': 0.1822287061793478,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 5.151870309734203e-06}\n",
      "\n",
      "# training | log loss: 7.13%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 14.14%, AUC: 99.27%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "326 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.49378639277054015,\n",
      " 'colsample_bylevel': 0.8945132919352095,\n",
      " 'colsample_bytree': 0.9014095722354097,\n",
      " 'gamma': 0.710602406500149,\n",
      " 'learning_rate': 0.19950488474220546,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 3.8977961208074253e-10}\n",
      "\n",
      "# training | log loss: 11.95%, AUC: 99.98%, accuracy: 98.60%\n",
      "# testing  | log loss: 18.44%, AUC: 99.26%, accuracy: 95.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "327 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.6038238659359236,\n",
      " 'colsample_bylevel': 0.9126925240986197,\n",
      " 'learning_rate': 0.19367007748415568,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 4.319346134769293e-08,\n",
      " 'reg_lambda': 1.5912281395622878,\n",
      " 'subsample': 0.8727066498360705}\n",
      "\n",
      "# training | log loss: 8.64%, AUC: 99.99%, accuracy: 99.65%\n",
      "# testing  | log loss: 16.88%, AUC: 99.19%, accuracy: 95.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "328 | Thu Oct 26 04:30:51 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.8324726821585812,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 4.871354923609551e-07,\n",
      " 'scale_pos_weight': 2.649572288768033}\n",
      "\n",
      "# training | log loss: 7.94%, AUC: 100.00%, accuracy: 98.95%\n",
      "# testing  | log loss: 15.83%, AUC: 99.14%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "329 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.3798523831040156, 'max_depth': 6}\n",
      "\n",
      "# training | log loss: 10.20%, AUC: 99.97%, accuracy: 99.30%\n",
      "# testing  | log loss: 16.60%, AUC: 99.09%, accuracy: 95.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "330 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 10.01%, AUC: 99.97%, accuracy: 97.55%\n",
      "# testing  | log loss: 15.73%, AUC: 99.37%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "331 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.24705682268534784,\n",
      " 'colsample_bytree': 0.8333329461733328,\n",
      " 'learning_rate': 0.11860992120109111,\n",
      " 'max_depth': 8,\n",
      " 'scale_pos_weight': 3.104388421405455}\n",
      "\n",
      "# training | log loss: 8.96%, AUC: 100.00%, accuracy: 98.25%\n",
      "# testing  | log loss: 17.61%, AUC: 99.16%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "332 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7155966658048305,\n",
      " 'colsample_bytree': 0.7839190409481855,\n",
      " 'learning_rate': 0.18561696557352284,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 4.114670207304841,\n",
      " 'subsample': 0.7454502463391672}\n",
      "\n",
      "# training | log loss: 9.15%, AUC: 99.99%, accuracy: 98.60%\n",
      "# testing  | log loss: 20.54%, AUC: 98.75%, accuracy: 91.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "333 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.5777174461906869,\n",
      " 'colsample_bytree': 0.7913208027619905,\n",
      " 'gamma': 0.8724127061974302,\n",
      " 'learning_rate': 0.19584124144251125,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 5.046195583774196e-10}\n",
      "\n",
      "# training | log loss: 16.21%, AUC: 99.86%, accuracy: 98.60%\n",
      "# testing  | log loss: 25.11%, AUC: 97.95%, accuracy: 91.21%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "334 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.5471451162671814,\n",
      " 'gamma': 0.6388624569536315,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 1.785888759098008e-10}\n",
      "\n",
      "# training | log loss: 17.20%, AUC: 99.86%, accuracy: 97.90%\n",
      "# testing  | log loss: 23.96%, AUC: 98.08%, accuracy: 94.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "335 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.3661645557587426,\n",
      " 'gamma': 0.45031377991236576,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 1.3062672539931609e-05,\n",
      " 'reg_lambda': 3.617740190976021}\n",
      "\n",
      "# training | log loss: 17.02%, AUC: 99.86%, accuracy: 98.25%\n",
      "# testing  | log loss: 22.40%, AUC: 98.91%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "336 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7963286086467167,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 4.751486756650194e-06,\n",
      " 'reg_lambda': 1.13546172286901,\n",
      " 'subsample': 0.8415621755378428}\n",
      "\n",
      "# training | log loss: 13.30%, AUC: 99.96%, accuracy: 98.25%\n",
      "# testing  | log loss: 21.48%, AUC: 98.71%, accuracy: 94.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "337 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7552722275815652,\n",
      " 'colsample_bylevel': 0.9512297075529536,\n",
      " 'colsample_bytree': 0.9421311223833008,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 0.747870416011159,\n",
      " 'subsample': 0.8909931589895714}\n",
      "\n",
      "# training | log loss: 14.30%, AUC: 99.95%, accuracy: 98.95%\n",
      "# testing  | log loss: 22.55%, AUC: 98.74%, accuracy: 94.34%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "338 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.5113026802198888,\n",
      " 'colsample_bylevel': 0.7262821851431096,\n",
      " 'gamma': 0.07444416308921997,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 4.3561150798818505e-08}\n",
      "\n",
      "# training | log loss: 16.92%, AUC: 99.84%, accuracy: 98.60%\n",
      "# testing  | log loss: 24.11%, AUC: 98.44%, accuracy: 94.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "339 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.8043503553771844, 'max_depth': 4}\n",
      "\n",
      "# training | log loss: 15.91%, AUC: 99.88%, accuracy: 98.25%\n",
      "# testing  | log loss: 21.86%, AUC: 99.07%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "340 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'max_depth': 5,\n",
      " 'reg_lambda': 3.3396078576316404,\n",
      " 'subsample': 0.8420720530888733}\n",
      "\n",
      "# training | log loss: 17.88%, AUC: 99.86%, accuracy: 98.25%\n",
      "# testing  | log loss: 24.73%, AUC: 98.67%, accuracy: 94.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "341 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.9479239700346893,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 5.133347471643192}\n",
      "\n",
      "# training | log loss: 19.23%, AUC: 99.90%, accuracy: 98.25%\n",
      "# testing  | log loss: 25.11%, AUC: 99.02%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "342 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7179469599897778,\n",
      " 'gamma': 0.480621024940986,\n",
      " 'learning_rate': 0.16337681307900698,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 3.3298698690019415e-09,\n",
      " 'reg_lambda': 3.905974270599137}\n",
      "\n",
      "# training | log loss: 20.84%, AUC: 99.68%, accuracy: 97.20%\n",
      "# testing  | log loss: 27.69%, AUC: 97.51%, accuracy: 91.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "343 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.5900643882915451,\n",
      " 'learning_rate': 0.18101135758033604,\n",
      " 'reg_alpha': 0.0002920421123215135}\n",
      "\n",
      "# training | log loss: 17.12%, AUC: 99.75%, accuracy: 97.90%\n",
      "# testing  | log loss: 23.88%, AUC: 98.16%, accuracy: 92.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "344 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.3807565479492939, 'learning_rate': 0.16336723712254608}\n",
      "\n",
      "# training | log loss: 18.95%, AUC: 99.64%, accuracy: 97.55%\n",
      "# testing  | log loss: 25.80%, AUC: 97.84%, accuracy: 91.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "345 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'gamma': 0.1432025872809206,\n",
      " 'learning_rate': 0.19211835848743014,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 5.0239978681558045e-08}\n",
      "\n",
      "# training | log loss: 21.91%, AUC: 99.30%, accuracy: 97.20%\n",
      "# testing  | log loss: 29.14%, AUC: 96.24%, accuracy: 89.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "346 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'learning_rate': 0.17526187147483882, 'reg_lambda': 1.3563685722513745}\n",
      "\n",
      "# training | log loss: 19.08%, AUC: 99.63%, accuracy: 97.90%\n",
      "# testing  | log loss: 25.39%, AUC: 97.99%, accuracy: 92.40%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "347 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7619624598977952,\n",
      " 'colsample_bytree': 0.9810660179429012,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 3.891601614828777}\n",
      "\n",
      "# training | log loss: 18.35%, AUC: 99.91%, accuracy: 94.06%\n",
      "# testing  | log loss: 24.73%, AUC: 99.11%, accuracy: 89.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "348 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.971659299922879,\n",
      " 'gamma': 0.4954291803400268,\n",
      " 'max_depth': 4,\n",
      " 'subsample': 0.632685101381262}\n",
      "\n",
      "# training | log loss: 21.77%, AUC: 99.68%, accuracy: 97.55%\n",
      "# testing  | log loss: 29.75%, AUC: 96.99%, accuracy: 89.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "349 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.23701479851946916,\n",
      " 'gamma': 0.5843497404029224,\n",
      " 'learning_rate': 0.16952799247564668,\n",
      " 'reg_lambda': 2.611759301118198}\n",
      "\n",
      "# training | log loss: 22.37%, AUC: 99.62%, accuracy: 96.85%\n",
      "# testing  | log loss: 28.75%, AUC: 97.32%, accuracy: 90.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "350 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'max_depth': 7,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.0006876224413118469,\n",
      " 'scale_pos_weight': 5.0575258348762455}\n",
      "\n",
      "# training | log loss: 20.41%, AUC: 99.79%, accuracy: 91.26%\n",
      "# testing  | log loss: 28.92%, AUC: 97.44%, accuracy: 84.20%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "351 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 56\n",
      "{'learning_rate': 0.08216940733052262,\n",
      " 'max_depth': 4,\n",
      " 'scale_pos_weight': 7.618114182347841,\n",
      " 'subsample': 0.7258788019975251}\n",
      "\n",
      "# training | log loss: 23.99%, AUC: 99.63%, accuracy: 89.86%\n",
      "# testing  | log loss: 30.24%, AUC: 98.89%, accuracy: 85.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9.0 configurations x 33.3 iterations each\n",
      "\n",
      "352 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1414 (run 325)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bytree': 0.8955964486499088,\n",
      " 'learning_rate': 0.1822287061793478,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 5.151870309734203e-06}\n",
      "\n",
      "# training | log loss: 3.99%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.22%, AUC: 99.28%, accuracy: 95.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "353 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1222 (run 352)\n",
      "\n",
      "n_estimators: 167\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 3.95%, AUC: 100.00%, accuracy: 99.30%\n",
      "# testing  | log loss: 11.53%, AUC: 99.47%, accuracy: 96.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "354 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.8324726821585812,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 4.871354923609551e-07,\n",
      " 'scale_pos_weight': 2.649572288768033}\n",
      "\n",
      "# training | log loss: 3.67%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.29%, AUC: 99.19%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "355 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.3798523831040156, 'max_depth': 6}\n",
      "\n",
      "# training | log loss: 5.44%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 13.38%, AUC: 99.28%, accuracy: 95.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "356 | Thu Oct 26 04:30:52 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.6038238659359236,\n",
      " 'colsample_bylevel': 0.9126925240986197,\n",
      " 'learning_rate': 0.19367007748415568,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 4.319346134769293e-08,\n",
      " 'reg_lambda': 1.5912281395622878,\n",
      " 'subsample': 0.8727066498360705}\n",
      "\n",
      "# training | log loss: 4.64%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 13.42%, AUC: 99.24%, accuracy: 95.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "357 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.24705682268534784,\n",
      " 'colsample_bytree': 0.8333329461733328,\n",
      " 'learning_rate': 0.11860992120109111,\n",
      " 'max_depth': 8,\n",
      " 'scale_pos_weight': 3.104388421405455}\n",
      "\n",
      "# training | log loss: 3.63%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 12.46%, AUC: 99.27%, accuracy: 96.72%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "358 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.49378639277054015,\n",
      " 'colsample_bylevel': 0.8945132919352095,\n",
      " 'colsample_bytree': 0.9014095722354097,\n",
      " 'gamma': 0.710602406500149,\n",
      " 'learning_rate': 0.19950488474220546,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 3.8977961208074253e-10}\n",
      "\n",
      "# training | log loss: 10.57%, AUC: 99.99%, accuracy: 98.60%\n",
      "# testing  | log loss: 17.34%, AUC: 99.28%, accuracy: 95.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "359 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.7155966658048305,\n",
      " 'colsample_bytree': 0.7839190409481855,\n",
      " 'learning_rate': 0.18561696557352284,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 4.114670207304841,\n",
      " 'subsample': 0.7454502463391672}\n",
      "\n",
      "# training | log loss: 3.84%, AUC: 100.00%, accuracy: 99.30%\n",
      "# testing  | log loss: 15.71%, AUC: 98.89%, accuracy: 93.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "360 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.7963286086467167,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 4.751486756650194e-06,\n",
      " 'reg_lambda': 1.13546172286901,\n",
      " 'subsample': 0.8415621755378428}\n",
      "\n",
      "# training | log loss: 6.38%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 16.01%, AUC: 98.84%, accuracy: 94.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 100.0 iterations each\n",
      "\n",
      "361 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1153 (run 353)\n",
      "\n",
      "n_estimators: 500\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 1.99%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.17%, AUC: 99.42%, accuracy: 97.02%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "362 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1017 (run 361)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bytree': 0.8955964486499088,\n",
      " 'learning_rate': 0.1822287061793478,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 5.151870309734203e-06}\n",
      "\n",
      "# training | log loss: 2.45%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 11.27%, AUC: 99.30%, accuracy: 95.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "363 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1017 (run 361)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.8324726821585812,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 4.871354923609551e-07,\n",
      " 'scale_pos_weight': 2.649572288768033}\n",
      "\n",
      "# training | log loss: 2.11%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.75%, AUC: 99.25%, accuracy: 96.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 1.0 configurations x 300.0 iterations each\n",
      "\n",
      "364 | Thu Oct 26 04:30:53 2017 | lowest loss so far: 0.1017 (run 361)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'max_depth': 5,\n",
      " 'scale_pos_weight': 4.126107644174415,\n",
      " 'subsample': 0.9504702059140802}\n",
      "\n",
      "# training | log loss: 1.29%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 9.96%, AUC: 99.32%, accuracy: 96.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 81 configurations x 3.7 iterations each\n",
      "\n",
      "365 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3840712639095013,\n",
      " 'colsample_bytree': 0.5413750290387624,\n",
      " 'gamma': 0.6658761677161216,\n",
      " 'learning_rate': 0.1221391696877236,\n",
      " 'max_depth': 7,\n",
      " 'reg_lambda': 0.5378968740452976,\n",
      " 'scale_pos_weight': 9.142046398716356}\n",
      "\n",
      "# training | log loss: 56.03%, AUC: 96.07%, accuracy: 68.88%\n",
      "# testing  | log loss: 65.72%, AUC: 84.32%, accuracy: 66.62%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "366 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.855169141464625,\n",
      " 'learning_rate': 0.16937063539027503,\n",
      " 'reg_alpha': 0.011847663086805182,\n",
      " 'reg_lambda': 9.539346650511753,\n",
      " 'scale_pos_weight': 2.822299921277876}\n",
      "\n",
      "# training | log loss: 49.94%, AUC: 91.48%, accuracy: 72.73%\n",
      "# testing  | log loss: 56.31%, AUC: 85.44%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "367 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6652551374860076,\n",
      " 'colsample_bytree': 0.7859998132765442,\n",
      " 'learning_rate': 0.03611939016274157,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 5.951088843337732}\n",
      "\n",
      "# training | log loss: 56.77%, AUC: 96.71%, accuracy: 83.57%\n",
      "# testing  | log loss: 59.02%, AUC: 91.45%, accuracy: 76.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "368 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.34065848277535987,\n",
      " 'colsample_bytree': 0.7073648512400248,\n",
      " 'gamma': 0.27203670758408527,\n",
      " 'max_depth': 7,\n",
      " 'reg_lambda': 8.087849392743939}\n",
      "\n",
      "# training | log loss: 49.05%, AUC: 94.81%, accuracy: 86.71%\n",
      "# testing  | log loss: 52.52%, AUC: 89.54%, accuracy: 80.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "369 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.18221311458919132,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 3.494421225268913}\n",
      "\n",
      "# training | log loss: 54.03%, AUC: 81.71%, accuracy: 74.83%\n",
      "# testing  | log loss: 56.85%, AUC: 76.42%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "370 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7312359273842766,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'subsample': 0.781495676324822}\n",
      "\n",
      "# training | log loss: 45.44%, AUC: 92.44%, accuracy: 83.22%\n",
      "# testing  | log loss: 49.93%, AUC: 86.52%, accuracy: 75.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "371 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7491853530097159,\n",
      " 'gamma': 0.7273398178683868,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 6.851534442266308,\n",
      " 'scale_pos_weight': 4.479196809583049,\n",
      " 'subsample': 0.6579583106930927}\n",
      "\n",
      "# training | log loss: 60.03%, AUC: 88.94%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.84%, AUC: 83.56%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "372 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.8151696738769818,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 2.698618435569416,\n",
      " 'scale_pos_weight': 6.414127851750693,\n",
      " 'subsample': 0.8624872536492023}\n",
      "\n",
      "# training | log loss: 30.50%, AUC: 99.70%, accuracy: 87.06%\n",
      "# testing  | log loss: 38.84%, AUC: 97.83%, accuracy: 81.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "373 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5674277192135102,\n",
      " 'colsample_bytree': 0.7776914067616947,\n",
      " 'learning_rate': 0.15346011700817663,\n",
      " 'subsample': 0.6100914311072461}\n",
      "\n",
      "# training | log loss: 41.50%, AUC: 93.92%, accuracy: 84.27%\n",
      "# testing  | log loss: 47.23%, AUC: 88.04%, accuracy: 76.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "374 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7943179979721814,\n",
      " 'gamma': 0.6573832187768602,\n",
      " 'learning_rate': 0.041008412847909244,\n",
      " 'reg_alpha': 8.226340830240577e-09,\n",
      " 'reg_lambda': 8.455702644218801,\n",
      " 'subsample': 0.9607698351701242}\n",
      "\n",
      "# training | log loss: 57.70%, AUC: 87.95%, accuracy: 81.82%\n",
      "# testing  | log loss: 59.33%, AUC: 83.71%, accuracy: 76.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "375 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.8267841185768466,\n",
      " 'gamma': 0.0804826410870263,\n",
      " 'learning_rate': 0.07108728817313532,\n",
      " 'min_child_weight': 10,\n",
      " 'subsample': 0.8742806575692171}\n",
      "\n",
      "# training | log loss: 55.87%, AUC: 82.74%, accuracy: 73.78%\n",
      "# testing  | log loss: 56.86%, AUC: 81.22%, accuracy: 70.04%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "376 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.2789308052533788,\n",
      " 'colsample_bylevel': 0.7015152053903064,\n",
      " 'colsample_bytree': 0.987555363520406,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 9.598481900914575,\n",
      " 'scale_pos_weight': 7.524722114682625}\n",
      "\n",
      "# training | log loss: 65.52%, AUC: 79.63%, accuracy: 65.38%\n",
      "# testing  | log loss: 68.43%, AUC: 77.70%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "377 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.1272916023672889,\n",
      " 'colsample_bytree': 0.8747124135039419,\n",
      " 'gamma': 0.13720995478231923,\n",
      " 'learning_rate': 0.0772752289801024,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_alpha': 0.014553873162756848,\n",
      " 'scale_pos_weight': 8.369379895525729,\n",
      " 'subsample': 0.7610098146937079}\n",
      "\n",
      "# training | log loss: 57.75%, AUC: 89.82%, accuracy: 66.43%\n",
      "# testing  | log loss: 60.67%, AUC: 84.48%, accuracy: 65.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "378 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5083908037166951,\n",
      " 'colsample_bylevel': 0.9614315424132893,\n",
      " 'gamma': 0.7760615285021177,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 0.00014469325299927614,\n",
      " 'reg_lambda': 2.577568676699842,\n",
      " 'scale_pos_weight': 5.027496118533955}\n",
      "\n",
      "# training | log loss: 54.00%, AUC: 90.89%, accuracy: 72.73%\n",
      "# testing  | log loss: 59.18%, AUC: 85.32%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "379 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.6399166599561927,\n",
      " 'learning_rate': 0.0900800005157166,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4}\n",
      "\n",
      "# training | log loss: 45.74%, AUC: 94.28%, accuracy: 84.97%\n",
      "# testing  | log loss: 50.11%, AUC: 88.15%, accuracy: 76.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "380 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.4745327859343763,\n",
      " 'colsample_bytree': 0.549433563852756,\n",
      " 'gamma': 0.7384811297117378,\n",
      " 'learning_rate': 0.07341037511057066,\n",
      " 'max_depth': 10,\n",
      " 'scale_pos_weight': 2.5257240272244927,\n",
      " 'subsample': 0.9691916830957815}\n",
      "\n",
      "# training | log loss: 47.92%, AUC: 98.04%, accuracy: 73.78%\n",
      "# testing  | log loss: 53.28%, AUC: 90.56%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "381 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7754524174561226,\n",
      " 'colsample_bylevel': 0.9927754514687885,\n",
      " 'min_child_weight': 5,\n",
      " 'scale_pos_weight': 4.6290692277444885,\n",
      " 'subsample': 0.6967130929408285}\n",
      "\n",
      "# training | log loss: 57.94%, AUC: 89.79%, accuracy: 66.78%\n",
      "# testing  | log loss: 65.23%, AUC: 82.25%, accuracy: 65.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "382 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.785878543101922,\n",
      " 'colsample_bytree': 0.5370798955271514,\n",
      " 'gamma': 0.6371488133258262,\n",
      " 'learning_rate': 0.14285412866425448,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 4.552100641912084}\n",
      "\n",
      "# training | log loss: 52.40%, AUC: 82.20%, accuracy: 73.43%\n",
      "# testing  | log loss: 54.68%, AUC: 79.34%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "383 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'learning_rate': 0.014426428696209272,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 0.0005970846208390623,\n",
      " 'reg_lambda': 3.0193800020567076,\n",
      " 'subsample': 0.8853118945787877}\n",
      "\n",
      "# training | log loss: 58.48%, AUC: 99.08%, accuracy: 95.10%\n",
      "# testing  | log loss: 59.73%, AUC: 98.03%, accuracy: 93.59%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "384 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9994589148122417,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 1.472282329092824,\n",
      " 'subsample': 0.834882279136153}\n",
      "\n",
      "# training | log loss: 52.54%, AUC: 84.31%, accuracy: 75.52%\n",
      "# testing  | log loss: 54.43%, AUC: 81.59%, accuracy: 74.66%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "385 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7337274994924539,\n",
      " 'colsample_bylevel': 0.798501463677004,\n",
      " 'colsample_bytree': 0.5647414626929539,\n",
      " 'gamma': 0.2814814630849053,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 1.4622022968734962,\n",
      " 'scale_pos_weight': 2.016317604454318,\n",
      " 'subsample': 0.899689278961125}\n",
      "\n",
      "# training | log loss: 55.84%, AUC: 84.57%, accuracy: 65.38%\n",
      "# testing  | log loss: 58.56%, AUC: 81.55%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "386 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6970131740513191,\n",
      " 'colsample_bytree': 0.7972333738336109,\n",
      " 'gamma': 0.4135769743353275,\n",
      " 'learning_rate': 0.12017646654020342,\n",
      " 'min_child_weight': 7,\n",
      " 'scale_pos_weight': 6.948278120662276,\n",
      " 'subsample': 0.7847963211745241}\n",
      "\n",
      "# training | log loss: 66.39%, AUC: 87.74%, accuracy: 65.38%\n",
      "# testing  | log loss: 71.52%, AUC: 80.61%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "387 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6964209835001935,\n",
      " 'colsample_bylevel': 0.6762002171504875,\n",
      " 'gamma': 0.62807654069279,\n",
      " 'learning_rate': 0.08772121343154508,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 3.321130304048389e-08,\n",
      " 'reg_lambda': 9.759413393334633,\n",
      " 'subsample': 0.6952629797710734}\n",
      "\n",
      "# training | log loss: 57.34%, AUC: 78.99%, accuracy: 65.38%\n",
      "# testing  | log loss: 58.17%, AUC: 77.79%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "388 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.30391343653280983,\n",
      " 'gamma': 0.6027285437016157,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 0.0034525862653889848}\n",
      "\n",
      "# training | log loss: 23.02%, AUC: 99.67%, accuracy: 97.20%\n",
      "# testing  | log loss: 26.45%, AUC: 98.59%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "389 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.661486209096725,\n",
      " 'colsample_bytree': 0.9369196999369636,\n",
      " 'min_child_weight': 8}\n",
      "\n",
      "# training | log loss: 48.80%, AUC: 85.48%, accuracy: 74.83%\n",
      "# testing  | log loss: 51.88%, AUC: 81.26%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "390 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.6908996058406087,\n",
      " 'colsample_bytree': 0.9454870758351958,\n",
      " 'learning_rate': 0.05503408226793185,\n",
      " 'max_depth': 10,\n",
      " 'reg_alpha': 7.385164780045698e-08,\n",
      " 'subsample': 0.8314248137466296}\n",
      "\n",
      "# training | log loss: 40.63%, AUC: 99.32%, accuracy: 95.80%\n",
      "# testing  | log loss: 45.63%, AUC: 96.97%, accuracy: 90.46%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "391 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.54459978650644,\n",
      " 'colsample_bytree': 0.9794599007797682,\n",
      " 'gamma': 0.29731804276784135,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 7.7012399175769675,\n",
      " 'subsample': 0.8443853139893376}\n",
      "\n",
      "# training | log loss: 44.22%, AUC: 97.91%, accuracy: 75.52%\n",
      "# testing  | log loss: 51.51%, AUC: 93.05%, accuracy: 72.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "392 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7850963426046288,\n",
      " 'colsample_bytree': 0.9767495621212123,\n",
      " 'learning_rate': 0.042482219119862545,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_lambda': 9.126805083559336,\n",
      " 'scale_pos_weight': 2.009379992101542,\n",
      " 'subsample': 0.6199402575993695}\n",
      "\n",
      "# training | log loss: 60.81%, AUC: 80.25%, accuracy: 65.38%\n",
      "# testing  | log loss: 61.27%, AUC: 80.24%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "393 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6364825933010121,\n",
      " 'colsample_bylevel': 0.5005956284701243,\n",
      " 'colsample_bytree': 0.8030991211208678,\n",
      " 'gamma': 0.6288840799837556,\n",
      " 'learning_rate': 0.04598477174458998,\n",
      " 'max_depth': 8,\n",
      " 'subsample': 0.7164496617876075}\n",
      "\n",
      "# training | log loss: 49.28%, AUC: 97.20%, accuracy: 79.37%\n",
      "# testing  | log loss: 53.25%, AUC: 90.68%, accuracy: 73.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "394 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5943328188419996,\n",
      " 'colsample_bytree': 0.8239909579148442,\n",
      " 'learning_rate': 0.013343627138163332,\n",
      " 'min_child_weight': 5,\n",
      " 'subsample': 0.6950782098468951}\n",
      "\n",
      "# training | log loss: 64.92%, AUC: 82.93%, accuracy: 73.43%\n",
      "# testing  | log loss: 65.41%, AUC: 78.05%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "395 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6991231488018282,\n",
      " 'colsample_bylevel': 0.5672836772345823,\n",
      " 'colsample_bytree': 0.7897096025213048,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 3.018234235556009e-09,\n",
      " 'subsample': 0.772811524170552}\n",
      "\n",
      "# training | log loss: 51.67%, AUC: 84.46%, accuracy: 73.08%\n",
      "# testing  | log loss: 53.10%, AUC: 82.04%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "396 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3976513079834556,\n",
      " 'colsample_bylevel': 0.8077427624809828,\n",
      " 'colsample_bytree': 0.6704370020047661,\n",
      " 'reg_alpha': 0.4436276666345138,\n",
      " 'subsample': 0.9262811684482923}\n",
      "\n",
      "# training | log loss: 48.02%, AUC: 91.40%, accuracy: 82.52%\n",
      "# testing  | log loss: 52.19%, AUC: 86.31%, accuracy: 75.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "397 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.8391395487659115,\n",
      " 'gamma': 0.7108843288236422,\n",
      " 'learning_rate': 0.10746188372163865,\n",
      " 'reg_alpha': 0.002176283171889116,\n",
      " 'scale_pos_weight': 4.077313236689274}\n",
      "\n",
      "# training | log loss: 49.19%, AUC: 92.55%, accuracy: 72.73%\n",
      "# testing  | log loss: 54.19%, AUC: 87.61%, accuracy: 70.34%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "398 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.1567962968259444,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 6.7728413021229,\n",
      " 'subsample': 0.5660710900289383}\n",
      "\n",
      "# training | log loss: 60.04%, AUC: 82.02%, accuracy: 70.98%\n",
      "# testing  | log loss: 60.89%, AUC: 81.09%, accuracy: 69.30%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "399 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5175008993707522,\n",
      " 'colsample_bytree': 0.5226346519166902,\n",
      " 'gamma': 0.999979275038891,\n",
      " 'learning_rate': 0.03658005585682172,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 8.250775883758134e-09,\n",
      " 'reg_lambda': 0.7429331538871984,\n",
      " 'scale_pos_weight': 0.38194316728050837,\n",
      " 'subsample': 0.8702569440284857}\n",
      "\n",
      "# training | log loss: 66.00%, AUC: 85.72%, accuracy: 62.24%\n",
      "# testing  | log loss: 66.79%, AUC: 80.17%, accuracy: 66.32%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "400 | Thu Oct 26 04:30:54 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.25617709239892106,\n",
      " 'colsample_bylevel': 0.6514611241213426,\n",
      " 'gamma': 0.8650008839660404,\n",
      " 'max_depth': 2}\n",
      "\n",
      "# training | log loss: 54.00%, AUC: 82.18%, accuracy: 70.28%\n",
      "# testing  | log loss: 56.64%, AUC: 77.87%, accuracy: 66.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "401 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6796144683144936,\n",
      " 'colsample_bylevel': 0.9541134895874062,\n",
      " 'colsample_bytree': 0.6110502808774801,\n",
      " 'learning_rate': 0.03052364131473788,\n",
      " 'reg_alpha': 0.01669665461613282,\n",
      " 'subsample': 0.7411996719342004}\n",
      "\n",
      "# training | log loss: 57.04%, AUC: 89.45%, accuracy: 65.38%\n",
      "# testing  | log loss: 58.81%, AUC: 83.74%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "402 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7700666689121771,\n",
      " 'colsample_bytree': 0.6121175550352376,\n",
      " 'learning_rate': 0.1175507621332706,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 6,\n",
      " 'subsample': 0.7486952786804627}\n",
      "\n",
      "# training | log loss: 53.86%, AUC: 81.69%, accuracy: 73.43%\n",
      "# testing  | log loss: 55.87%, AUC: 78.56%, accuracy: 70.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "403 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9383459842259467,\n",
      " 'reg_lambda': 9.403878216422838,\n",
      " 'subsample': 0.5575543341740264}\n",
      "\n",
      "# training | log loss: 53.37%, AUC: 89.08%, accuracy: 75.52%\n",
      "# testing  | log loss: 55.89%, AUC: 83.37%, accuracy: 72.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "404 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9780974248059389,\n",
      " 'gamma': 0.33407410112603664,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 0.0029187141471454818,\n",
      " 'reg_lambda': 8.96344002436873}\n",
      "\n",
      "# training | log loss: 50.19%, AUC: 90.07%, accuracy: 82.17%\n",
      "# testing  | log loss: 52.77%, AUC: 84.79%, accuracy: 73.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "405 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.3113586630068307,\n",
      " 'colsample_bylevel': 0.624938668372184,\n",
      " 'gamma': 0.7372508016729298,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 0.0003505674979105522,\n",
      " 'reg_lambda': 9.860962990987865,\n",
      " 'subsample': 0.8782864067510989}\n",
      "\n",
      "# training | log loss: 50.32%, AUC: 94.13%, accuracy: 84.97%\n",
      "# testing  | log loss: 52.99%, AUC: 90.90%, accuracy: 80.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "406 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.622595638888991,\n",
      " 'gamma': 0.5381602034025444,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_lambda': 1.9315777047053664,\n",
      " 'scale_pos_weight': 0.29220282486026683,\n",
      " 'subsample': 0.5528790672717535}\n",
      "\n",
      "# training | log loss: 67.07%, AUC: 82.30%, accuracy: 55.59%\n",
      "# testing  | log loss: 67.81%, AUC: 78.63%, accuracy: 56.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "407 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.8561758933741886,\n",
      " 'gamma': 0.6921855648414055,\n",
      " 'learning_rate': 0.10432574693984953,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 5.838759483566821,\n",
      " 'subsample': 0.9819321664338967}\n",
      "\n",
      "# training | log loss: 47.31%, AUC: 91.32%, accuracy: 84.97%\n",
      "# testing  | log loss: 51.02%, AUC: 85.38%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "408 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5999123502629615,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 1.8746592778979955e-05}\n",
      "\n",
      "# training | log loss: 48.09%, AUC: 86.19%, accuracy: 74.48%\n",
      "# testing  | log loss: 51.52%, AUC: 81.51%, accuracy: 69.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "409 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.2805910761894772,\n",
      " 'colsample_bylevel': 0.9018211587432597,\n",
      " 'gamma': 0.7652430421945141,\n",
      " 'learning_rate': 0.04536405955069701,\n",
      " 'min_child_weight': 5}\n",
      "\n",
      "# training | log loss: 58.40%, AUC: 87.49%, accuracy: 75.52%\n",
      "# testing  | log loss: 60.28%, AUC: 83.26%, accuracy: 73.32%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "410 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.819438501732231,\n",
      " 'gamma': 0.5809124926162903,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 2.5109829740635496,\n",
      " 'scale_pos_weight': 5.9381700124925985,\n",
      " 'subsample': 0.5957690580204816}\n",
      "\n",
      "# training | log loss: 63.16%, AUC: 85.51%, accuracy: 65.38%\n",
      "# testing  | log loss: 67.11%, AUC: 79.64%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "411 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.7460007466225186,\n",
      " 'colsample_bytree': 0.6702870138615284,\n",
      " 'gamma': 0.31521675982271924,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 2.577335440920657}\n",
      "\n",
      "# training | log loss: 53.97%, AUC: 82.09%, accuracy: 74.48%\n",
      "# testing  | log loss: 56.54%, AUC: 77.98%, accuracy: 68.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "412 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.561270385169131,\n",
      " 'learning_rate': 0.022407015897538865,\n",
      " 'min_child_weight': 3,\n",
      " 'subsample': 0.7367468900358098}\n",
      "\n",
      "# training | log loss: 60.87%, AUC: 87.40%, accuracy: 80.42%\n",
      "# testing  | log loss: 62.05%, AUC: 82.55%, accuracy: 76.30%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "413 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5266826144429048,\n",
      " 'colsample_bytree': 0.7806812975363076,\n",
      " 'gamma': 0.25116813234710356,\n",
      " 'reg_alpha': 6.342316766131645e-10,\n",
      " 'reg_lambda': 3.6767956192299684,\n",
      " 'scale_pos_weight': 7.693265143210521}\n",
      "\n",
      "# training | log loss: 67.25%, AUC: 88.60%, accuracy: 65.38%\n",
      "# testing  | log loss: 70.38%, AUC: 83.32%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "414 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.5115525153142959,\n",
      " 'gamma': 0.25364476947637693,\n",
      " 'learning_rate': 0.039896787581188725,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 6.05733724871793e-09,\n",
      " 'reg_lambda': 4.2623075797290255,\n",
      " 'scale_pos_weight': 8.956891528516456,\n",
      " 'subsample': 0.890827531440659}\n",
      "\n",
      "# training | log loss: 64.34%, AUC: 72.11%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.75%, AUC: 72.37%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "415 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.41227407283701567,\n",
      " 'colsample_bytree': 0.7487871098598611,\n",
      " 'gamma': 0.7818635313899327,\n",
      " 'learning_rate': 0.09322514819495757,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 2.2407192472631944e-06,\n",
      " 'scale_pos_weight': 3.426340719373271}\n",
      "\n",
      "# training | log loss: 35.91%, AUC: 98.95%, accuracy: 85.31%\n",
      "# testing  | log loss: 42.05%, AUC: 97.00%, accuracy: 77.50%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "416 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.9271128908571404,\n",
      " 'gamma': 0.44675285465636594,\n",
      " 'learning_rate': 0.1511243715966072,\n",
      " 'max_depth': 2,\n",
      " 'reg_alpha': 1.560269198584552e-07,\n",
      " 'reg_lambda': 8.882378231008797,\n",
      " 'scale_pos_weight': 0.690729379317848}\n",
      "\n",
      "# training | log loss: 54.33%, AUC: 82.53%, accuracy: 75.52%\n",
      "# testing  | log loss: 57.01%, AUC: 77.89%, accuracy: 72.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "417 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.7354500214932171,\n",
      " 'colsample_bytree': 0.9127996351744463,\n",
      " 'gamma': 0.5127384566111824,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 2.360127583449881e-09,\n",
      " 'scale_pos_weight': 9.477472184941568,\n",
      " 'subsample': 0.7608461248529685}\n",
      "\n",
      "# training | log loss: 54.27%, AUC: 97.05%, accuracy: 68.53%\n",
      "# testing  | log loss: 62.33%, AUC: 89.51%, accuracy: 66.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "418 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.466785418444986,\n",
      " 'gamma': 0.6489910486833541,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_alpha': 9.815912409878806e-07,\n",
      " 'scale_pos_weight': 8.459333458390029,\n",
      " 'subsample': 0.6875254576735559}\n",
      "\n",
      "# training | log loss: 59.13%, AUC: 91.43%, accuracy: 65.38%\n",
      "# testing  | log loss: 64.32%, AUC: 85.09%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "419 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.885145526061773,\n",
      " 'colsample_bytree': 0.9868662904281155,\n",
      " 'gamma': 0.11741620913218753,\n",
      " 'learning_rate': 0.1277093838029619,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 2.2018589637525492e-07,\n",
      " 'reg_lambda': 6.486355747812686,\n",
      " 'subsample': 0.7974651480031765}\n",
      "\n",
      "# training | log loss: 52.95%, AUC: 83.92%, accuracy: 76.22%\n",
      "# testing  | log loss: 56.25%, AUC: 78.78%, accuracy: 68.70%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "420 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.8310877550909727,\n",
      " 'colsample_bytree': 0.820275126538377,\n",
      " 'subsample': 0.7834575242436261}\n",
      "\n",
      "# training | log loss: 43.31%, AUC: 92.69%, accuracy: 83.22%\n",
      "# testing  | log loss: 48.37%, AUC: 86.81%, accuracy: 73.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "421 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.8083659516515329,\n",
      " 'colsample_bylevel': 0.6881438662268535,\n",
      " 'colsample_bytree': 0.9056850895317619,\n",
      " 'gamma': 0.9757753046662964,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6,\n",
      " 'subsample': 0.6091897790987979}\n",
      "\n",
      "# training | log loss: 52.92%, AUC: 82.43%, accuracy: 73.43%\n",
      "# testing  | log loss: 55.61%, AUC: 78.25%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "422 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.286352027904038,\n",
      " 'colsample_bytree': 0.6099148907395235,\n",
      " 'learning_rate': 0.15868657103623657,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9}\n",
      "\n",
      "# training | log loss: 48.99%, AUC: 86.82%, accuracy: 74.13%\n",
      "# testing  | log loss: 52.10%, AUC: 82.37%, accuracy: 67.66%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "423 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.19398526152130702,\n",
      " 'gamma': 0.674603370279756,\n",
      " 'learning_rate': 0.03949215925269823,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 4}\n",
      "\n",
      "# training | log loss: 62.53%, AUC: 89.66%, accuracy: 72.73%\n",
      "# testing  | log loss: 63.81%, AUC: 84.89%, accuracy: 73.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "424 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'gamma': 0.02698885148238861,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 1.2464925002398931e-05,\n",
      " 'reg_lambda': 0.35833169124949416,\n",
      " 'scale_pos_weight': 5.251344523472548,\n",
      " 'subsample': 0.9876597800496268}\n",
      "\n",
      "# training | log loss: 52.17%, AUC: 94.59%, accuracy: 65.38%\n",
      "# testing  | log loss: 57.45%, AUC: 88.68%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "425 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.8406390105531679,\n",
      " 'learning_rate': 0.05908457525839719,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'scale_pos_weight': 1.411231391687644,\n",
      " 'subsample': 0.9146042869012571}\n",
      "\n",
      "# training | log loss: 39.62%, AUC: 98.87%, accuracy: 77.97%\n",
      "# testing  | log loss: 44.82%, AUC: 95.14%, accuracy: 71.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "426 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.7352990892450249,\n",
      " 'gamma': 0.25734114350418635,\n",
      " 'min_child_weight': 6,\n",
      " 'subsample': 0.7192789716138278}\n",
      "\n",
      "# training | log loss: 51.37%, AUC: 85.82%, accuracy: 75.17%\n",
      "# testing  | log loss: 53.74%, AUC: 81.24%, accuracy: 69.75%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "427 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9367852448725826,\n",
      " 'min_child_weight': 6,\n",
      " 'scale_pos_weight': 8.681911767707916,\n",
      " 'subsample': 0.950668100833167}\n",
      "\n",
      "# training | log loss: 64.97%, AUC: 87.55%, accuracy: 65.38%\n",
      "# testing  | log loss: 69.19%, AUC: 81.49%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "428 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5808927629492853,\n",
      " 'colsample_bytree': 0.7538914335661888,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 8.098803612877958e-08}\n",
      "\n",
      "# training | log loss: 44.12%, AUC: 95.01%, accuracy: 87.76%\n",
      "# testing  | log loss: 50.00%, AUC: 88.12%, accuracy: 80.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "429 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5816216884965683,\n",
      " 'colsample_bytree': 0.9733238809301421,\n",
      " 'gamma': 0.04266114039751867,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 0.04378930359069815,\n",
      " 'scale_pos_weight': 3.4473172339915106}\n",
      "\n",
      "# training | log loss: 49.25%, AUC: 92.24%, accuracy: 72.73%\n",
      "# testing  | log loss: 55.47%, AUC: 85.60%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "430 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.2341353071695986,\n",
      " 'colsample_bylevel': 0.8353134880968869,\n",
      " 'reg_alpha': 1.176890686448775e-09,\n",
      " 'reg_lambda': 1.9451513530394908,\n",
      " 'scale_pos_weight': 0.100458722456289,\n",
      " 'subsample': 0.7010899185768245}\n",
      "\n",
      "# training | log loss: 93.41%, AUC: 87.12%, accuracy: 34.62%\n",
      "# testing  | log loss: 95.44%, AUC: 82.52%, accuracy: 35.02%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "431 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6115897696882202,\n",
      " 'colsample_bylevel': 0.7881424811480822,\n",
      " 'gamma': 0.33132088388719205,\n",
      " 'learning_rate': 0.07373838674399147,\n",
      " 'min_child_weight': 1,\n",
      " 'scale_pos_weight': 5.785204640896838,\n",
      " 'subsample': 0.9955015178608579}\n",
      "\n",
      "# training | log loss: 56.11%, AUC: 89.52%, accuracy: 72.73%\n",
      "# testing  | log loss: 61.09%, AUC: 83.77%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "432 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5178345571366433,\n",
      " 'gamma': 0.5333037540836068,\n",
      " 'learning_rate': 0.020889678735941816,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 0.00014821130691201336,\n",
      " 'reg_lambda': 4.937574118080734,\n",
      " 'scale_pos_weight': 5.81990696577654}\n",
      "\n",
      "# training | log loss: 63.24%, AUC: 67.78%, accuracy: 65.38%\n",
      "# testing  | log loss: 63.50%, AUC: 69.27%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "433 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.6061167021498011,\n",
      " 'colsample_bytree': 0.8756579187693013,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 8.627879718707854}\n",
      "\n",
      "# training | log loss: 44.71%, AUC: 97.03%, accuracy: 82.17%\n",
      "# testing  | log loss: 49.28%, AUC: 91.90%, accuracy: 75.56%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "434 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.24656902529649455,\n",
      " 'colsample_bylevel': 0.5333655671180573,\n",
      " 'colsample_bytree': 0.7785406380161156,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 9.79147558496128,\n",
      " 'scale_pos_weight': 9.442140314384579}\n",
      "\n",
      "# training | log loss: 72.46%, AUC: 75.04%, accuracy: 65.38%\n",
      "# testing  | log loss: 73.34%, AUC: 75.66%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "435 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.44698115142144024,\n",
      " 'colsample_bytree': 0.5043724650951146,\n",
      " 'gamma': 0.9110906178798055,\n",
      " 'learning_rate': 0.11116802595699707,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 0.16552504595011283}\n",
      "\n",
      "# training | log loss: 43.43%, AUC: 94.00%, accuracy: 83.57%\n",
      "# testing  | log loss: 49.58%, AUC: 86.66%, accuracy: 74.96%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "436 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.12106453136432478,\n",
      " 'colsample_bytree': 0.5512526901631423,\n",
      " 'gamma': 0.3345300256103324,\n",
      " 'max_depth': 3,\n",
      " 'scale_pos_weight': 1.5950452238167956,\n",
      " 'subsample': 0.9644030350168766}\n",
      "\n",
      "# training | log loss: 49.87%, AUC: 90.14%, accuracy: 76.92%\n",
      "# testing  | log loss: 53.38%, AUC: 85.60%, accuracy: 72.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "437 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.8655735916978943,\n",
      " 'gamma': 0.8071088363542056,\n",
      " 'learning_rate': 0.19277033121955445,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_lambda': 1.5922743974525826,\n",
      " 'scale_pos_weight': 0.5080467171214135}\n",
      "\n",
      "# training | log loss: 55.08%, AUC: 82.31%, accuracy: 69.23%\n",
      "# testing  | log loss: 56.96%, AUC: 78.12%, accuracy: 66.77%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "438 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.9696201772429344,\n",
      " 'reg_alpha': 2.673667152879772e-06,\n",
      " 'reg_lambda': 6.130638179501009}\n",
      "\n",
      "# training | log loss: 47.34%, AUC: 91.67%, accuracy: 84.97%\n",
      "# testing  | log loss: 50.80%, AUC: 86.47%, accuracy: 77.94%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "439 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bylevel': 0.5811213165951999,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 4.719217895759692e-10,\n",
      " 'scale_pos_weight': 3.3003622129298367}\n",
      "\n",
      "# training | log loss: 54.39%, AUC: 89.26%, accuracy: 66.43%\n",
      "# testing  | log loss: 58.22%, AUC: 84.44%, accuracy: 65.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "440 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'reg_lambda': 0.8063475483355907,\n",
      " 'scale_pos_weight': 5.228420188509364,\n",
      " 'subsample': 0.9457871733783549}\n",
      "\n",
      "# training | log loss: 47.99%, AUC: 95.36%, accuracy: 72.73%\n",
      "# testing  | log loss: 53.60%, AUC: 90.51%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "441 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.4314075854885192,\n",
      " 'colsample_bylevel': 0.8034654853161367,\n",
      " 'colsample_bytree': 0.6886635199740796,\n",
      " 'gamma': 0.6711975008741509,\n",
      " 'learning_rate': 0.19018793400749662,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 0.43134649151697546,\n",
      " 'scale_pos_weight': 8.780683974747456}\n",
      "\n",
      "# training | log loss: 38.14%, AUC: 99.57%, accuracy: 80.42%\n",
      "# testing  | log loss: 53.61%, AUC: 94.36%, accuracy: 71.39%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "442 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.5876883375246224,\n",
      " 'colsample_bytree': 0.8196551932242226,\n",
      " 'gamma': 0.20216998261679608,\n",
      " 'reg_lambda': 7.61486572497952,\n",
      " 'scale_pos_weight': 2.796602525735001,\n",
      " 'subsample': 0.687682244283156}\n",
      "\n",
      "# training | log loss: 55.17%, AUC: 89.59%, accuracy: 66.43%\n",
      "# testing  | log loss: 58.60%, AUC: 84.23%, accuracy: 65.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "443 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.6129997607629579,\n",
      " 'learning_rate': 0.14647102757271954,\n",
      " 'min_child_weight': 1,\n",
      " 'scale_pos_weight': 8.421009432331642,\n",
      " 'subsample': 0.6445309437283857}\n",
      "\n",
      "# training | log loss: 61.28%, AUC: 92.95%, accuracy: 67.83%\n",
      "# testing  | log loss: 67.98%, AUC: 87.90%, accuracy: 66.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "444 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'colsample_bytree': 0.5498567614112075, 'subsample': 0.6783012728696249}\n",
      "\n",
      "# training | log loss: 48.76%, AUC: 91.98%, accuracy: 79.37%\n",
      "# testing  | log loss: 52.73%, AUC: 85.87%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "445 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 19\n",
      "{'base_score': 0.18228844035275005,\n",
      " 'gamma': 0.8783442980639034,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 5.465704717431983e-10,\n",
      " 'scale_pos_weight': 3.969102010151069}\n",
      "\n",
      "# training | log loss: 53.91%, AUC: 86.35%, accuracy: 72.73%\n",
      "# testing  | log loss: 58.81%, AUC: 78.70%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 27.0 configurations x 11.1 iterations each\n",
      "\n",
      "446 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.30391343653280983,\n",
      " 'gamma': 0.6027285437016157,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 0.0034525862653889848}\n",
      "\n",
      "# training | log loss: 12.06%, AUC: 99.93%, accuracy: 98.60%\n",
      "# testing  | log loss: 17.55%, AUC: 99.03%, accuracy: 96.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "447 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.8151696738769818,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 2.698618435569416,\n",
      " 'scale_pos_weight': 6.414127851750693,\n",
      " 'subsample': 0.8624872536492023}\n",
      "\n",
      "# training | log loss: 13.17%, AUC: 99.98%, accuracy: 96.85%\n",
      "# testing  | log loss: 21.69%, AUC: 99.09%, accuracy: 91.51%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "448 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.41227407283701567,\n",
      " 'colsample_bytree': 0.7487871098598611,\n",
      " 'gamma': 0.7818635313899327,\n",
      " 'learning_rate': 0.09322514819495757,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 2.2407192472631944e-06,\n",
      " 'scale_pos_weight': 3.426340719373271}\n",
      "\n",
      "# training | log loss: 18.04%, AUC: 99.84%, accuracy: 95.80%\n",
      "# testing  | log loss: 25.38%, AUC: 98.98%, accuracy: 90.46%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "449 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.8406390105531679,\n",
      " 'learning_rate': 0.05908457525839719,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'scale_pos_weight': 1.411231391687644,\n",
      " 'subsample': 0.9146042869012571}\n",
      "\n",
      "# training | log loss: 21.78%, AUC: 99.84%, accuracy: 94.06%\n",
      "# testing  | log loss: 28.93%, AUC: 97.91%, accuracy: 89.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "450 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.6908996058406087,\n",
      " 'colsample_bytree': 0.9454870758351958,\n",
      " 'learning_rate': 0.05503408226793185,\n",
      " 'max_depth': 10,\n",
      " 'reg_alpha': 7.385164780045698e-08,\n",
      " 'subsample': 0.8314248137466296}\n",
      "\n",
      "# training | log loss: 22.14%, AUC: 99.78%, accuracy: 97.90%\n",
      "# testing  | log loss: 29.68%, AUC: 98.59%, accuracy: 95.08%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "451 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.5674277192135102,\n",
      " 'colsample_bytree': 0.7776914067616947,\n",
      " 'learning_rate': 0.15346011700817663,\n",
      " 'subsample': 0.6100914311072461}\n",
      "\n",
      "# training | log loss: 26.31%, AUC: 98.20%, accuracy: 93.71%\n",
      "# testing  | log loss: 36.13%, AUC: 92.87%, accuracy: 83.46%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "452 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.8310877550909727,\n",
      " 'colsample_bytree': 0.820275126538377,\n",
      " 'subsample': 0.7834575242436261}\n",
      "\n",
      "# training | log loss: 28.54%, AUC: 98.50%, accuracy: 92.31%\n",
      "# testing  | log loss: 36.45%, AUC: 93.76%, accuracy: 84.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "453 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.6061167021498011,\n",
      " 'colsample_bytree': 0.8756579187693013,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 8.627879718707854}\n",
      "\n",
      "# training | log loss: 30.93%, AUC: 98.89%, accuracy: 91.96%\n",
      "# testing  | log loss: 38.42%, AUC: 94.27%, accuracy: 84.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "454 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.44698115142144024,\n",
      " 'colsample_bytree': 0.5043724650951146,\n",
      " 'gamma': 0.9110906178798055,\n",
      " 'learning_rate': 0.11116802595699707,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 0.16552504595011283}\n",
      "\n",
      "# training | log loss: 30.41%, AUC: 98.22%, accuracy: 90.21%\n",
      "# testing  | log loss: 40.58%, AUC: 91.32%, accuracy: 80.77%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "455 | Thu Oct 26 04:30:55 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7312359273842766,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'subsample': 0.781495676324822}\n",
      "\n",
      "# training | log loss: 32.34%, AUC: 96.85%, accuracy: 88.46%\n",
      "# testing  | log loss: 39.62%, AUC: 91.40%, accuracy: 80.33%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "456 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.5808927629492853,\n",
      " 'colsample_bytree': 0.7538914335661888,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 8.098803612877958e-08}\n",
      "\n",
      "# training | log loss: 29.34%, AUC: 98.74%, accuracy: 94.06%\n",
      "# testing  | log loss: 36.92%, AUC: 94.06%, accuracy: 85.39%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "457 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.6399166599561927,\n",
      " 'learning_rate': 0.0900800005157166,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 4}\n",
      "\n",
      "# training | log loss: 33.22%, AUC: 97.53%, accuracy: 89.16%\n",
      "# testing  | log loss: 40.93%, AUC: 91.89%, accuracy: 81.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "458 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.9696201772429344,\n",
      " 'reg_alpha': 2.673667152879772e-06,\n",
      " 'reg_lambda': 6.130638179501009}\n",
      "\n",
      "# training | log loss: 34.93%, AUC: 96.87%, accuracy: 89.51%\n",
      "# testing  | log loss: 40.53%, AUC: 91.61%, accuracy: 80.03%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "459 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.8561758933741886,\n",
      " 'gamma': 0.6921855648414055,\n",
      " 'learning_rate': 0.10432574693984953,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 5.838759483566821,\n",
      " 'subsample': 0.9819321664338967}\n",
      "\n",
      "# training | log loss: 36.09%, AUC: 95.96%, accuracy: 87.76%\n",
      "# testing  | log loss: 41.85%, AUC: 90.39%, accuracy: 79.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "460 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.54459978650644,\n",
      " 'colsample_bytree': 0.9794599007797682,\n",
      " 'gamma': 0.29731804276784135,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 7.7012399175769675,\n",
      " 'subsample': 0.8443853139893376}\n",
      "\n",
      "# training | log loss: 20.87%, AUC: 99.77%, accuracy: 91.26%\n",
      "# testing  | log loss: 30.45%, AUC: 98.68%, accuracy: 83.16%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "461 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.5999123502629615,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 1.8746592778979955e-05}\n",
      "\n",
      "# training | log loss: 41.40%, AUC: 90.51%, accuracy: 81.47%\n",
      "# testing  | log loss: 46.25%, AUC: 85.85%, accuracy: 74.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "462 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.661486209096725,\n",
      " 'colsample_bytree': 0.9369196999369636,\n",
      " 'min_child_weight': 8}\n",
      "\n",
      "# training | log loss: 41.88%, AUC: 90.02%, accuracy: 81.82%\n",
      "# testing  | log loss: 47.02%, AUC: 85.09%, accuracy: 76.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "463 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.286352027904038,\n",
      " 'colsample_bytree': 0.6099148907395235,\n",
      " 'learning_rate': 0.15868657103623657,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9}\n",
      "\n",
      "# training | log loss: 41.15%, AUC: 90.92%, accuracy: 82.87%\n",
      "# testing  | log loss: 46.76%, AUC: 85.27%, accuracy: 76.15%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "464 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.3976513079834556,\n",
      " 'colsample_bylevel': 0.8077427624809828,\n",
      " 'colsample_bytree': 0.6704370020047661,\n",
      " 'reg_alpha': 0.4436276666345138,\n",
      " 'subsample': 0.9262811684482923}\n",
      "\n",
      "# training | log loss: 33.98%, AUC: 97.30%, accuracy: 88.81%\n",
      "# testing  | log loss: 41.04%, AUC: 92.72%, accuracy: 81.07%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "465 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.34065848277535987,\n",
      " 'colsample_bytree': 0.7073648512400248,\n",
      " 'gamma': 0.27203670758408527,\n",
      " 'max_depth': 7,\n",
      " 'reg_lambda': 8.087849392743939}\n",
      "\n",
      "# training | log loss: 30.90%, AUC: 99.25%, accuracy: 94.76%\n",
      "# testing  | log loss: 37.68%, AUC: 96.32%, accuracy: 87.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "466 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.5498567614112075, 'subsample': 0.6783012728696249}\n",
      "\n",
      "# training | log loss: 35.89%, AUC: 97.10%, accuracy: 89.16%\n",
      "# testing  | log loss: 43.15%, AUC: 90.97%, accuracy: 80.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "467 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.9780974248059389,\n",
      " 'gamma': 0.33407410112603664,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_alpha': 0.0029187141471454818,\n",
      " 'reg_lambda': 8.96344002436873}\n",
      "\n",
      "# training | log loss: 39.42%, AUC: 94.30%, accuracy: 86.36%\n",
      "# testing  | log loss: 44.28%, AUC: 88.79%, accuracy: 77.35%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "468 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.3113586630068307,\n",
      " 'colsample_bylevel': 0.624938668372184,\n",
      " 'gamma': 0.7372508016729298,\n",
      " 'max_depth': 6,\n",
      " 'reg_alpha': 0.0003505674979105522,\n",
      " 'reg_lambda': 9.860962990987865,\n",
      " 'subsample': 0.8782864067510989}\n",
      "\n",
      "# training | log loss: 34.77%, AUC: 98.53%, accuracy: 89.86%\n",
      "# testing  | log loss: 40.17%, AUC: 94.72%, accuracy: 84.65%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "469 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.6991231488018282,\n",
      " 'colsample_bylevel': 0.5672836772345823,\n",
      " 'colsample_bytree': 0.7897096025213048,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_alpha': 3.018234235556009e-09,\n",
      " 'subsample': 0.772811524170552}\n",
      "\n",
      "# training | log loss: 43.95%, AUC: 89.99%, accuracy: 78.32%\n",
      "# testing  | log loss: 48.12%, AUC: 84.86%, accuracy: 73.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "470 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.6364825933010121,\n",
      " 'colsample_bylevel': 0.5005956284701243,\n",
      " 'colsample_bytree': 0.8030991211208678,\n",
      " 'gamma': 0.6288840799837556,\n",
      " 'learning_rate': 0.04598477174458998,\n",
      " 'max_depth': 8,\n",
      " 'subsample': 0.7164496617876075}\n",
      "\n",
      "# training | log loss: 34.29%, AUC: 99.31%, accuracy: 93.01%\n",
      "# testing  | log loss: 41.77%, AUC: 94.16%, accuracy: 83.61%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "471 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.4745327859343763,\n",
      " 'colsample_bytree': 0.549433563852756,\n",
      " 'gamma': 0.7384811297117378,\n",
      " 'learning_rate': 0.07341037511057066,\n",
      " 'max_depth': 10,\n",
      " 'scale_pos_weight': 2.5257240272244927,\n",
      " 'subsample': 0.9691916830957815}\n",
      "\n",
      "# training | log loss: 30.27%, AUC: 99.92%, accuracy: 87.41%\n",
      "# testing  | log loss: 42.26%, AUC: 95.11%, accuracy: 76.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "472 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.12106453136432478,\n",
      " 'colsample_bytree': 0.5512526901631423,\n",
      " 'gamma': 0.3345300256103324,\n",
      " 'max_depth': 3,\n",
      " 'scale_pos_weight': 1.5950452238167956,\n",
      " 'subsample': 0.9644030350168766}\n",
      "\n",
      "# training | log loss: 34.94%, AUC: 97.33%, accuracy: 85.66%\n",
      "# testing  | log loss: 42.96%, AUC: 92.44%, accuracy: 77.50%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9.0 configurations x 33.3 iterations each\n",
      "\n",
      "473 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.30391343653280983,\n",
      " 'gamma': 0.6027285437016157,\n",
      " 'max_depth': 7,\n",
      " 'reg_alpha': 0.0034525862653889848}\n",
      "\n",
      "# training | log loss: 11.99%, AUC: 99.94%, accuracy: 98.60%\n",
      "# testing  | log loss: 17.48%, AUC: 99.03%, accuracy: 96.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "474 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.8151696738769818,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 2.698618435569416,\n",
      " 'scale_pos_weight': 6.414127851750693,\n",
      " 'subsample': 0.8624872536492023}\n",
      "\n",
      "# training | log loss: 5.46%, AUC: 100.00%, accuracy: 98.95%\n",
      "# testing  | log loss: 14.19%, AUC: 99.33%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "475 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.41227407283701567,\n",
      " 'colsample_bytree': 0.7487871098598611,\n",
      " 'gamma': 0.7818635313899327,\n",
      " 'learning_rate': 0.09322514819495757,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 2.2407192472631944e-06,\n",
      " 'scale_pos_weight': 3.426340719373271}\n",
      "\n",
      "# training | log loss: 9.74%, AUC: 99.99%, accuracy: 97.90%\n",
      "# testing  | log loss: 16.83%, AUC: 99.45%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "476 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.8406390105531679,\n",
      " 'learning_rate': 0.05908457525839719,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'scale_pos_weight': 1.411231391687644,\n",
      " 'subsample': 0.9146042869012571}\n",
      "\n",
      "# training | log loss: 11.50%, AUC: 99.92%, accuracy: 98.95%\n",
      "# testing  | log loss: 20.16%, AUC: 98.53%, accuracy: 93.89%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "477 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.6908996058406087,\n",
      " 'colsample_bytree': 0.9454870758351958,\n",
      " 'learning_rate': 0.05503408226793185,\n",
      " 'max_depth': 10,\n",
      " 'reg_alpha': 7.385164780045698e-08,\n",
      " 'subsample': 0.8314248137466296}\n",
      "\n",
      "# training | log loss: 10.21%, AUC: 99.99%, accuracy: 99.30%\n",
      "# testing  | log loss: 19.05%, AUC: 99.02%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "478 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.54459978650644,\n",
      " 'colsample_bytree': 0.9794599007797682,\n",
      " 'gamma': 0.29731804276784135,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 7.7012399175769675,\n",
      " 'subsample': 0.8443853139893376}\n",
      "\n",
      "# training | log loss: 6.76%, AUC: 100.00%, accuracy: 98.95%\n",
      "# testing  | log loss: 15.55%, AUC: 99.30%, accuracy: 95.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "479 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.5674277192135102,\n",
      " 'colsample_bytree': 0.7776914067616947,\n",
      " 'learning_rate': 0.15346011700817663,\n",
      " 'subsample': 0.6100914311072461}\n",
      "\n",
      "# training | log loss: 13.45%, AUC: 99.80%, accuracy: 97.90%\n",
      "# testing  | log loss: 26.00%, AUC: 96.19%, accuracy: 89.87%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "480 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.8310877550909727,\n",
      " 'colsample_bytree': 0.820275126538377,\n",
      " 'subsample': 0.7834575242436261}\n",
      "\n",
      "# training | log loss: 14.41%, AUC: 99.88%, accuracy: 97.55%\n",
      "# testing  | log loss: 23.38%, AUC: 97.75%, accuracy: 93.00%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "481 | Thu Oct 26 04:30:56 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.5808927629492853,\n",
      " 'colsample_bytree': 0.7538914335661888,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 8.098803612877958e-08}\n",
      "\n",
      "# training | log loss: 18.33%, AUC: 99.60%, accuracy: 97.20%\n",
      "# testing  | log loss: 26.90%, AUC: 97.09%, accuracy: 91.95%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 100.0 iterations each\n",
      "\n",
      "482 | Thu Oct 26 04:30:57 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.8151696738769818,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 2.698618435569416,\n",
      " 'scale_pos_weight': 6.414127851750693,\n",
      " 'subsample': 0.8624872536492023}\n",
      "\n",
      "# training | log loss: 2.66%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 11.97%, AUC: 99.34%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "483 | Thu Oct 26 04:30:57 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bylevel': 0.54459978650644,\n",
      " 'colsample_bytree': 0.9794599007797682,\n",
      " 'gamma': 0.29731804276784135,\n",
      " 'max_depth': 5,\n",
      " 'scale_pos_weight': 7.7012399175769675,\n",
      " 'subsample': 0.8443853139893376}\n",
      "\n",
      "# training | log loss: 4.00%, AUC: 100.00%, accuracy: 99.30%\n",
      "# testing  | log loss: 13.19%, AUC: 99.33%, accuracy: 95.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "484 | Thu Oct 26 04:30:57 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.41227407283701567,\n",
      " 'colsample_bytree': 0.7487871098598611,\n",
      " 'gamma': 0.7818635313899327,\n",
      " 'learning_rate': 0.09322514819495757,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 2.2407192472631944e-06,\n",
      " 'scale_pos_weight': 3.426340719373271}\n",
      "\n",
      "# training | log loss: 8.01%, AUC: 100.00%, accuracy: 98.25%\n",
      "# testing  | log loss: 15.19%, AUC: 99.53%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 1.0 configurations x 300.0 iterations each\n",
      "\n",
      "485 | Thu Oct 26 04:30:57 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.8151696738769818,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 2.698618435569416,\n",
      " 'scale_pos_weight': 6.414127851750693,\n",
      " 'subsample': 0.8624872536492023}\n",
      "\n",
      "# training | log loss: 1.51%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.32%, AUC: 99.38%, accuracy: 96.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 27 configurations x 11.1 iterations each\n",
      "\n",
      "486 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7059919098955825,\n",
      " 'learning_rate': 0.07408577809242914,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 6.346818932860334e-10,\n",
      " 'reg_lambda': 7.840082557889668,\n",
      " 'scale_pos_weight': 1.4959012804548941}\n",
      "\n",
      "# training | log loss: 47.57%, AUC: 87.55%, accuracy: 75.52%\n",
      "# testing  | log loss: 52.17%, AUC: 82.46%, accuracy: 69.60%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "487 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.7192746412333146,\n",
      " 'gamma': 0.15968017893495234,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 2.7747338662899106e-07}\n",
      "\n",
      "# training | log loss: 44.53%, AUC: 88.76%, accuracy: 74.48%\n",
      "# testing  | log loss: 48.76%, AUC: 83.91%, accuracy: 70.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "488 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.8753391808998867,\n",
      " 'gamma': 0.8623849489519767,\n",
      " 'learning_rate': 0.04782652719668404,\n",
      " 'min_child_weight': 9,\n",
      " 'subsample': 0.6566934623309555}\n",
      "\n",
      "# training | log loss: 52.78%, AUC: 81.26%, accuracy: 76.57%\n",
      "# testing  | log loss: 54.79%, AUC: 78.02%, accuracy: 74.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "489 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.6500525418013887,\n",
      " 'learning_rate': 0.09883352407261135,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 6,\n",
      " 'reg_lambda': 4.443017358140202,\n",
      " 'scale_pos_weight': 3.312998361069238,\n",
      " 'subsample': 0.7832961804562245}\n",
      "\n",
      "# training | log loss: 49.52%, AUC: 91.87%, accuracy: 73.43%\n",
      "# testing  | log loss: 57.56%, AUC: 84.61%, accuracy: 69.30%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "490 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7220385204669527,\n",
      " 'colsample_bytree': 0.9551944834156006,\n",
      " 'gamma': 0.15910672868742992,\n",
      " 'learning_rate': 0.08449332189540275,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 2.384720006363909e-07,\n",
      " 'reg_lambda': 6.779115612213252,\n",
      " 'scale_pos_weight': 8.698045799712819}\n",
      "\n",
      "# training | log loss: 69.88%, AUC: 89.75%, accuracy: 66.08%\n",
      "# testing  | log loss: 78.01%, AUC: 83.15%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "491 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.9026328124668391,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 5.598960295759406}\n",
      "\n",
      "# training | log loss: 25.42%, AUC: 99.65%, accuracy: 95.80%\n",
      "# testing  | log loss: 31.70%, AUC: 97.54%, accuracy: 92.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "492 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.514007236448728,\n",
      " 'gamma': 0.6486686933999144,\n",
      " 'max_depth': 2,\n",
      " 'reg_alpha': 2.391761513948851e-10,\n",
      " 'reg_lambda': 1.9387921411688618,\n",
      " 'scale_pos_weight': 5.723991771200809,\n",
      " 'subsample': 0.664139728905587}\n",
      "\n",
      "# training | log loss: 66.71%, AUC: 87.06%, accuracy: 66.78%\n",
      "# testing  | log loss: 73.18%, AUC: 81.22%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "493 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.49026919604428976,\n",
      " 'colsample_bylevel': 0.6541957066195114,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 1.6386016213455708e-10,\n",
      " 'subsample': 0.6174678201295152}\n",
      "\n",
      "# training | log loss: 48.21%, AUC: 83.78%, accuracy: 75.17%\n",
      "# testing  | log loss: 52.12%, AUC: 79.16%, accuracy: 73.17%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "494 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.1372992813669079,\n",
      " 'gamma': 0.2472414212708639,\n",
      " 'learning_rate': 0.08863658068392323,\n",
      " 'reg_lambda': 6.185383651254086,\n",
      " 'scale_pos_weight': 3.4558723933593862,\n",
      " 'subsample': 0.7480151873944066}\n",
      "\n",
      "# training | log loss: 44.94%, AUC: 95.97%, accuracy: 73.08%\n",
      "# testing  | log loss: 52.71%, AUC: 90.54%, accuracy: 69.90%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "495 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.2470856273296093,\n",
      " 'colsample_bytree': 0.6221856434031238,\n",
      " 'reg_lambda': 4.1948432937761915,\n",
      " 'scale_pos_weight': 1.9561196668650684,\n",
      " 'subsample': 0.5553410979163367}\n",
      "\n",
      "# training | log loss: 42.01%, AUC: 95.05%, accuracy: 76.92%\n",
      "# testing  | log loss: 49.37%, AUC: 88.60%, accuracy: 72.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "496 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.9016716999667,\n",
      " 'colsample_bytree': 0.9821128584673238,\n",
      " 'gamma': 0.771113693261726,\n",
      " 'learning_rate': 0.04107031466420979,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8}\n",
      "\n",
      "# training | log loss: 48.24%, AUC: 85.88%, accuracy: 74.13%\n",
      "# testing  | log loss: 51.67%, AUC: 81.44%, accuracy: 68.55%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "497 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.48409789918370505,\n",
      " 'colsample_bytree': 0.7883617128673432,\n",
      " 'gamma': 0.3342927667913296,\n",
      " 'learning_rate': 0.03751935191223411,\n",
      " 'reg_alpha': 0.18810561340462337,\n",
      " 'reg_lambda': 3.79109493274296,\n",
      " 'scale_pos_weight': 7.731010174563354,\n",
      " 'subsample': 0.9853066733621574}\n",
      "\n",
      "# training | log loss: 60.77%, AUC: 90.48%, accuracy: 69.58%\n",
      "# testing  | log loss: 66.06%, AUC: 85.03%, accuracy: 68.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "498 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.261705467915194,\n",
      " 'colsample_bylevel': 0.8318031754063957,\n",
      " 'colsample_bytree': 0.7170855248907437,\n",
      " 'learning_rate': 0.02843429879781041,\n",
      " 'max_depth': 2,\n",
      " 'reg_alpha': 1.7807916596777056e-07,\n",
      " 'reg_lambda': 4.752552876597691,\n",
      " 'scale_pos_weight': 3.931081256231664,\n",
      " 'subsample': 0.599959638751651}\n",
      "\n",
      "# training | log loss: 61.31%, AUC: 80.16%, accuracy: 65.38%\n",
      "# testing  | log loss: 62.66%, AUC: 77.62%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "499 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7875664536317893,\n",
      " 'colsample_bylevel': 0.9593920124112862,\n",
      " 'colsample_bytree': 0.8278670639885877,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 8.92363336493508,\n",
      " 'subsample': 0.7133759303001493}\n",
      "\n",
      "# training | log loss: 42.41%, AUC: 92.67%, accuracy: 82.17%\n",
      "# testing  | log loss: 47.67%, AUC: 86.75%, accuracy: 74.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "500 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.9054955745374964,\n",
      " 'colsample_bytree': 0.6936664274060769,\n",
      " 'gamma': 0.15453115172186516,\n",
      " 'max_depth': 10,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 1.1910320692309969e-05,\n",
      " 'reg_lambda': 7.053385070643279,\n",
      " 'subsample': 0.6466940924181237}\n",
      "\n",
      "# training | log loss: 45.67%, AUC: 88.75%, accuracy: 75.87%\n",
      "# testing  | log loss: 50.46%, AUC: 83.44%, accuracy: 71.24%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "501 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'gamma': 0.4076286295903302,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 8.161205231308935,\n",
      " 'scale_pos_weight': 9.060557820453075}\n",
      "\n",
      "# training | log loss: 65.32%, AUC: 91.72%, accuracy: 67.13%\n",
      "# testing  | log loss: 75.57%, AUC: 84.36%, accuracy: 67.06%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "502 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7024235309401812,\n",
      " 'colsample_bylevel': 0.7447619922091886,\n",
      " 'colsample_bytree': 0.7225900605634615,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 1.949914382118432e-06,\n",
      " 'reg_lambda': 6.439571957269378}\n",
      "\n",
      "# training | log loss: 37.78%, AUC: 96.39%, accuracy: 86.01%\n",
      "# testing  | log loss: 43.65%, AUC: 90.98%, accuracy: 79.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "503 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'gamma': 0.5932210717285583,\n",
      " 'learning_rate': 0.1359563879755081,\n",
      " 'reg_alpha': 0.0008486247788105619}\n",
      "\n",
      "# training | log loss: 21.98%, AUC: 99.53%, accuracy: 97.20%\n",
      "# testing  | log loss: 28.87%, AUC: 96.81%, accuracy: 89.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "504 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bylevel': 0.7039663460605861,\n",
      " 'learning_rate': 0.16969670902387815,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.000699391105554207}\n",
      "\n",
      "# training | log loss: 19.11%, AUC: 99.57%, accuracy: 96.85%\n",
      "# testing  | log loss: 26.71%, AUC: 97.41%, accuracy: 92.70%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "505 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.21743979206905736,\n",
      " 'colsample_bylevel': 0.5824607572018462,\n",
      " 'colsample_bytree': 0.6553788061176935,\n",
      " 'learning_rate': 0.11675162993436942,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_lambda': 4.80945986172608,\n",
      " 'scale_pos_weight': 6.263485775634777}\n",
      "\n",
      "# training | log loss: 71.70%, AUC: 84.32%, accuracy: 66.43%\n",
      "# testing  | log loss: 77.82%, AUC: 79.34%, accuracy: 65.42%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "506 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.37963265169127114,\n",
      " 'colsample_bylevel': 0.897214055729256,\n",
      " 'colsample_bytree': 0.6642103044128412,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 8.848208077405938e-09,\n",
      " 'reg_lambda': 2.6783260530148203,\n",
      " 'scale_pos_weight': 2.1209052919849514,\n",
      " 'subsample': 0.6510921045013245}\n",
      "\n",
      "# training | log loss: 32.14%, AUC: 99.17%, accuracy: 84.97%\n",
      "# testing  | log loss: 42.27%, AUC: 93.55%, accuracy: 76.45%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "507 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.8153347550788669,\n",
      " 'colsample_bytree': 0.6053660605771085,\n",
      " 'gamma': 0.1980382439742735,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 4.0569832502388685,\n",
      " 'scale_pos_weight': 9.399720423977415,\n",
      " 'subsample': 0.9118589841300502}\n",
      "\n",
      "# training | log loss: 62.30%, AUC: 93.39%, accuracy: 69.93%\n",
      "# testing  | log loss: 73.85%, AUC: 86.50%, accuracy: 67.66%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "508 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'learning_rate': 0.017013327470583553,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 6.2895063713669855e-06,\n",
      " 'scale_pos_weight': 9.694974262854705}\n",
      "\n",
      "# training | log loss: 40.92%, AUC: 97.66%, accuracy: 84.97%\n",
      "# testing  | log loss: 47.07%, AUC: 92.04%, accuracy: 80.48%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "509 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.4539741722590127, 'gamma': 0.4311421317565103}\n",
      "\n",
      "# training | log loss: 26.39%, AUC: 99.37%, accuracy: 95.45%\n",
      "# testing  | log loss: 32.43%, AUC: 96.09%, accuracy: 88.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "510 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7847608080499683,\n",
      " 'colsample_bytree': 0.5421431257245807,\n",
      " 'gamma': 0.7738716815946319,\n",
      " 'learning_rate': 0.04308938369704764,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 0.015846083558980553,\n",
      " 'scale_pos_weight': 2.8448825079471414}\n",
      "\n",
      "# training | log loss: 58.56%, AUC: 84.92%, accuracy: 67.83%\n",
      "# testing  | log loss: 64.39%, AUC: 79.13%, accuracy: 66.47%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "511 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'colsample_bytree': 0.6584842402371893,\n",
      " 'learning_rate': 0.04793109682590214,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 5.563783290128223,\n",
      " 'scale_pos_weight': 7.42273994745327,\n",
      " 'subsample': 0.6161491608608218}\n",
      "\n",
      "# training | log loss: 72.76%, AUC: 83.87%, accuracy: 65.38%\n",
      "# testing  | log loss: 76.27%, AUC: 79.49%, accuracy: 65.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "512 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 56\n",
      "{'base_score': 0.7591316150951429,\n",
      " 'colsample_bytree': 0.6237515105399055,\n",
      " 'learning_rate': 0.05135174549525918,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 0.0017716697454749609,\n",
      " 'subsample': 0.643932651649938}\n",
      "\n",
      "# training | log loss: 51.67%, AUC: 82.63%, accuracy: 75.52%\n",
      "# testing  | log loss: 54.05%, AUC: 79.42%, accuracy: 74.37%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9.0 configurations x 33.3 iterations each\n",
      "\n",
      "513 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.7039663460605861,\n",
      " 'learning_rate': 0.16969670902387815,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.000699391105554207}\n",
      "\n",
      "# training | log loss: 12.15%, AUC: 99.84%, accuracy: 98.95%\n",
      "# testing  | log loss: 21.45%, AUC: 97.86%, accuracy: 93.14%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "514 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'gamma': 0.5932210717285583,\n",
      " 'learning_rate': 0.1359563879755081,\n",
      " 'reg_alpha': 0.0008486247788105619}\n",
      "\n",
      "# training | log loss: 17.42%, AUC: 99.74%, accuracy: 98.25%\n",
      "# testing  | log loss: 24.12%, AUC: 98.24%, accuracy: 92.25%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "515 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bytree': 0.9026328124668391,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 5.598960295759406}\n",
      "\n",
      "# training | log loss: 12.70%, AUC: 99.92%, accuracy: 98.60%\n",
      "# testing  | log loss: 19.07%, AUC: 99.06%, accuracy: 96.27%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "516 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.4539741722590127, 'gamma': 0.4311421317565103}\n",
      "\n",
      "# training | log loss: 16.10%, AUC: 99.76%, accuracy: 97.90%\n",
      "# testing  | log loss: 22.45%, AUC: 98.53%, accuracy: 93.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "517 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.37963265169127114,\n",
      " 'colsample_bylevel': 0.897214055729256,\n",
      " 'colsample_bytree': 0.6642103044128412,\n",
      " 'max_depth': 8,\n",
      " 'reg_alpha': 8.848208077405938e-09,\n",
      " 'reg_lambda': 2.6783260530148203,\n",
      " 'scale_pos_weight': 2.1209052919849514,\n",
      " 'subsample': 0.6510921045013245}\n",
      "\n",
      "# training | log loss: 14.56%, AUC: 99.95%, accuracy: 97.90%\n",
      "# testing  | log loss: 27.61%, AUC: 97.37%, accuracy: 87.63%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "518 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.7024235309401812,\n",
      " 'colsample_bylevel': 0.7447619922091886,\n",
      " 'colsample_bytree': 0.7225900605634615,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 1.949914382118432e-06,\n",
      " 'reg_lambda': 6.439571957269378}\n",
      "\n",
      "# training | log loss: 24.03%, AUC: 99.08%, accuracy: 94.06%\n",
      "# testing  | log loss: 32.76%, AUC: 94.80%, accuracy: 86.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "519 | Thu Oct 26 04:30:58 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'learning_rate': 0.017013327470583553,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 2,\n",
      " 'reg_alpha': 6.2895063713669855e-06,\n",
      " 'scale_pos_weight': 9.694974262854705}\n",
      "\n",
      "# training | log loss: 24.58%, AUC: 99.60%, accuracy: 88.81%\n",
      "# testing  | log loss: 35.53%, AUC: 96.94%, accuracy: 83.16%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "520 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.7875664536317893,\n",
      " 'colsample_bylevel': 0.9593920124112862,\n",
      " 'colsample_bytree': 0.8278670639885877,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 8.92363336493508,\n",
      " 'subsample': 0.7133759303001493}\n",
      "\n",
      "# training | log loss: 30.19%, AUC: 97.61%, accuracy: 90.21%\n",
      "# testing  | log loss: 37.75%, AUC: 92.29%, accuracy: 80.92%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "521 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bytree': 0.7192746412333146,\n",
      " 'gamma': 0.15968017893495234,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 2.7747338662899106e-07}\n",
      "\n",
      "# training | log loss: 36.09%, AUC: 93.84%, accuracy: 86.01%\n",
      "# testing  | log loss: 41.17%, AUC: 89.27%, accuracy: 79.43%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 100.0 iterations each\n",
      "\n",
      "522 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bytree': 0.9026328124668391,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 5.598960295759406}\n",
      "\n",
      "# training | log loss: 6.07%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 14.28%, AUC: 99.15%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "523 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bylevel': 0.7039663460605861,\n",
      " 'learning_rate': 0.16969670902387815,\n",
      " 'max_depth': 5,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_alpha': 0.000699391105554207}\n",
      "\n",
      "# training | log loss: 8.18%, AUC: 99.97%, accuracy: 98.95%\n",
      "# testing  | log loss: 18.42%, AUC: 98.16%, accuracy: 93.74%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "524 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.4539741722590127, 'gamma': 0.4311421317565103}\n",
      "\n",
      "# training | log loss: 16.10%, AUC: 99.76%, accuracy: 97.90%\n",
      "# testing  | log loss: 22.45%, AUC: 98.53%, accuracy: 93.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 1.0 configurations x 300.0 iterations each\n",
      "\n",
      "525 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'colsample_bytree': 0.9026328124668391,\n",
      " 'max_depth': 4,\n",
      " 'reg_lambda': 5.598960295759406}\n",
      "\n",
      "# training | log loss: 3.23%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.14%, AUC: 99.25%, accuracy: 95.53%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 18 configurations x 33.3 iterations each\n",
      "\n",
      "526 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.5700116149155144,\n",
      " 'colsample_bylevel': 0.5879619360738626,\n",
      " 'gamma': 0.7646439116364079,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 2.8219108029672963e-09,\n",
      " 'reg_lambda': 5.974734947870989}\n",
      "\n",
      "# training | log loss: 41.98%, AUC: 90.53%, accuracy: 79.02%\n",
      "# testing  | log loss: 46.45%, AUC: 85.94%, accuracy: 74.52%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "527 | Thu Oct 26 04:30:59 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.4114941352862277,\n",
      " 'colsample_bylevel': 0.8572539355284224,\n",
      " 'colsample_bytree': 0.5484331806865705,\n",
      " 'scale_pos_weight': 6.556240251785757,\n",
      " 'subsample': 0.9463965630277515}\n",
      "\n",
      "# training | log loss: 29.37%, AUC: 99.36%, accuracy: 86.01%\n",
      "# testing  | log loss: 44.44%, AUC: 94.08%, accuracy: 75.26%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "528 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.7264547307014508,\n",
      " 'colsample_bytree': 0.8114176644487221,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 0.0007283056918100533,\n",
      " 'reg_lambda': 0.5549802220755737,\n",
      " 'scale_pos_weight': 1.9723473145963317}\n",
      "\n",
      "# training | log loss: 4.62%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 13.57%, AUC: 99.23%, accuracy: 96.13%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "529 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.6548909314256283,\n",
      " 'colsample_bylevel': 0.9294945181552318,\n",
      " 'gamma': 0.9990954935542551,\n",
      " 'learning_rate': 0.17046740955053546,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 8.929780422821318e-05,\n",
      " 'scale_pos_weight': 7.528008409448752}\n",
      "\n",
      "# training | log loss: 9.65%, AUC: 99.97%, accuracy: 97.55%\n",
      "# testing  | log loss: 16.05%, AUC: 99.08%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "530 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.6283450224327399,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 1.6787145326302055,\n",
      " 'scale_pos_weight': 6.6613948662518485,\n",
      " 'subsample': 0.765174411850092}\n",
      "\n",
      "# training | log loss: 41.94%, AUC: 96.74%, accuracy: 78.67%\n",
      "# testing  | log loss: 52.17%, AUC: 91.77%, accuracy: 72.58%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "531 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'learning_rate': 0.08906632210350864,\n",
      " 'reg_alpha': 7.658566037889394e-10,\n",
      " 'reg_lambda': 9.007995531006763,\n",
      " 'scale_pos_weight': 1.2949486669996424}\n",
      "\n",
      "# training | log loss: 24.53%, AUC: 99.23%, accuracy: 93.71%\n",
      "# testing  | log loss: 30.85%, AUC: 95.83%, accuracy: 86.44%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "532 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.20941694525547316,\n",
      " 'colsample_bylevel': 0.7471743410903005,\n",
      " 'learning_rate': 0.08061256313802537,\n",
      " 'max_depth': 9,\n",
      " 'reg_lambda': 2.6334165924538873,\n",
      " 'scale_pos_weight': 1.7836925464452176,\n",
      " 'subsample': 0.5344071366647809}\n",
      "\n",
      "# training | log loss: 14.96%, AUC: 99.91%, accuracy: 97.55%\n",
      "# testing  | log loss: 25.27%, AUC: 97.72%, accuracy: 89.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "533 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bytree': 0.544080228509872,\n",
      " 'gamma': 0.40169414222668043,\n",
      " 'learning_rate': 0.03241766993049755,\n",
      " 'max_depth': 3,\n",
      " 'min_child_weight': 3,\n",
      " 'subsample': 0.5965859128692582}\n",
      "\n",
      "# training | log loss: 41.46%, AUC: 92.86%, accuracy: 82.52%\n",
      "# testing  | log loss: 47.34%, AUC: 86.69%, accuracy: 75.56%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "534 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.47562776409789265,\n",
      " 'colsample_bylevel': 0.9998848756746002,\n",
      " 'colsample_bytree': 0.9796184702453152,\n",
      " 'gamma': 0.315555187034947,\n",
      " 'learning_rate': 0.1051200755799686,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 10,\n",
      " 'reg_lambda': 5.501702728117952,\n",
      " 'scale_pos_weight': 2.2520231581457035}\n",
      "\n",
      "# training | log loss: 37.24%, AUC: 95.13%, accuracy: 79.37%\n",
      "# testing  | log loss: 43.80%, AUC: 89.97%, accuracy: 72.28%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "535 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.835929562995289,\n",
      " 'colsample_bytree': 0.6534805575713425,\n",
      " 'gamma': 0.6047638138305739,\n",
      " 'learning_rate': 0.14756579050689642,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 6.0459795361894635,\n",
      " 'scale_pos_weight': 9.438490509276361}\n",
      "\n",
      "# training | log loss: 37.21%, AUC: 98.49%, accuracy: 82.17%\n",
      "# testing  | log loss: 49.64%, AUC: 93.47%, accuracy: 75.56%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "536 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.5614863334808602,\n",
      " 'colsample_bytree': 0.9560377522782486,\n",
      " 'gamma': 0.9348963676189367,\n",
      " 'learning_rate': 0.19738856766006077,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 2.8355268076091435e-06,\n",
      " 'subsample': 0.5973810307134064}\n",
      "\n",
      "# training | log loss: 41.52%, AUC: 87.99%, accuracy: 79.37%\n",
      "# testing  | log loss: 49.00%, AUC: 81.83%, accuracy: 72.88%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "537 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.4796317667447363,\n",
      " 'colsample_bytree': 0.5634696699660544,\n",
      " 'max_depth': 9,\n",
      " 'subsample': 0.9574857952025857}\n",
      "\n",
      "# training | log loss: 7.32%, AUC: 100.00%, accuracy: 99.65%\n",
      "# testing  | log loss: 18.10%, AUC: 98.89%, accuracy: 94.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "538 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.315154199767793,\n",
      " 'learning_rate': 0.14606422431989793,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 4.256928257169189,\n",
      " 'subsample': 0.9313723604948816}\n",
      "\n",
      "# training | log loss: 7.05%, AUC: 100.00%, accuracy: 99.30%\n",
      "# testing  | log loss: 14.12%, AUC: 99.35%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "539 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.2818161030309792,\n",
      " 'colsample_bylevel': 0.836302972723028,\n",
      " 'gamma': 0.2651881861965206,\n",
      " 'learning_rate': 0.0989285648912484,\n",
      " 'reg_alpha': 0.000325391238263054,\n",
      " 'reg_lambda': 7.0139061262054}\n",
      "\n",
      "# training | log loss: 22.58%, AUC: 99.38%, accuracy: 95.80%\n",
      "# testing  | log loss: 29.65%, AUC: 96.68%, accuracy: 89.57%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "540 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bytree': 0.7943177663415563,\n",
      " 'gamma': 0.29836172622172774,\n",
      " 'learning_rate': 0.10225893963264443,\n",
      " 'reg_lambda': 9.605205088170433,\n",
      " 'subsample': 0.9132849040716761}\n",
      "\n",
      "# training | log loss: 25.97%, AUC: 98.96%, accuracy: 94.41%\n",
      "# testing  | log loss: 33.67%, AUC: 94.87%, accuracy: 86.89%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "541 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'colsample_bylevel': 0.9789621192110981,\n",
      " 'colsample_bytree': 0.7219601381489327,\n",
      " 'gamma': 0.7330574877935178,\n",
      " 'learning_rate': 0.13822699430486163,\n",
      " 'min_child_weight': 8,\n",
      " 'scale_pos_weight': 9.921525078123684,\n",
      " 'subsample': 0.7844915230786913}\n",
      "\n",
      "# training | log loss: 44.79%, AUC: 97.61%, accuracy: 75.87%\n",
      "# testing  | log loss: 56.54%, AUC: 91.53%, accuracy: 71.09%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "542 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.4247103962813601,\n",
      " 'colsample_bytree': 0.9133024348296808,\n",
      " 'gamma': 0.2599094297055623,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 2.733708361989517}\n",
      "\n",
      "# training | log loss: 25.94%, AUC: 98.27%, accuracy: 92.66%\n",
      "# testing  | log loss: 33.65%, AUC: 93.59%, accuracy: 84.20%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "543 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 167\n",
      "{'base_score': 0.35313869895737493,\n",
      " 'colsample_bytree': 0.5650256384860568,\n",
      " 'gamma': 0.5540195497867009,\n",
      " 'learning_rate': 0.024072847989611207,\n",
      " 'max_depth': 9,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 5.981514973426355,\n",
      " 'subsample': 0.5790286736735624}\n",
      "\n",
      "# training | log loss: 53.24%, AUC: 81.77%, accuracy: 73.08%\n",
      "# testing  | log loss: 55.38%, AUC: 78.42%, accuracy: 70.79%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 6.0 configurations x 100.0 iterations each\n",
      "\n",
      "544 | Thu Oct 26 04:31:00 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bylevel': 0.7264547307014508,\n",
      " 'colsample_bytree': 0.8114176644487221,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 0.0007283056918100533,\n",
      " 'reg_lambda': 0.5549802220755737,\n",
      " 'scale_pos_weight': 1.9723473145963317}\n",
      "\n",
      "# training | log loss: 2.38%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 11.54%, AUC: 99.22%, accuracy: 95.98%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "545 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.315154199767793,\n",
      " 'learning_rate': 0.14606422431989793,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 4.256928257169189,\n",
      " 'subsample': 0.9313723604948816}\n",
      "\n",
      "# training | log loss: 3.93%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.14%, AUC: 99.30%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "546 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.6548909314256283,\n",
      " 'colsample_bylevel': 0.9294945181552318,\n",
      " 'gamma': 0.9990954935542551,\n",
      " 'learning_rate': 0.17046740955053546,\n",
      " 'max_depth': 9,\n",
      " 'reg_alpha': 8.929780422821318e-05,\n",
      " 'scale_pos_weight': 7.528008409448752}\n",
      "\n",
      "# training | log loss: 9.65%, AUC: 99.97%, accuracy: 97.55%\n",
      "# testing  | log loss: 16.05%, AUC: 99.08%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "547 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.4796317667447363,\n",
      " 'colsample_bytree': 0.5634696699660544,\n",
      " 'max_depth': 9,\n",
      " 'subsample': 0.9574857952025857}\n",
      "\n",
      "# training | log loss: 3.67%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 14.35%, AUC: 98.96%, accuracy: 95.38%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "548 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.20941694525547316,\n",
      " 'colsample_bylevel': 0.7471743410903005,\n",
      " 'learning_rate': 0.08061256313802537,\n",
      " 'max_depth': 9,\n",
      " 'reg_lambda': 2.6334165924538873,\n",
      " 'scale_pos_weight': 1.7836925464452176,\n",
      " 'subsample': 0.5344071366647809}\n",
      "\n",
      "# training | log loss: 7.41%, AUC: 99.99%, accuracy: 98.95%\n",
      "# testing  | log loss: 18.26%, AUC: 98.30%, accuracy: 93.89%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "549 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.2818161030309792,\n",
      " 'colsample_bylevel': 0.836302972723028,\n",
      " 'gamma': 0.2651881861965206,\n",
      " 'learning_rate': 0.0989285648912484,\n",
      " 'reg_alpha': 0.000325391238263054,\n",
      " 'reg_lambda': 7.0139061262054}\n",
      "\n",
      "# training | log loss: 16.84%, AUC: 99.65%, accuracy: 97.90%\n",
      "# testing  | log loss: 24.20%, AUC: 98.04%, accuracy: 93.59%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 2.0 configurations x 300.0 iterations each\n",
      "\n",
      "550 | Thu Oct 26 04:31:01 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'colsample_bylevel': 0.7264547307014508,\n",
      " 'colsample_bytree': 0.8114176644487221,\n",
      " 'max_depth': 5,\n",
      " 'reg_alpha': 0.0007283056918100533,\n",
      " 'reg_lambda': 0.5549802220755737,\n",
      " 'scale_pos_weight': 1.9723473145963317}\n",
      "\n",
      "# training | log loss: 1.60%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 11.11%, AUC: 99.13%, accuracy: 95.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "551 | Thu Oct 26 04:31:02 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.315154199767793,\n",
      " 'learning_rate': 0.14606422431989793,\n",
      " 'max_depth': 6,\n",
      " 'reg_lambda': 4.256928257169189,\n",
      " 'subsample': 0.9313723604948816}\n",
      "\n",
      "# training | log loss: 2.43%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 10.82%, AUC: 99.33%, accuracy: 95.68%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 9 configurations x 100.0 iterations each\n",
      "\n",
      "552 | Thu Oct 26 04:31:02 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.2871102557171168,\n",
      " 'colsample_bytree': 0.6370625229533423,\n",
      " 'gamma': 0.12190283912595812,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 3.4379330247379425,\n",
      " 'scale_pos_weight': 5.038358226057776,\n",
      " 'subsample': 0.8261151004073615}\n",
      "\n",
      "# training | log loss: 11.13%, AUC: 99.89%, accuracy: 97.90%\n",
      "# testing  | log loss: 22.47%, AUC: 98.05%, accuracy: 90.01%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "553 | Thu Oct 26 04:31:02 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.6046124475724798,\n",
      " 'colsample_bytree': 0.9345167536528436,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 7,\n",
      " 'reg_lambda': 7.881445791381654,\n",
      " 'subsample': 0.5070812502545358}\n",
      "\n",
      "# training | log loss: 41.22%, AUC: 87.91%, accuracy: 80.77%\n",
      "# testing  | log loss: 48.71%, AUC: 82.40%, accuracy: 74.81%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "554 | Thu Oct 26 04:31:02 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.3659573479399014,\n",
      " 'learning_rate': 0.17284797012250322,\n",
      " 'max_depth': 2,\n",
      " 'min_child_weight': 1,\n",
      " 'reg_lambda': 1.8588697155873202,\n",
      " 'scale_pos_weight': 8.50155077573932,\n",
      " 'subsample': 0.7400347844797754}\n",
      "\n",
      "# training | log loss: 16.77%, AUC: 99.27%, accuracy: 94.41%\n",
      "# testing  | log loss: 32.03%, AUC: 95.43%, accuracy: 84.80%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "555 | Thu Oct 26 04:31:02 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.3585531087272641,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 7.14427608054585}\n",
      "\n",
      "# training | log loss: 5.76%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 14.26%, AUC: 99.08%, accuracy: 95.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "556 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bytree': 0.5302332399321372,\n",
      " 'gamma': 0.19705151379221564,\n",
      " 'min_child_weight': 5,\n",
      " 'reg_lambda': 1.5888796032395385,\n",
      " 'scale_pos_weight': 5.172147388942926}\n",
      "\n",
      "# training | log loss: 18.94%, AUC: 99.13%, accuracy: 94.41%\n",
      "# testing  | log loss: 27.95%, AUC: 97.24%, accuracy: 85.10%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "557 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.5679563839515063,\n",
      " 'colsample_bylevel': 0.9459571618817874,\n",
      " 'gamma': 0.6030982650703884,\n",
      " 'learning_rate': 0.07865351269193793,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 8.733483773620886,\n",
      " 'subsample': 0.5474908739585252}\n",
      "\n",
      "# training | log loss: 6.39%, AUC: 100.00%, accuracy: 98.95%\n",
      "# testing  | log loss: 15.35%, AUC: 99.20%, accuracy: 94.49%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "558 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.8577218652144859,\n",
      " 'colsample_bytree': 0.7038086089671047,\n",
      " 'gamma': 0.28263753788670354,\n",
      " 'reg_alpha': 2.527391054839853e-10,\n",
      " 'reg_lambda': 9.100563451042367,\n",
      " 'scale_pos_weight': 8.65775601394409,\n",
      " 'subsample': 0.995772993536042}\n",
      "\n",
      "# training | log loss: 16.74%, AUC: 99.77%, accuracy: 94.41%\n",
      "# testing  | log loss: 27.44%, AUC: 98.11%, accuracy: 85.84%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "559 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'base_score': 0.8015145323051289,\n",
      " 'colsample_bytree': 0.880737566537401,\n",
      " 'gamma': 0.592866754282509,\n",
      " 'learning_rate': 0.15076718896276792,\n",
      " 'max_depth': 7,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_lambda': 1.9674975928715175}\n",
      "\n",
      "# training | log loss: 39.09%, AUC: 92.42%, accuracy: 82.17%\n",
      "# testing  | log loss: 43.41%, AUC: 88.41%, accuracy: 77.05%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "560 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 500\n",
      "{'colsample_bylevel': 0.5423208673430431,\n",
      " 'colsample_bytree': 0.7585939223225842,\n",
      " 'learning_rate': 0.054894687588035285,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 8,\n",
      " 'reg_alpha': 3.223046392017253e-06,\n",
      " 'reg_lambda': 5.397600294405235}\n",
      "\n",
      "# training | log loss: 34.64%, AUC: 94.76%, accuracy: 84.97%\n",
      "# testing  | log loss: 40.50%, AUC: 89.75%, accuracy: 78.54%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 3.0 configurations x 300.0 iterations each\n",
      "\n",
      "561 | Thu Oct 26 04:31:03 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.3585531087272641,\n",
      " 'max_depth': 10,\n",
      " 'reg_lambda': 7.14427608054585}\n",
      "\n",
      "# training | log loss: 3.35%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 12.74%, AUC: 99.04%, accuracy: 95.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "562 | Thu Oct 26 04:31:04 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.5679563839515063,\n",
      " 'colsample_bylevel': 0.9459571618817874,\n",
      " 'gamma': 0.6030982650703884,\n",
      " 'learning_rate': 0.07865351269193793,\n",
      " 'max_depth': 9,\n",
      " 'scale_pos_weight': 8.733483773620886,\n",
      " 'subsample': 0.5474908739585252}\n",
      "\n",
      "# training | log loss: 4.86%, AUC: 100.00%, accuracy: 99.30%\n",
      "# testing  | log loss: 13.40%, AUC: 99.26%, accuracy: 95.83%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "563 | Thu Oct 26 04:31:04 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.2871102557171168,\n",
      " 'colsample_bytree': 0.6370625229533423,\n",
      " 'gamma': 0.12190283912595812,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'reg_lambda': 3.4379330247379425,\n",
      " 'scale_pos_weight': 5.038358226057776,\n",
      " 'subsample': 0.8261151004073615}\n",
      "\n",
      "# training | log loss: 6.76%, AUC: 100.00%, accuracy: 98.60%\n",
      "# testing  | log loss: 17.47%, AUC: 98.65%, accuracy: 92.85%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "*** 6 configurations x 300.0 iterations each\n",
      "\n",
      "564 | Thu Oct 26 04:31:04 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.7369330665327406,\n",
      " 'colsample_bylevel': 0.6195904716440964,\n",
      " 'colsample_bytree': 0.5351309410890055,\n",
      " 'gamma': 0.2181250097884978,\n",
      " 'max_depth': 8,\n",
      " 'min_child_weight': 9,\n",
      " 'reg_alpha': 3.221915137503647e-05,\n",
      " 'reg_lambda': 4.52207182426821,\n",
      " 'subsample': 0.644579939548785}\n",
      "\n",
      "# training | log loss: 42.09%, AUC: 87.22%, accuracy: 80.07%\n",
      "# testing  | log loss: 50.07%, AUC: 81.25%, accuracy: 75.11%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "565 | Thu Oct 26 04:31:05 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.7689534384955344,\n",
      " 'colsample_bytree': 0.7953552013364529,\n",
      " 'reg_alpha': 0.17717398655367583,\n",
      " 'subsample': 0.9907244185039119}\n",
      "\n",
      "# training | log loss: 3.76%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 15.13%, AUC: 98.58%, accuracy: 94.19%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "566 | Thu Oct 26 04:31:05 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'max_depth': 5, 'min_child_weight': 9, 'reg_alpha': 1.5382653135241985e-07}\n",
      "\n",
      "# training | log loss: 25.54%, AUC: 96.55%, accuracy: 89.86%\n",
      "# testing  | log loss: 35.61%, AUC: 91.25%, accuracy: 82.71%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "567 | Thu Oct 26 04:31:05 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'colsample_bytree': 0.5539899140342279,\n",
      " 'gamma': 0.40269469040036476,\n",
      " 'learning_rate': 0.027765957906674195,\n",
      " 'reg_lambda': 1.9225003743826448,\n",
      " 'subsample': 0.5980598067270645}\n",
      "\n",
      "# training | log loss: 17.28%, AUC: 99.65%, accuracy: 97.90%\n",
      "# testing  | log loss: 28.24%, AUC: 95.87%, accuracy: 88.23%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "568 | Thu Oct 26 04:31:06 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.28376199168277494,\n",
      " 'colsample_bylevel': 0.9317010242489632,\n",
      " 'colsample_bytree': 0.8070097442739459,\n",
      " 'learning_rate': 0.07042598647811767,\n",
      " 'min_child_weight': 4,\n",
      " 'reg_alpha': 0.01690693096902465,\n",
      " 'reg_lambda': 8.074162654860285,\n",
      " 'scale_pos_weight': 8.029268688534259,\n",
      " 'subsample': 0.6638585189133617}\n",
      "\n",
      "# training | log loss: 15.65%, AUC: 99.67%, accuracy: 96.15%\n",
      "# testing  | log loss: 24.52%, AUC: 98.02%, accuracy: 87.93%\n",
      "\n",
      "0 seconds.\n",
      "\n",
      "569 | Thu Oct 26 04:31:06 2017 | lowest loss so far: 0.0996 (run 364)\n",
      "\n",
      "n_estimators: 1500\n",
      "{'base_score': 0.3479968373438923,\n",
      " 'colsample_bylevel': 0.94832152286904,\n",
      " 'colsample_bytree': 0.5670806217669153,\n",
      " 'learning_rate': 0.18287081242695796,\n",
      " 'max_depth': 4,\n",
      " 'reg_alpha': 0.0002881318438852199,\n",
      " 'subsample': 0.9209465163690864}\n",
      "\n",
      "# training | log loss: 2.18%, AUC: 100.00%, accuracy: 100.00%\n",
      "# testing  | log loss: 14.93%, AUC: 98.42%, accuracy: 94.04%\n",
      "\n",
      "0 seconds.\n"
     ]
    }
   ],
   "source": [
    "hb = Hyperband(get_params, try_params, max_iter=300, eta=3)\n",
    "results = hb.run(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'auc': 0.98000568326572213,\n",
       "  'counter': 1,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.50362370652875321,\n",
       "  'loss': 0.50362370652875321,\n",
       "  'params': {'base_score': 0.49261530391627795,\n",
       "   'colsample_bylevel': 0.8598587930959023,\n",
       "   'gamma': 0.3642883152833015,\n",
       "   'learning_rate': 0.0860038674839635,\n",
       "   'max_depth': 8,\n",
       "   'reg_lambda': 7.645837501391092,\n",
       "   'scale_pos_weight': 0.9269814218271035},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84411194073725682,\n",
       "  'counter': 2,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61388811580115032,\n",
       "  'loss': 0.61388811580115032,\n",
       "  'params': {'colsample_bylevel': 0.6292199627538462,\n",
       "   'max_depth': 6,\n",
       "   'scale_pos_weight': 0.25456032618956326,\n",
       "   'subsample': 0.5221121193544558},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.78120896780136007,\n",
       "  'counter': 3,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64036258677611946,\n",
       "  'loss': 0.64036258677611946,\n",
       "  'params': {'base_score': 0.4913911557274533,\n",
       "   'colsample_bylevel': 0.9386799295359937,\n",
       "   'colsample_bytree': 0.5731609493482342,\n",
       "   'learning_rate': 0.025772184596576257,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 2.3073291793991593e-10,\n",
       "   'reg_lambda': 2.994879137821092,\n",
       "   'scale_pos_weight': 4.28743008082254,\n",
       "   'subsample': 0.6836774362120062},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84373958884512124,\n",
       "  'counter': 4,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.53134499081645037,\n",
       "  'loss': 0.53134499081645037,\n",
       "  'params': {'base_score': 0.67262109005906,\n",
       "   'colsample_bylevel': 0.5729040270029386,\n",
       "   'gamma': 0.9251244506291805,\n",
       "   'learning_rate': 0.1332972289914044,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.00027913222656036885,\n",
       "   'reg_lambda': 3.4591615330937207,\n",
       "   'subsample': 0.8842692380495034},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83734591490779386,\n",
       "  'counter': 5,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60050085293553801,\n",
       "  'loss': 0.60050085293553801,\n",
       "  'params': {'colsample_bylevel': 0.5176112623485047,\n",
       "   'gamma': 0.7882911085402525,\n",
       "   'learning_rate': 0.048197876011777434,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.42842513712460534,\n",
       "   'scale_pos_weight': 0.8320669020635969},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80623493444646954,\n",
       "  'counter': 6,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61780000126042056,\n",
       "  'loss': 0.61780000126042056,\n",
       "  'params': {'min_child_weight': 3,\n",
       "   'reg_lambda': 4.043807914348974,\n",
       "   'scale_pos_weight': 7.463360698892914},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96245125129833231,\n",
       "  'counter': 7,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.44976306691676954,\n",
       "  'loss': 0.44976306691676954,\n",
       "  'params': {'base_score': 0.8692320258880805,\n",
       "   'max_depth': 10,\n",
       "   'reg_lambda': 1.8143913886403642,\n",
       "   'subsample': 0.937398340836006},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84419522997628693,\n",
       "  'counter': 8,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65027022470571605,\n",
       "  'loss': 0.65027022470571605,\n",
       "  'params': {'base_score': 0.6079730148094737,\n",
       "   'colsample_bytree': 0.5128452290687116,\n",
       "   'scale_pos_weight': 6.9328474076500095,\n",
       "   'subsample': 0.8279248961656142},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9104444705744017,\n",
       "  'counter': 9,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.54926906503881323,\n",
       "  'loss': 0.54926906503881323,\n",
       "  'params': {'base_score': 0.5864055884063183,\n",
       "   'colsample_bylevel': 0.8542144061589139,\n",
       "   'gamma': 0.09270478710227648,\n",
       "   'learning_rate': 0.056723562479300244,\n",
       "   'max_depth': 4,\n",
       "   'reg_alpha': 2.06232164448684e-09,\n",
       "   'scale_pos_weight': 5.915726564382805,\n",
       "   'subsample': 0.5224559898792853},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79269308405354022,\n",
       "  'counter': 10,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.68286872940518284,\n",
       "  'loss': 0.68286872940518284,\n",
       "  'params': {'base_score': 0.34822223445153644,\n",
       "   'colsample_bylevel': 0.7169282501279773,\n",
       "   'colsample_bytree': 0.7244084767449213,\n",
       "   'gamma': 0.9582306289375496,\n",
       "   'learning_rate': 0.04682346489463303,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 2.7364940114175315e-07,\n",
       "   'reg_lambda': 5.211904733652633},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.69456366237482114,\n",
       "  'counter': 11,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.63665791457704923,\n",
       "  'loss': 0.63665791457704923,\n",
       "  'params': {'gamma': 0.7472876202115231,\n",
       "   'learning_rate': 0.04936239862244561,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_lambda': 8.254305965387157,\n",
       "   'scale_pos_weight': 7.419551616029973,\n",
       "   'subsample': 0.932005986706836},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83423971622866322,\n",
       "  'counter': 12,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.52807207583226323,\n",
       "  'loss': 0.52807207583226323,\n",
       "  'params': {'base_score': 0.39987901125034975,\n",
       "   'colsample_bytree': 0.7630646310747209,\n",
       "   'learning_rate': 0.196696835483434,\n",
       "   'reg_lambda': 4.9020718144758515,\n",
       "   'subsample': 0.8266441272858888},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98288651106277058,\n",
       "  'counter': 13,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.42065212991083079,\n",
       "  'loss': 0.42065212991083079,\n",
       "  'params': {'base_score': 0.23323220855719884,\n",
       "   'colsample_bylevel': 0.6001882404701808,\n",
       "   'max_depth': 8,\n",
       "   'reg_alpha': 2.509229358303713e-06,\n",
       "   'reg_lambda': 0.3367777853955599,\n",
       "   'scale_pos_weight': 0.7436642594737095},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8174691829815588,\n",
       "  'counter': 14,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60935517907942105,\n",
       "  'loss': 0.60935517907942105,\n",
       "  'params': {'base_score': 0.13690879353727878,\n",
       "   'colsample_bylevel': 0.5897336494595147,\n",
       "   'colsample_bytree': 0.7652637549355532,\n",
       "   'gamma': 0.9509975083124608,\n",
       "   'reg_alpha': 0.22729609811408272,\n",
       "   'subsample': 0.8878881773889014},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.77016579457934031,\n",
       "  'counter': 15,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.57868979726924985,\n",
       "  'loss': 0.57868979726924985,\n",
       "  'params': {'base_score': 0.717814680312837,\n",
       "   'colsample_bylevel': 0.8933720821124295,\n",
       "   'gamma': 0.06481914328979743,\n",
       "   'min_child_weight': 10,\n",
       "   'scale_pos_weight': 1.0738619391724376,\n",
       "   'subsample': 0.7868232971277229},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82395104552491816,\n",
       "  'counter': 16,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.55122348048825554,\n",
       "  'loss': 0.55122348048825554,\n",
       "  'params': {'base_score': 0.7538751525010713,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 1.7755235910627178e-07,\n",
       "   'scale_pos_weight': 1.6478853404557812},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.93054657338271896,\n",
       "  'counter': 17,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.52163467566231503,\n",
       "  'loss': 0.52163467566231503,\n",
       "  'params': {'colsample_bylevel': 0.6146019491242953,\n",
       "   'colsample_bytree': 0.7486456226824385,\n",
       "   'gamma': 0.7459371565379647,\n",
       "   'max_depth': 9,\n",
       "   'subsample': 0.7254404308383714},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8075675622709545,\n",
       "  'counter': 18,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60902644274131734,\n",
       "  'loss': 0.60902644274131734,\n",
       "  'params': {'base_score': 0.7240676935370662,\n",
       "   'min_child_weight': 9,\n",
       "   'scale_pos_weight': 2.351304858846671,\n",
       "   'subsample': 0.5721801792978329},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85869245693456397,\n",
       "  'counter': 19,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.50749896304618047,\n",
       "  'loss': 0.50749896304618047,\n",
       "  'params': {'base_score': 0.13936490016590908,\n",
       "   'colsample_bylevel': 0.6126772336496998,\n",
       "   'colsample_bytree': 0.9656138794508988,\n",
       "   'learning_rate': 0.18316236783397458,\n",
       "   'min_child_weight': 3},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80015481999725624,\n",
       "  'counter': 20,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58123323352432821,\n",
       "  'loss': 0.58123323352432821,\n",
       "  'params': {'colsample_bytree': 0.5199518690659819,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 5.939360889918373e-10,\n",
       "   'subsample': 0.7684990954579503},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81339780900307679,\n",
       "  'counter': 21,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.55663165152517058,\n",
       "  'loss': 0.55663165152517058,\n",
       "  'params': {'colsample_bylevel': 0.9431729210401354,\n",
       "   'colsample_bytree': 0.7885861823386202,\n",
       "   'gamma': 0.07179765684107264,\n",
       "   'learning_rate': 0.15912653719528544,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_lambda': 3.2290435081714173,\n",
       "   'scale_pos_weight': 0.765149337382315,\n",
       "   'subsample': 0.9956975020548969},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.73450820154036101,\n",
       "  'counter': 22,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60976905114782198,\n",
       "  'loss': 0.60976905114782198,\n",
       "  'params': {'colsample_bylevel': 0.5490963777892068,\n",
       "   'colsample_bytree': 0.6539694554596636,\n",
       "   'reg_lambda': 5.237948257147955},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80618594077645167,\n",
       "  'counter': 23,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.56432699516482221,\n",
       "  'loss': 0.56432699516482221,\n",
       "  'params': {'base_score': 0.7708736360604694,\n",
       "   'colsample_bylevel': 0.7463079709088856,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 2.32074447164062e-08,\n",
       "   'subsample': 0.5290210763694183},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.68899798146079527,\n",
       "  'counter': 24,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64945041440460616,\n",
       "  'loss': 0.64945041440460616,\n",
       "  'params': {'base_score': 0.358297080616115,\n",
       "   'colsample_bylevel': 0.8848939754590054,\n",
       "   'learning_rate': 0.044546039924399386,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 10,\n",
       "   'reg_lambda': 6.573051524566011,\n",
       "   'scale_pos_weight': 5.926851678292476},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.7671134889372293,\n",
       "  'counter': 25,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64560173198736193,\n",
       "  'loss': 0.64560173198736193,\n",
       "  'params': {'colsample_bylevel': 0.7589853364780499,\n",
       "   'colsample_bytree': 0.5512360951727078,\n",
       "   'gamma': 0.2912797064220122,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_lambda': 2.436219675021782,\n",
       "   'scale_pos_weight': 4.954882636411917,\n",
       "   'subsample': 0.93723570754854},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81365747545417133,\n",
       "  'counter': 26,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61774559823127151,\n",
       "  'loss': 0.61774559823127151,\n",
       "  'params': {'reg_alpha': 1.0412266740944833e-10,\n",
       "   'reg_lambda': 4.606542878002066,\n",
       "   'scale_pos_weight': 7.75689569324277},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79981186430713147,\n",
       "  'counter': 27,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.56419535067859594,\n",
       "  'loss': 0.56419535067859594,\n",
       "  'params': {'base_score': 0.21333493353798139,\n",
       "   'colsample_bylevel': 0.6599576104454234,\n",
       "   'colsample_bytree': 0.876957133572157,\n",
       "   'gamma': 0.00023319473398719648,\n",
       "   'learning_rate': 0.18871854006603217,\n",
       "   'reg_alpha': 7.064211815451934e-07,\n",
       "   'reg_lambda': 9.785855628288907,\n",
       "   'subsample': 0.9179511623339462},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8488202324259706,\n",
       "  'counter': 28,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.66385572902225343,\n",
       "  'loss': 0.66385572902225343,\n",
       "  'params': {'base_score': 0.6946049805646547,\n",
       "   'colsample_bylevel': 0.5983513495224698,\n",
       "   'gamma': 0.5227839783041155,\n",
       "   'reg_alpha': 1.2329630942289668e-08,\n",
       "   'scale_pos_weight': 8.223766721762809},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.77248809453818568,\n",
       "  'counter': 29,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65337631350657976,\n",
       "  'loss': 0.65337631350657976,\n",
       "  'params': {'colsample_bylevel': 0.7712823286695225,\n",
       "   'gamma': 0.3788075305843812,\n",
       "   'learning_rate': 0.06080482918475979,\n",
       "   'min_child_weight': 9,\n",
       "   'scale_pos_weight': 0.41665718595923973},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.75101906833637089,\n",
       "  'counter': 30,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.75072137230865643,\n",
       "  'loss': 0.75072137230865643,\n",
       "  'params': {'base_score': 0.7608376737390178,\n",
       "   'colsample_bytree': 0.873498404375189,\n",
       "   'gamma': 0.15944325959433592,\n",
       "   'learning_rate': 0.07375318186244899,\n",
       "   'max_depth': 2,\n",
       "   'scale_pos_weight': 8.161482862431,\n",
       "   'subsample': 0.9155850362974258},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98673741352617239,\n",
       "  'counter': 31,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.39571709908689368,\n",
       "  'loss': 0.39571709908689368,\n",
       "  'params': {'base_score': 0.2697155552230666,\n",
       "   'max_depth': 8,\n",
       "   'subsample': 0.8758244966382095},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85617908166264922,\n",
       "  'counter': 32,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.56859223911019618,\n",
       "  'loss': 0.56859223911019618,\n",
       "  'params': {'base_score': 0.5460505173285536,\n",
       "   'colsample_bylevel': 0.8543856193149106,\n",
       "   'learning_rate': 0.1780197474237355,\n",
       "   'reg_lambda': 9.175382678571912,\n",
       "   'scale_pos_weight': 3.0847486198533534,\n",
       "   'subsample': 0.893244556077375},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79254120367648506,\n",
       "  'counter': 33,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.5955207072942339,\n",
       "  'loss': 0.5955207072942339,\n",
       "  'params': {'colsample_bylevel': 0.9830633082775855,\n",
       "   'learning_rate': 0.0656242111874958,\n",
       "   'max_depth': 3,\n",
       "   'scale_pos_weight': 8.23791730194077},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83106002704450588,\n",
       "  'counter': 34,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65655712181516268,\n",
       "  'loss': 0.65655712181516268,\n",
       "  'params': {'base_score': 0.7633256768650193,\n",
       "   'colsample_bylevel': 0.7366527107954693,\n",
       "   'gamma': 0.5895440308210147,\n",
       "   'learning_rate': 0.11182137715068084,\n",
       "   'reg_lambda': 2.173622350463475,\n",
       "   'scale_pos_weight': 4.701995793181962,\n",
       "   'subsample': 0.7207719229244705},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.86728104728869027,\n",
       "  'counter': 35,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51226335417495927,\n",
       "  'loss': 0.51226335417495927,\n",
       "  'params': {'min_child_weight': 4, 'reg_alpha': 1.985516491427777e-05},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81217786661963265,\n",
       "  'counter': 36,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62518853990669221,\n",
       "  'loss': 0.62518853990669221,\n",
       "  'params': {'base_score': 0.4452789279317175,\n",
       "   'colsample_bylevel': 0.9236437638347061,\n",
       "   'colsample_bytree': 0.7766156384308421,\n",
       "   'learning_rate': 0.09846288618646419,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.0035682804112918483,\n",
       "   'scale_pos_weight': 7.360995762318851,\n",
       "   'subsample': 0.8238877575820984},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87605091422188253,\n",
       "  'counter': 37,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.5649451125307694,\n",
       "  'loss': 0.5649451125307694,\n",
       "  'params': {'colsample_bytree': 0.7613124474578432,\n",
       "   'max_depth': 8,\n",
       "   'reg_lambda': 7.051917854926246,\n",
       "   'subsample': 0.706626567202508},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82691516256099717,\n",
       "  'counter': 38,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.7037207686221546,\n",
       "  'loss': 0.7037207686221546,\n",
       "  'params': {'base_score': 0.372034692467607,\n",
       "   'colsample_bytree': 0.9201134729611079,\n",
       "   'learning_rate': 0.1880271560913663,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 8,\n",
       "   'reg_alpha': 8.354506120581884e-08,\n",
       "   'reg_lambda': 3.557821698191283,\n",
       "   'scale_pos_weight': 8.817860801455726,\n",
       "   'subsample': 0.7684490387492953},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97865835734023165,\n",
       "  'counter': 39,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.39607705524532699,\n",
       "  'loss': 0.39607705524532699,\n",
       "  'params': {'colsample_bylevel': 0.9943362690192601,\n",
       "   'gamma': 0.39934834513402806,\n",
       "   'max_depth': 7,\n",
       "   'reg_alpha': 0.023127948002785937,\n",
       "   'reg_lambda': 4.314456594855414,\n",
       "   'scale_pos_weight': 1.6513804044794713},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84031983067787641,\n",
       "  'counter': 40,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60827002098059335,\n",
       "  'loss': 0.60827002098059335,\n",
       "  'params': {'base_score': 0.37716427054296353,\n",
       "   'colsample_bytree': 0.5275733002357631,\n",
       "   'gamma': 0.35980911032454566,\n",
       "   'learning_rate': 0.09641637784694922,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 1.8861594308262452e-10,\n",
       "   'reg_lambda': 8.669892736737191,\n",
       "   'scale_pos_weight': 0.9749198282154619,\n",
       "   'subsample': 0.9230438002826384},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8147549336625709,\n",
       "  'counter': 41,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60917942738923869,\n",
       "  'loss': 0.60917942738923869,\n",
       "  'params': {'colsample_bylevel': 0.9376184149567206,\n",
       "   'colsample_bytree': 0.9710905347177408,\n",
       "   'gamma': 0.5167871740287502,\n",
       "   'learning_rate': 0.05527683360244918,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_lambda': 7.999195659034034,\n",
       "   'subsample': 0.8805297693194301},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84542987046073648,\n",
       "  'counter': 42,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.53411811405873333,\n",
       "  'loss': 0.53411811405873333,\n",
       "  'params': {'base_score': 0.6410709791560152,\n",
       "   'colsample_bytree': 0.9385994954424838,\n",
       "   'learning_rate': 0.11181750138637135,\n",
       "   'max_depth': 3,\n",
       "   'reg_lambda': 7.131144344942423},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.986972583142258,\n",
       "  'counter': 43,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.4399841603019376,\n",
       "  'loss': 0.4399841603019376,\n",
       "  'params': {'base_score': 0.15438704818116183,\n",
       "   'colsample_bylevel': 0.778637413082053,\n",
       "   'max_depth': 5,\n",
       "   'reg_alpha': 2.5439939070301485e-10},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.92917964998922142,\n",
       "  'counter': 44,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.44827664192715982,\n",
       "  'loss': 0.44827664192715982,\n",
       "  'params': {'base_score': 0.8913157193847405,\n",
       "   'colsample_bylevel': 0.8561070778099428,\n",
       "   'gamma': 0.9541125017415022,\n",
       "   'max_depth': 4},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84090285535108855,\n",
       "  'counter': 45,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61394480552563191,\n",
       "  'loss': 0.61394480552563191,\n",
       "  'params': {'base_score': 0.8259836374099252,\n",
       "   'colsample_bylevel': 0.6915656159149163,\n",
       "   'colsample_bytree': 0.7614870226553634,\n",
       "   'gamma': 0.23663722576548807,\n",
       "   'reg_alpha': 2.7127469862896568e-09,\n",
       "   'reg_lambda': 2.0435608409274932,\n",
       "   'scale_pos_weight': 2.286376946124655},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85113273365081243,\n",
       "  'counter': 46,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.59975929276243234,\n",
       "  'loss': 0.59975929276243234,\n",
       "  'params': {'base_score': 0.4350316734988665,\n",
       "   'colsample_bylevel': 0.6821931163960234,\n",
       "   'gamma': 0.5944392700970689,\n",
       "   'learning_rate': 0.03792845069801982,\n",
       "   'max_depth': 10,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 3.600075940256146e-05,\n",
       "   'reg_lambda': 0.7804005769278028,\n",
       "   'scale_pos_weight': 4.496839330201246},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.90252709349951998,\n",
       "  'counter': 47,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.56771050631200504,\n",
       "  'loss': 0.56771050631200504,\n",
       "  'params': {'base_score': 0.3848554312187912,\n",
       "   'colsample_bytree': 0.9930219811868838,\n",
       "   'max_depth': 4,\n",
       "   'reg_lambda': 9.127112441094988,\n",
       "   'subsample': 0.8079747542469446},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80134536617868968,\n",
       "  'counter': 48,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.54804972253861972,\n",
       "  'loss': 0.54804972253861972,\n",
       "  'params': {'learning_rate': 0.15283136136567171,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.07732851417892672,\n",
       "   'reg_lambda': 8.644596679429783,\n",
       "   'subsample': 0.8652329508116976},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98094146236306268,\n",
       "  'counter': 49,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.42773623629049823,\n",
       "  'loss': 0.42773623629049823,\n",
       "  'params': {'base_score': 0.5501723332148707,\n",
       "   'gamma': 0.7277115265550602,\n",
       "   'learning_rate': 0.05110437594829193,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 2.1608366980256952e-06},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98545377937170509,\n",
       "  'counter': 50,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.47942542154813844,\n",
       "  'loss': 0.47942542154813844,\n",
       "  'params': {'colsample_bylevel': 0.8225382921252917,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_lambda': 8.589737166917216},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.76654516236502246,\n",
       "  'counter': 51,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58655515108840472,\n",
       "  'loss': 0.58655515108840472,\n",
       "  'params': {'base_score': 0.5856333890744579,\n",
       "   'colsample_bylevel': 0.9326289214652335,\n",
       "   'min_child_weight': 10,\n",
       "   'reg_alpha': 0.001109187081110413,\n",
       "   'subsample': 0.5443130672361234},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.86124992650949495,\n",
       "  'counter': 52,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51651818550645678,\n",
       "  'loss': 0.51651818550645678,\n",
       "  'params': {'base_score': 0.4939765019037984,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_lambda': 1.7336165603524454},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87127893076214546,\n",
       "  'counter': 53,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.50578620582374834,\n",
       "  'loss': 0.50578620582374834,\n",
       "  'params': {'colsample_bytree': 0.9934828893728929,\n",
       "   'learning_rate': 0.13881122036909832,\n",
       "   'scale_pos_weight': 2.0988046564206906,\n",
       "   'subsample': 0.9877501935041284},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82477413918121778,\n",
       "  'counter': 54,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.57634324732551634,\n",
       "  'loss': 0.57634324732551634,\n",
       "  'params': {'colsample_bylevel': 0.6140027610911878,\n",
       "   'gamma': 0.6643714638562805,\n",
       "   'reg_alpha': 1.574302737226479e-09,\n",
       "   'reg_lambda': 6.837140487968132,\n",
       "   'subsample': 0.9138877069989726},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.69653810727653986,\n",
       "  'counter': 55,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.69392829289557145,\n",
       "  'loss': 0.69392829289557145,\n",
       "  'params': {'colsample_bylevel': 0.5844604173657935,\n",
       "   'gamma': 0.207712700734195,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 0.45733621404146385,\n",
       "   'reg_lambda': 9.6715309192758,\n",
       "   'scale_pos_weight': 8.20932425527,\n",
       "   'subsample': 0.7016973808999749},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79545142767554422,\n",
       "  'counter': 56,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65959069161674477,\n",
       "  'loss': 0.65959069161674477,\n",
       "  'params': {'colsample_bytree': 0.7000321104043605,\n",
       "   'gamma': 0.8277307682610487,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 0.18774234203643256,\n",
       "   'scale_pos_weight': 8.450339679425332,\n",
       "   'subsample': 0.6851498704168846},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9862327787249886,\n",
       "  'counter': 57,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.37314456727927559,\n",
       "  'loss': 0.37314456727927559,\n",
       "  'params': {'colsample_bylevel': 0.6805365705852497,\n",
       "   'gamma': 0.33626414036645613,\n",
       "   'max_depth': 5,\n",
       "   'reg_lambda': 0.48575558124628504},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81523507162874553,\n",
       "  'counter': 58,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64942040368803566,\n",
       "  'loss': 0.64942040368803566,\n",
       "  'params': {'learning_rate': 0.029713670086073528,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 1.6906586934055612e-07,\n",
       "   'reg_lambda': 6.372419247035008,\n",
       "   'subsample': 0.6217335249441494},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84125560977521707,\n",
       "  'counter': 59,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.52938059385416225,\n",
       "  'loss': 0.52938059385416225,\n",
       "  'params': {'colsample_bylevel': 0.843883968066669,\n",
       "   'gamma': 0.5321008775285428,\n",
       "   'min_child_weight': 5},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.74932878672075565,\n",
       "  'counter': 60,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.63825490888646752,\n",
       "  'loss': 0.63825490888646752,\n",
       "  'params': {'base_score': 0.5290880312323333,\n",
       "   'colsample_bylevel': 0.7771119210113528,\n",
       "   'learning_rate': 0.0280552588930435,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 0.1290837676257977,\n",
       "   'reg_lambda': 5.909726459348906},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.95534226977874459,\n",
       "  'counter': 61,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.47853853521332834,\n",
       "  'loss': 0.47853853521332834,\n",
       "  'params': {'colsample_bylevel': 0.8917775783203605,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 2.509440263018093e-10,\n",
       "   'scale_pos_weight': 5.998900676808297,\n",
       "   'subsample': 0.5340230520614999},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87392948831011041,\n",
       "  'counter': 62,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60112352613720554,\n",
       "  'loss': 0.60112352613720554,\n",
       "  'params': {'colsample_bylevel': 0.8455693985099918,\n",
       "   'colsample_bytree': 0.9765455378126114,\n",
       "   'scale_pos_weight': 7.772988486702895},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.93209477335528246,\n",
       "  'counter': 63,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.53183220095943584,\n",
       "  'loss': 0.53183220095943584,\n",
       "  'params': {'base_score': 0.3136559882420248,\n",
       "   'colsample_bylevel': 0.6177250276614525,\n",
       "   'max_depth': 10,\n",
       "   'reg_lambda': 4.525880476060549},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8236521841378095,\n",
       "  'counter': 64,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.50205512938884966,\n",
       "  'loss': 0.50205512938884966,\n",
       "  'params': {'colsample_bylevel': 0.8768535289138253,\n",
       "   'colsample_bytree': 0.9911757307135998,\n",
       "   'learning_rate': 0.1974418563017841,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.22728671058347436},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81828247790385478,\n",
       "  'counter': 65,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58258909875341036,\n",
       "  'loss': 0.58258909875341036,\n",
       "  'params': {'colsample_bytree': 0.6628249185064845,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 0.498728655312033,\n",
       "   'reg_lambda': 6.184738495731263,\n",
       "   'subsample': 0.8827720307956152},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.92095851216022884,\n",
       "  'counter': 66,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.45345242706789524,\n",
       "  'loss': 0.45345242706789524,\n",
       "  'params': {'colsample_bytree': 0.869496563393928,\n",
       "   'gamma': 0.05626299573085758,\n",
       "   'learning_rate': 0.19452409237749685,\n",
       "   'scale_pos_weight': 1.8516398687495748},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8915182158465127,\n",
       "  'counter': 67,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.47491832762601299,\n",
       "  'loss': 0.47491832762601299,\n",
       "  'params': {'base_score': 0.4047921274378211,\n",
       "   'colsample_bylevel': 0.762954725640158,\n",
       "   'colsample_bytree': 0.9268310251103031,\n",
       "   'gamma': 0.9407226902660163,\n",
       "   'learning_rate': 0.1750479326863249,\n",
       "   'reg_alpha': 0.0008309085092318194,\n",
       "   'scale_pos_weight': 1.370541903540626,\n",
       "   'subsample': 0.7402295213990955},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83620926176338017,\n",
       "  'counter': 68,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58004142128586234,\n",
       "  'loss': 0.58004142128586234,\n",
       "  'params': {'colsample_bytree': 0.7458099633907365,\n",
       "   'learning_rate': 0.08880244152687498,\n",
       "   'scale_pos_weight': 3.982479970036621,\n",
       "   'subsample': 0.674902430689714},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8191055715601544,\n",
       "  'counter': 69,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51229949148951981,\n",
       "  'loss': 0.51229949148951981,\n",
       "  'params': {'base_score': 0.7015466449826175,\n",
       "   'colsample_bylevel': 0.8387140868348782,\n",
       "   'learning_rate': 0.15655616259146163,\n",
       "   'min_child_weight': 7},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87853489329178669,\n",
       "  'counter': 70,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.46711155743339555,\n",
       "  'loss': 0.46711155743339555,\n",
       "  'params': {'gamma': 0.8304091317760383,\n",
       "   'learning_rate': 0.18655844981807934,\n",
       "   'reg_lambda': 2.7117393357439976,\n",
       "   'subsample': 0.8488915136099406},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.74976483038391439,\n",
       "  'counter': 71,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.59992163542841304,\n",
       "  'loss': 0.59992163542841304,\n",
       "  'params': {'colsample_bylevel': 0.5190081710785646,\n",
       "   'colsample_bytree': 0.5617247196242932,\n",
       "   'gamma': 0.19612687885921543,\n",
       "   'learning_rate': 0.1407676346176043,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 0.0004641575515615427,\n",
       "   'reg_lambda': 3.32262823186835,\n",
       "   'subsample': 0.5888416699757504},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80796441099809901,\n",
       "  'counter': 72,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64541501806141188,\n",
       "  'loss': 0.64541501806141188,\n",
       "  'params': {'colsample_bylevel': 0.77259633061198,\n",
       "   'colsample_bytree': 0.8216398443148835,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 1.7429783308678434e-07,\n",
       "   'scale_pos_weight': 7.437692145103946},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.90059184353381549,\n",
       "  'counter': 73,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.48082460176571651,\n",
       "  'loss': 0.48082460176571651,\n",
       "  'params': {'colsample_bylevel': 0.8709953806199363,\n",
       "   'colsample_bytree': 0.8657838838456496,\n",
       "   'gamma': 0.7421224848005188,\n",
       "   'learning_rate': 0.13307776380570055,\n",
       "   'reg_alpha': 0.026243679997381995},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8843749387579124,\n",
       "  'counter': 74,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.49957926553603255,\n",
       "  'loss': 0.49957926553603255,\n",
       "  'params': {'base_score': 0.7595104657382621,\n",
       "   'colsample_bylevel': 0.6759374542177303},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80229584337703574,\n",
       "  'counter': 75,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.67506208287443736,\n",
       "  'loss': 0.67506208287443736,\n",
       "  'params': {'colsample_bylevel': 0.5597564319349952,\n",
       "   'gamma': 0.0965515370605764,\n",
       "   'learning_rate': 0.16160014720475765,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_lambda': 6.628711682104667,\n",
       "   'scale_pos_weight': 5.959298774570999,\n",
       "   'subsample': 0.9455410185987998},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8187234209340154,\n",
       "  'counter': 76,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61835241773000593,\n",
       "  'loss': 0.61835241773000593,\n",
       "  'params': {'colsample_bylevel': 0.9519846078726443,\n",
       "   'colsample_bytree': 0.6322637271165976,\n",
       "   'learning_rate': 0.08114997870741336,\n",
       "   'reg_alpha': 3.1204727321498765e-05,\n",
       "   'scale_pos_weight': 6.222752722638753},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79867521116271778,\n",
       "  'counter': 77,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58927079488907774,\n",
       "  'loss': 0.58927079488907774,\n",
       "  'params': {'colsample_bytree': 0.5601904458681094,\n",
       "   'gamma': 0.5216233205411112,\n",
       "   'learning_rate': 0.15673044253789747,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_lambda': 4.703143689298725,\n",
       "   'scale_pos_weight': 2.849766974992788},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.69130068395163347,\n",
       "  'counter': 78,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62295230454730566,\n",
       "  'loss': 0.62295230454730566,\n",
       "  'params': {'base_score': 0.39709018112091743,\n",
       "   'gamma': 0.8578157775768855,\n",
       "   'learning_rate': 0.04610470965570295,\n",
       "   'reg_alpha': 4.731038292907027e-09,\n",
       "   'reg_lambda': 3.374636542357583,\n",
       "   'scale_pos_weight': 8.615660588340992},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.86309208850216557,\n",
       "  'counter': 79,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65510254747466079,\n",
       "  'loss': 0.65510254747466079,\n",
       "  'params': {'base_score': 0.3660420945900035,\n",
       "   'colsample_bylevel': 0.7809175429572621,\n",
       "   'colsample_bytree': 0.7882001868600724,\n",
       "   'learning_rate': 0.04945818956770296,\n",
       "   'max_depth': 8,\n",
       "   'reg_alpha': 5.988502400163365e-08,\n",
       "   'reg_lambda': 6.837346377283481},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81754757285358726,\n",
       "  'counter': 80,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.71480004908031214,\n",
       "  'loss': 0.71480004908031214,\n",
       "  'params': {'learning_rate': 0.18347712972333693,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 8.72858750659453e-05,\n",
       "   'reg_lambda': 9.298130054678145,\n",
       "   'scale_pos_weight': 6.7412486251779375,\n",
       "   'subsample': 0.5531244869199835},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80799870656711159,\n",
       "  'counter': 81,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61935959993993472,\n",
       "  'loss': 0.61935959993993472,\n",
       "  'params': {'learning_rate': 0.033265124558681226,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81876261587002963,\n",
       "  'counter': 82,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.5830521350379495,\n",
       "  'loss': 0.5830521350379495,\n",
       "  'params': {'base_score': 0.5143529403546298,\n",
       "   'colsample_bytree': 0.7713522581058057,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_lambda': 8.53003865099797,\n",
       "   'subsample': 0.6825552862527678},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83690987124463512,\n",
       "  'counter': 83,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.54102744262015945,\n",
       "  'loss': 0.54102744262015945,\n",
       "  'params': {'colsample_bylevel': 0.5392320201067464,\n",
       "   'gamma': 0.876120831604173,\n",
       "   'learning_rate': 0.19623762091248506,\n",
       "   'reg_alpha': 0.0020881668636361945,\n",
       "   'reg_lambda': 5.667813720571123,\n",
       "   'subsample': 0.6425376533292089},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.78564289493797412,\n",
       "  'counter': 84,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.63053678586834772,\n",
       "  'loss': 0.63053678586834772,\n",
       "  'params': {'colsample_bylevel': 0.6427020781012366,\n",
       "   'colsample_bytree': 0.9079211603894015,\n",
       "   'gamma': 0.07348006776812266,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 0.0002952472061757965,\n",
       "   'reg_lambda': 7.467306184818209,\n",
       "   'scale_pos_weight': 4.152492539915862},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.69130068395163347,\n",
       "  'counter': 85,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.66305743946226092,\n",
       "  'loss': 0.66305743946226092,\n",
       "  'params': {'colsample_bylevel': 0.6513447141056838,\n",
       "   'gamma': 0.43102210030415267,\n",
       "   'learning_rate': 0.07215155772480165,\n",
       "   'reg_alpha': 2.453113395940956e-06,\n",
       "   'reg_lambda': 7.841591933192395,\n",
       "   'scale_pos_weight': 7.81377577461791,\n",
       "   'subsample': 0.515524749109282},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81291277166990028,\n",
       "  'counter': 86,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62735744269256621,\n",
       "  'loss': 0.62735744269256621,\n",
       "  'params': {'colsample_bylevel': 0.6826382812012364,\n",
       "   'colsample_bytree': 0.6188788561793175,\n",
       "   'gamma': 0.48734539406628263,\n",
       "   'learning_rate': 0.11172790958069265,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 6,\n",
       "   'scale_pos_weight': 4.524948152917895,\n",
       "   'subsample': 0.8114197891578256},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83377427636349377,\n",
       "  'counter': 87,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58151705445369206,\n",
       "  'loss': 0.58151705445369206,\n",
       "  'params': {'base_score': 0.7515780549154465,\n",
       "   'colsample_bylevel': 0.8476288727495247,\n",
       "   'colsample_bytree': 0.6379256073591052,\n",
       "   'gamma': 0.6671348958184127,\n",
       "   'max_depth': 7,\n",
       "   'reg_alpha': 0.0011301538662431116,\n",
       "   'reg_lambda': 8.773413414241615,\n",
       "   'scale_pos_weight': 1.1343776243379273},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8277823505203129,\n",
       "  'counter': 88,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62883858122875369,\n",
       "  'loss': 0.62883858122875369,\n",
       "  'params': {'colsample_bylevel': 0.6240621313307908,\n",
       "   'colsample_bytree': 0.8621930426428457,\n",
       "   'gamma': 0.5751958569139761,\n",
       "   'learning_rate': 0.08780645278995504,\n",
       "   'scale_pos_weight': 9.78215356539561},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.90335508652282126,\n",
       "  'counter': 89,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.46283839699630408,\n",
       "  'loss': 0.46283839699630408,\n",
       "  'params': {'colsample_bylevel': 0.6508676776486799,\n",
       "   'learning_rate': 0.1694190583157303,\n",
       "   'reg_alpha': 2.887394732762719e-10},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81900758422011877,\n",
       "  'counter': 90,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.70110398972887222,\n",
       "  'loss': 0.70110398972887222,\n",
       "  'params': {'base_score': 0.8842123451481619,\n",
       "   'colsample_bytree': 0.6317220592590076,\n",
       "   'learning_rate': 0.021520087581346936},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79259999608050646,\n",
       "  'counter': 91,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.67642618291601875,\n",
       "  'loss': 0.67642618291601875,\n",
       "  'params': {'base_score': 0.16910804100048127,\n",
       "   'colsample_bylevel': 0.5160020899156443,\n",
       "   'gamma': 0.05744206757824111,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 1.3467481930726572e-08,\n",
       "   'reg_lambda': 9.778583772402175,\n",
       "   'subsample': 0.8968528875531231},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.92240382542575505,\n",
       "  'counter': 92,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.43170797943669176,\n",
       "  'loss': 0.43170797943669176,\n",
       "  'params': {'base_score': 0.4546044795615085,\n",
       "   'learning_rate': 0.18112476080341794,\n",
       "   'max_depth': 4,\n",
       "   'scale_pos_weight': 3.689011893019332,\n",
       "   'subsample': 0.5046633332048214},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8734297528759285,\n",
       "  'counter': 93,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.67999089029013848,\n",
       "  'loss': 0.67999089029013848,\n",
       "  'params': {'base_score': 0.8804805927076786,\n",
       "   'colsample_bytree': 0.6310167671130831,\n",
       "   'gamma': 0.9608625100489567,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 4,\n",
       "   'scale_pos_weight': 5.125455758231628},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82717482901209172,\n",
       "  'counter': 94,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.6083516716823848,\n",
       "  'loss': 0.6083516716823848,\n",
       "  'params': {'base_score': 0.308597743520136,\n",
       "   'colsample_bylevel': 0.8832438018494801,\n",
       "   'learning_rate': 0.10497048803357929,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 10,\n",
       "   'scale_pos_weight': 6.769592807971556,\n",
       "   'subsample': 0.7587103001586035},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83390655927254198,\n",
       "  'counter': 95,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.55858594241334147,\n",
       "  'loss': 0.55858594241334147,\n",
       "  'params': {'colsample_bytree': 0.9548705513478883,\n",
       "   'gamma': 0.31957915340105536,\n",
       "   'learning_rate': 0.06049389939436136},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85587042154153681,\n",
       "  'counter': 96,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62979115605709624,\n",
       "  'loss': 0.62979115605709624,\n",
       "  'params': {'base_score': 0.6464603498127436,\n",
       "   'learning_rate': 0.05838221698363256,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 3.0726953402075566e-05,\n",
       "   'reg_lambda': 9.842230064328843,\n",
       "   'scale_pos_weight': 5.793535316966673,\n",
       "   'subsample': 0.6218620631585416},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80354518196249047,\n",
       "  'counter': 97,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.55367243978376712,\n",
       "  'loss': 0.55367243978376712,\n",
       "  'params': {'base_score': 0.6041772677706194,\n",
       "   'colsample_bytree': 0.7509814966065929,\n",
       "   'gamma': 0.3137015701802698,\n",
       "   'min_child_weight': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87463009779136525,\n",
       "  'counter': 98,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.4657177197540126,\n",
       "  'loss': 0.4657177197540126,\n",
       "  'params': {'base_score': 0.7747616711304494,\n",
       "   'colsample_bytree': 0.9972391185995656,\n",
       "   'learning_rate': 0.15077908578270424,\n",
       "   'reg_alpha': 6.095718830385236e-09},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9844347110353342,\n",
       "  'counter': 99,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.34593430392433028,\n",
       "  'loss': 0.34593430392433028,\n",
       "  'params': {'learning_rate': 0.08397151663781838, 'max_depth': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82963431124698683,\n",
       "  'counter': 100,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.57601209857602409,\n",
       "  'loss': 0.57601209857602409,\n",
       "  'params': {'colsample_bytree': 0.745322826766913,\n",
       "   'gamma': 0.06657178836494215,\n",
       "   'learning_rate': 0.07950580895777726,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_lambda': 7.131127688738765},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84733572422443015,\n",
       "  'counter': 101,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.54889236059700497,\n",
       "  'loss': 0.54889236059700497,\n",
       "  'params': {'reg_alpha': 0.040283660331020474,\n",
       "   'scale_pos_weight': 4.510839432216187},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.91702432045779692,\n",
       "  'counter': 102,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51667537121588003,\n",
       "  'loss': 0.51667537121588003,\n",
       "  'params': {'colsample_bytree': 0.5899485623190004,\n",
       "   'gamma': 0.615491105889301,\n",
       "   'max_depth': 6,\n",
       "   'reg_lambda': 2.457142463700891},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.71770827209124588,\n",
       "  'counter': 103,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.64944648736013566,\n",
       "  'loss': 0.64944648736013566,\n",
       "  'params': {'colsample_bytree': 0.8314241795008055,\n",
       "   'gamma': 0.2961070479916855,\n",
       "   'max_depth': 7,\n",
       "   'reg_alpha': 5.761194938656948e-09,\n",
       "   'reg_lambda': 5.887530152845781,\n",
       "   'scale_pos_weight': 9.701144400235187},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98757520528347742,\n",
       "  'counter': 104,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.26303533199291829,\n",
       "  'loss': 0.26303533199291829,\n",
       "  'params': {'learning_rate': 0.1525696762274703, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9388754972857507,\n",
       "  'counter': 105,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.44330172325122197,\n",
       "  'loss': 0.44330172325122197,\n",
       "  'params': {'colsample_bytree': 0.9596232840050427,\n",
       "   'gamma': 0.6786785925059716,\n",
       "   'learning_rate': 0.0937213101767643,\n",
       "   'max_depth': 4,\n",
       "   'reg_alpha': 4.403259655851586e-05},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81685676210633584,\n",
       "  'counter': 106,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51372696715788768,\n",
       "  'loss': 0.51372696715788768,\n",
       "  'params': {'base_score': 0.5059655306798135,\n",
       "   'gamma': 0.348887432478715,\n",
       "   'learning_rate': 0.13901873580443216,\n",
       "   'min_child_weight': 7},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.89205714621670873,\n",
       "  'counter': 107,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.52276870743794879,\n",
       "  'loss': 0.52276870743794879,\n",
       "  'params': {'base_score': 0.318105780922152,\n",
       "   'colsample_bylevel': 0.5853009001141644,\n",
       "   'colsample_bytree': 0.9673070813430631,\n",
       "   'learning_rate': 0.10598039379859753,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8099290571658142,\n",
       "  'counter': 108,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.63001643212292835,\n",
       "  'loss': 0.63001643212292835,\n",
       "  'params': {'colsample_bylevel': 0.5050016566559016,\n",
       "   'colsample_bytree': 0.5336653739787816,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 4.597242497989092e-09,\n",
       "   'scale_pos_weight': 4.08203841709406},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8672026574166618,\n",
       "  'counter': 109,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.5581589794638615,\n",
       "  'loss': 0.5581589794638615,\n",
       "  'params': {'colsample_bylevel': 0.7702098509078763,\n",
       "   'colsample_bytree': 0.7298185565329536,\n",
       "   'learning_rate': 0.07680483570814363,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 2,\n",
       "   'subsample': 0.6659068594116215},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80199208262292521,\n",
       "  'counter': 110,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.57456569267012148,\n",
       "  'loss': 0.57456569267012148,\n",
       "  'params': {'colsample_bytree': 0.7588548438892797,\n",
       "   'gamma': 0.19140578723420298,\n",
       "   'learning_rate': 0.17068664268760383,\n",
       "   'reg_lambda': 9.388583121870603,\n",
       "   'subsample': 0.5058856690935579},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84292629392282525,\n",
       "  'counter': 111,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.71337268965654688,\n",
       "  'loss': 0.71337268965654688,\n",
       "  'params': {'base_score': 0.8508569638598146,\n",
       "   'scale_pos_weight': 8.557893140909496},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82120740000391956,\n",
       "  'counter': 112,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58772112142666622,\n",
       "  'loss': 0.58772112142666622,\n",
       "  'params': {'colsample_bylevel': 0.9291848161025544,\n",
       "   'colsample_bytree': 0.928277548229677,\n",
       "   'learning_rate': 0.06539252317438479,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_lambda': 4.37807292033815,\n",
       "   'scale_pos_weight': 1.9301029752883125},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.77220883061908407,\n",
       "  'counter': 113,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.61651776564458793,\n",
       "  'loss': 0.61651776564458793,\n",
       "  'params': {'base_score': 0.27351274793284186,\n",
       "   'colsample_bytree': 0.8339962133745691,\n",
       "   'reg_alpha': 1.6974949520123943e-07,\n",
       "   'reg_lambda': 3.790184956832961,\n",
       "   'scale_pos_weight': 6.204187122834512,\n",
       "   'subsample': 0.8697478901386764},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.81670978109628234,\n",
       "  'counter': 114,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.53748030485321618,\n",
       "  'loss': 0.53748030485321618,\n",
       "  'params': {'base_score': 0.46453393900194884,\n",
       "   'colsample_bytree': 0.6734671861732784,\n",
       "   'learning_rate': 0.16114066753554557,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_lambda': 4.086420943229048},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.84856546534187782,\n",
       "  'counter': 115,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.54459198423274047,\n",
       "  'loss': 0.54459198423274047,\n",
       "  'params': {'colsample_bylevel': 0.7767900311208558,\n",
       "   'gamma': 0.7139073091505532,\n",
       "   'learning_rate': 0.09914139642508368,\n",
       "   'reg_alpha': 0.00017792523862963453,\n",
       "   'subsample': 0.5425850214410985},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.78573598291100788,\n",
       "  'counter': 116,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.60046034411772886,\n",
       "  'loss': 0.60046034411772886,\n",
       "  'params': {'colsample_bytree': 0.54532667613986,\n",
       "   'min_child_weight': 10,\n",
       "   'reg_lambda': 9.033838943288188},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.75154819997256361,\n",
       "  'counter': 117,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.65737568081846531,\n",
       "  'loss': 0.65737568081846531,\n",
       "  'params': {'base_score': 0.8640675469158898,\n",
       "   'colsample_bylevel': 0.9941834649836025,\n",
       "   'colsample_bytree': 0.9652800852826537,\n",
       "   'gamma': 0.9631803634696013,\n",
       "   'learning_rate': 0.03639611705970446,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 1.4075891520759342e-10,\n",
       "   'subsample': 0.9728198935030281},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.74507613616320767,\n",
       "  'counter': 118,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.78934517316242625,\n",
       "  'loss': 0.78934517316242625,\n",
       "  'params': {'min_child_weight': 8,\n",
       "   'reg_alpha': 0.7394473065100763,\n",
       "   'scale_pos_weight': 0.1607663174703867},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9346130479941992,\n",
       "  'counter': 119,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.49381370340569719,\n",
       "  'loss': 0.49381370340569719,\n",
       "  'params': {'base_score': 0.17004093470269233,\n",
       "   'colsample_bytree': 0.6824372730902424,\n",
       "   'max_depth': 10,\n",
       "   'scale_pos_weight': 3.883263082893328},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.70950183236325859,\n",
       "  'counter': 120,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.63186318321839174,\n",
       "  'loss': 0.63186318321839174,\n",
       "  'params': {'base_score': 0.3118153920617016,\n",
       "   'gamma': 0.911682772876739,\n",
       "   'reg_lambda': 6.41473695221895,\n",
       "   'scale_pos_weight': 7.368887912876869,\n",
       "   'subsample': 0.9233125970597771},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.77203735277402163,\n",
       "  'counter': 121,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.68763040297077593,\n",
       "  'loss': 0.68763040297077593,\n",
       "  'params': {'colsample_bytree': 0.9096968397990647,\n",
       "   'learning_rate': 0.17129015787882482,\n",
       "   'max_depth': 10,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_lambda': 6.010346534691161,\n",
       "   'scale_pos_weight': 6.194518376632726},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85503262978423189,\n",
       "  'counter': 122,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.55442351931164768,\n",
       "  'loss': 0.55442351931164768,\n",
       "  'params': {'base_score': 0.5509956891849028,\n",
       "   'colsample_bylevel': 0.9666342106260783,\n",
       "   'gamma': 0.1792124005516157,\n",
       "   'scale_pos_weight': 3.1444594635135523,\n",
       "   'subsample': 0.7378516723698312},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83961432182961959,\n",
       "  'counter': 123,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.58339934510729885,\n",
       "  'loss': 0.58339934510729885,\n",
       "  'params': {'colsample_bytree': 0.5898012702659365,\n",
       "   'learning_rate': 0.060061211329622756,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 5},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.869887510533639,\n",
       "  'counter': 124,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.51657057907737669,\n",
       "  'loss': 0.51657057907737669,\n",
       "  'params': {'base_score': 0.7694543565653035,\n",
       "   'colsample_bytree': 0.8423940696172704,\n",
       "   'gamma': 0.3395402165369853,\n",
       "   'subsample': 0.8588063916199598},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.76258157446057973,\n",
       "  'counter': 125,\n",
       "  'iterations': 2.4,\n",
       "  'log_loss': 0.62856927240925287,\n",
       "  'loss': 0.62856927240925287,\n",
       "  'params': {'base_score': 0.8722892640127867,\n",
       "   'colsample_bylevel': 0.9961829110646094,\n",
       "   'colsample_bytree': 0.6387221709015193,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 1.3962129818360334e-06,\n",
       "   'reg_lambda': 7.821064525737356,\n",
       "   'subsample': 0.7327395446179624},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99091657357869378,\n",
       "  'counter': 126,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.15150789149388694,\n",
       "  'loss': 0.15150789149388694,\n",
       "  'params': {'learning_rate': 0.1525696762274703, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98962314069022284,\n",
       "  'counter': 127,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.17721426146918279,\n",
       "  'loss': 0.17721426146918279,\n",
       "  'params': {'learning_rate': 0.08397151663781838, 'max_depth': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99214141532913946,\n",
       "  'counter': 128,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.17769878185819141,\n",
       "  'loss': 0.17769878185819141,\n",
       "  'params': {'colsample_bylevel': 0.6805365705852497,\n",
       "   'gamma': 0.33626414036645613,\n",
       "   'max_depth': 5,\n",
       "   'reg_lambda': 0.48575558124628504},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99450291022399906,\n",
       "  'counter': 129,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.16416990004019083,\n",
       "  'loss': 0.16416990004019083,\n",
       "  'params': {'base_score': 0.2697155552230666,\n",
       "   'max_depth': 8,\n",
       "   'subsample': 0.8758244966382095},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99086757990867569,\n",
       "  'counter': 130,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.20595086969840501,\n",
       "  'loss': 0.20595086969840501,\n",
       "  'params': {'colsample_bylevel': 0.9943362690192601,\n",
       "   'gamma': 0.39934834513402806,\n",
       "   'max_depth': 7,\n",
       "   'reg_alpha': 0.023127948002785937,\n",
       "   'reg_lambda': 4.314456594855414,\n",
       "   'scale_pos_weight': 1.6513804044794713},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99231779254120367,\n",
       "  'counter': 131,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.17790141303006188,\n",
       "  'loss': 0.17790141303006188,\n",
       "  'params': {'base_score': 0.23323220855719884,\n",
       "   'colsample_bylevel': 0.6001882404701808,\n",
       "   'max_depth': 8,\n",
       "   'reg_alpha': 2.509229358303713e-06,\n",
       "   'reg_lambda': 0.3367777853955599,\n",
       "   'scale_pos_weight': 0.7436642594737095},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98724694769435795,\n",
       "  'counter': 132,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.2198182433543813,\n",
       "  'loss': 0.2198182433543813,\n",
       "  'params': {'base_score': 0.5501723332148707,\n",
       "   'gamma': 0.7277115265550602,\n",
       "   'learning_rate': 0.05110437594829193,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 2.1608366980256952e-06},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98038293452485936,\n",
       "  'counter': 133,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.23208551786891315,\n",
       "  'loss': 0.23208551786891315,\n",
       "  'params': {'base_score': 0.4546044795615085,\n",
       "   'learning_rate': 0.18112476080341794,\n",
       "   'max_depth': 4,\n",
       "   'scale_pos_weight': 3.689011893019332,\n",
       "   'subsample': 0.5046633332048214},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99405216845983491,\n",
       "  'counter': 134,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.16480603503360344,\n",
       "  'loss': 0.16480603503360344,\n",
       "  'params': {'base_score': 0.15438704818116183,\n",
       "   'colsample_bylevel': 0.778637413082053,\n",
       "   'max_depth': 5,\n",
       "   'reg_alpha': 2.5439939070301485e-10},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98942716601015157,\n",
       "  'counter': 135,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.21977344953806185,\n",
       "  'loss': 0.21977344953806185,\n",
       "  'params': {'colsample_bytree': 0.9596232840050427,\n",
       "   'gamma': 0.6786785925059716,\n",
       "   'learning_rate': 0.0937213101767643,\n",
       "   'max_depth': 4,\n",
       "   'reg_alpha': 4.403259655851586e-05},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98346953573598284,\n",
       "  'counter': 136,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.25039146950637753,\n",
       "  'loss': 0.25039146950637753,\n",
       "  'params': {'base_score': 0.8913157193847405,\n",
       "   'colsample_bylevel': 0.8561070778099428,\n",
       "   'gamma': 0.9541125017415022,\n",
       "   'max_depth': 4},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99105375585474353,\n",
       "  'counter': 137,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.20960295993984634,\n",
       "  'loss': 0.20960295993984634,\n",
       "  'params': {'base_score': 0.8692320258880805,\n",
       "   'max_depth': 10,\n",
       "   'reg_lambda': 1.8143913886403642,\n",
       "   'subsample': 0.937398340836006},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98359691927802917,\n",
       "  'counter': 138,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.23723951537955285,\n",
       "  'loss': 0.23723951537955285,\n",
       "  'params': {'colsample_bytree': 0.869496563393928,\n",
       "   'gamma': 0.05626299573085758,\n",
       "   'learning_rate': 0.19452409237749685,\n",
       "   'scale_pos_weight': 1.8516398687495748},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97346502831834125,\n",
       "  'counter': 139,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.27857251738089839,\n",
       "  'loss': 0.27857251738089839,\n",
       "  'params': {'colsample_bylevel': 0.6508676776486799,\n",
       "   'learning_rate': 0.1694190583157303,\n",
       "   'reg_alpha': 2.887394732762719e-10},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97773727634389629,\n",
       "  'counter': 140,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.26303224407858877,\n",
       "  'loss': 0.26303224407858877,\n",
       "  'params': {'base_score': 0.7747616711304494,\n",
       "   'colsample_bytree': 0.9972391185995656,\n",
       "   'learning_rate': 0.15077908578270424,\n",
       "   'reg_alpha': 6.095718830385236e-09},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96526348795735584,\n",
       "  'counter': 141,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.29350506422427747,\n",
       "  'loss': 0.29350506422427747,\n",
       "  'params': {'gamma': 0.8304091317760383,\n",
       "   'learning_rate': 0.18655844981807934,\n",
       "   'reg_lambda': 2.7117393357439976,\n",
       "   'subsample': 0.8488915136099406},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96298038293452481,\n",
       "  'counter': 142,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.30137164144111928,\n",
       "  'loss': 0.30137164144111928,\n",
       "  'params': {'base_score': 0.4047921274378211,\n",
       "   'colsample_bylevel': 0.762954725640158,\n",
       "   'colsample_bytree': 0.9268310251103031,\n",
       "   'gamma': 0.9407226902660163,\n",
       "   'learning_rate': 0.1750479326863249,\n",
       "   'reg_alpha': 0.0008309085092318194,\n",
       "   'scale_pos_weight': 1.370541903540626,\n",
       "   'subsample': 0.7402295213990955},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98637975973504222,\n",
       "  'counter': 143,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.25364187038774239,\n",
       "  'loss': 0.25364187038774239,\n",
       "  'params': {'colsample_bylevel': 0.8917775783203605,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 2.509440263018093e-10,\n",
       "   'scale_pos_weight': 5.998900676808297,\n",
       "   'subsample': 0.5340230520614999},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98647774707507774,\n",
       "  'counter': 144,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.28714304871512952,\n",
       "  'loss': 0.28714304871512952,\n",
       "  'params': {'colsample_bylevel': 0.8225382921252917,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_lambda': 8.589737166917216},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9664197385697767,\n",
       "  'counter': 145,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.3090896048019578,\n",
       "  'loss': 0.3090896048019578,\n",
       "  'params': {'colsample_bylevel': 0.8709953806199363,\n",
       "   'colsample_bytree': 0.8657838838456496,\n",
       "   'gamma': 0.7421224848005188,\n",
       "   'learning_rate': 0.13307776380570055,\n",
       "   'reg_alpha': 0.026243679997381995},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99163188116095391,\n",
       "  'counter': 146,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.23187594398114991,\n",
       "  'loss': 0.23187594398114991,\n",
       "  'params': {'base_score': 0.17004093470269233,\n",
       "   'colsample_bytree': 0.6824372730902424,\n",
       "   'max_depth': 10,\n",
       "   'scale_pos_weight': 3.883263082893328},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.94023752131224647,\n",
       "  'counter': 147,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.34967845898876648,\n",
       "  'loss': 0.34967845898876648,\n",
       "  'params': {'base_score': 0.7595104657382621,\n",
       "   'colsample_bylevel': 0.6759374542177303},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.90288474729065005,\n",
       "  'counter': 148,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.40219724576936927,\n",
       "  'loss': 0.40219724576936927,\n",
       "  'params': {'colsample_bylevel': 0.8768535289138253,\n",
       "   'colsample_bytree': 0.9911757307135998,\n",
       "   'learning_rate': 0.1974418563017841,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 0.22728671058347436},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98514511925059278,\n",
       "  'counter': 149,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.31134860960963762,\n",
       "  'loss': 0.31134860960963762,\n",
       "  'params': {'base_score': 0.49261530391627795,\n",
       "   'colsample_bylevel': 0.8598587930959023,\n",
       "   'gamma': 0.3642883152833015,\n",
       "   'learning_rate': 0.0860038674839635,\n",
       "   'max_depth': 8,\n",
       "   'reg_lambda': 7.645837501391092,\n",
       "   'scale_pos_weight': 0.9269814218271035},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97544437258706174,\n",
       "  'counter': 150,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.29005170721753643,\n",
       "  'loss': 0.29005170721753643,\n",
       "  'params': {'colsample_bytree': 0.9934828893728929,\n",
       "   'learning_rate': 0.13881122036909832,\n",
       "   'scale_pos_weight': 2.0988046564206906,\n",
       "   'subsample': 0.9877501935041284},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99224920140317874,\n",
       "  'counter': 151,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.11817436530720617,\n",
       "  'loss': 0.11817436530720617,\n",
       "  'params': {'learning_rate': 0.1525696762274703, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99381699884374941,\n",
       "  'counter': 152,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.1193615665370699,\n",
       "  'loss': 0.1193615665370699,\n",
       "  'params': {'base_score': 0.2697155552230666,\n",
       "   'max_depth': 8,\n",
       "   'subsample': 0.8758244966382095},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99386599251376717,\n",
       "  'counter': 153,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.11899745162690423,\n",
       "  'loss': 0.11899745162690423,\n",
       "  'params': {'base_score': 0.15438704818116183,\n",
       "   'colsample_bylevel': 0.778637413082053,\n",
       "   'max_depth': 5,\n",
       "   'reg_alpha': 2.5439939070301485e-10},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99134771787485054,\n",
       "  'counter': 154,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.13153183213933045,\n",
       "  'loss': 0.13153183213933045,\n",
       "  'params': {'learning_rate': 0.08397151663781838, 'max_depth': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99289591784741416,\n",
       "  'counter': 155,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.14593262150075187,\n",
       "  'loss': 0.14593262150075187,\n",
       "  'params': {'colsample_bylevel': 0.6805365705852497,\n",
       "   'gamma': 0.33626414036645613,\n",
       "   'max_depth': 5,\n",
       "   'reg_lambda': 0.48575558124628504},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99040703941050823,\n",
       "  'counter': 156,\n",
       "  'iterations': 300.0,\n",
       "  'log_loss': 0.11777917088736595,\n",
       "  'loss': 0.11777917088736595,\n",
       "  'params': {'learning_rate': 0.1525696762274703, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.82550414486448354,\n",
       "  'counter': 157,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.65801833092544548,\n",
       "  'loss': 0.65801833092544548,\n",
       "  'params': {'colsample_bylevel': 0.8167810246998367,\n",
       "   'learning_rate': 0.011114756463611495,\n",
       "   'reg_lambda': 6.535104634852409,\n",
       "   'scale_pos_weight': 0.26647630733359684},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87118584278911171,\n",
       "  'counter': 158,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.46591164029568388,\n",
       "  'loss': 0.46591164029568388,\n",
       "  'params': {'base_score': 0.7829689916869749,\n",
       "   'colsample_bytree': 0.9814585792998852,\n",
       "   'gamma': 0.7540959658000326,\n",
       "   'learning_rate': 0.10757668304002133,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_lambda': 8.605215630902991,\n",
       "   'subsample': 0.5627739647624941},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.87482117310443486,\n",
       "  'counter': 159,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.47462951691041183,\n",
       "  'loss': 0.47462951691041183,\n",
       "  'params': {'base_score': 0.8067212916426657,\n",
       "   'colsample_bylevel': 0.876576635492587,\n",
       "   'gamma': 0.137585088248811,\n",
       "   'learning_rate': 0.1242946239535829,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 7.305343409363043e-10,\n",
       "   'scale_pos_weight': 1.9904974118325625,\n",
       "   'subsample': 0.745704692303357},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.79948850608501387,\n",
       "  'counter': 160,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.58829037104518156,\n",
       "  'loss': 0.58829037104518156,\n",
       "  'params': {'colsample_bytree': 0.5162730025653296,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_alpha': 3.47201149242769e-05,\n",
       "   'reg_lambda': 7.441954581335533,\n",
       "   'scale_pos_weight': 2.3045687207997387},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.90721578772022649,\n",
       "  'counter': 161,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.41341749051566362,\n",
       "  'loss': 0.41341749051566362,\n",
       "  'params': {'colsample_bylevel': 0.928411127540913,\n",
       "   'colsample_bytree': 0.7708228528913176,\n",
       "   'learning_rate': 0.1981532586291729,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_alpha': 4.955911275286339e-08,\n",
       "   'reg_lambda': 8.819714913793442,\n",
       "   'subsample': 0.758805765139648},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.91686754071373988,\n",
       "  'counter': 162,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.40561552616405327,\n",
       "  'loss': 0.40561552616405327,\n",
       "  'params': {'reg_alpha': 0.000959507768081225,\n",
       "   'reg_lambda': 8.076824030249242},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98950555588217992,\n",
       "  'counter': 163,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.24792491046964413,\n",
       "  'loss': 0.24792491046964413,\n",
       "  'params': {'base_score': 0.11852393526730474,\n",
       "   'colsample_bylevel': 0.530145500671511,\n",
       "   'colsample_bytree': 0.929166857733412,\n",
       "   'gamma': 0.6477716727429028,\n",
       "   'max_depth': 9,\n",
       "   'subsample': 0.8872303522601266},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96896740941070414,\n",
       "  'counter': 164,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.41177494545021665,\n",
       "  'loss': 0.41177494545021665,\n",
       "  'params': {'base_score': 0.1794780366479901,\n",
       "   'colsample_bytree': 0.7776630793164538,\n",
       "   'learning_rate': 0.11664675315033597,\n",
       "   'scale_pos_weight': 4.930799723197132},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.91515276226311559,\n",
       "  'counter': 165,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.57465675343369338,\n",
       "  'loss': 0.57465675343369338,\n",
       "  'params': {'base_score': 0.46873697627271027,\n",
       "   'gamma': 0.2757615544943408,\n",
       "   'learning_rate': 0.1418896908528227,\n",
       "   'reg_alpha': 9.29027478118385e-05,\n",
       "   'reg_lambda': 8.807546107205347,\n",
       "   'scale_pos_weight': 6.301611584983098,\n",
       "   'subsample': 0.671352384093248},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.85911380249671732,\n",
       "  'counter': 166,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.70653772656007741,\n",
       "  'loss': 0.70653772656007741,\n",
       "  'params': {'min_child_weight': 6,\n",
       "   'reg_lambda': 4.389426428152262,\n",
       "   'scale_pos_weight': 7.242907756480696,\n",
       "   'subsample': 0.5781885111364499},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97821741431007114,\n",
       "  'counter': 167,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.36222505027667001,\n",
       "  'loss': 0.36222505027667001,\n",
       "  'params': {'base_score': 0.6702028305852819,\n",
       "   'colsample_bytree': 0.5607136974662824,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 0.008456071957485347,\n",
       "   'scale_pos_weight': 7.666934420401439,\n",
       "   'subsample': 0.8501708790123297},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.89670664550140122,\n",
       "  'counter': 168,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.43327282091544389,\n",
       "  'loss': 0.43327282091544389,\n",
       "  'params': {'colsample_bylevel': 0.5652340927021713,\n",
       "   'colsample_bytree': 0.9169689346034877,\n",
       "   'gamma': 0.13200036121360093,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 5.226323605647331e-10,\n",
       "   'reg_lambda': 3.715972511549541},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9345836517921885,\n",
       "  'counter': 169,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.42475194127566768,\n",
       "  'loss': 0.42475194127566768,\n",
       "  'params': {'base_score': 0.5626889067209949,\n",
       "   'gamma': 0.9153306256516188,\n",
       "   'learning_rate': 0.14945660230882732,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 1.1817413581805622e-05,\n",
       "   'reg_lambda': 5.986258428016942,\n",
       "   'scale_pos_weight': 3.030365356491723,\n",
       "   'subsample': 0.67640919252912},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83990338448272484,\n",
       "  'counter': 170,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.49005096189222463,\n",
       "  'loss': 0.49005096189222463,\n",
       "  'params': {'base_score': 0.5914101950843241,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9,\n",
       "   'reg_lambda': 6.050879390933382},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9909557685147079,\n",
       "  'counter': 171,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.14862991555874278,\n",
       "  'loss': 0.14862991555874278,\n",
       "  'params': {'learning_rate': 0.15335652010226497, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97224998530189899,\n",
       "  'counter': 172,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.34215852064420588,\n",
       "  'loss': 0.34215852064420588,\n",
       "  'params': {'colsample_bytree': 0.8134474533279035,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 1.5271246683621653e-09,\n",
       "   'reg_lambda': 5.336687149699236,\n",
       "   'scale_pos_weight': 2.2891982415253356,\n",
       "   'subsample': 0.864481753681435},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.83732141807278504,\n",
       "  'counter': 173,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.48001083597296573,\n",
       "  'loss': 0.48001083597296573,\n",
       "  'params': {'colsample_bylevel': 0.8685250476598436,\n",
       "   'colsample_bytree': 0.8658505876800258,\n",
       "   'learning_rate': 0.08960380243301903,\n",
       "   'min_child_weight': 5,\n",
       "   'subsample': 0.521097147373809},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.95891880769004634,\n",
       "  'counter': 174,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.33805784232492508,\n",
       "  'loss': 0.33805784232492508,\n",
       "  'params': {'colsample_bytree': 0.8290652671941507,\n",
       "   'gamma': 0.08892960244038861,\n",
       "   'reg_alpha': 1.8713470021074604e-05},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96284810002547672,\n",
       "  'counter': 175,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.52578010617709547,\n",
       "  'loss': 0.52578010617709547,\n",
       "  'params': {'gamma': 0.12782512174851912,\n",
       "   'learning_rate': 0.01854836904601146,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 6.655989318097287e-06,\n",
       "   'reg_lambda': 6.93967660166143,\n",
       "   'subsample': 0.6751893237765572},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.88513434064318885,\n",
       "  'counter': 176,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.42909759950120385,\n",
       "  'loss': 0.42909759950120385,\n",
       "  'params': {'base_score': 0.24022774010756187,\n",
       "   'colsample_bylevel': 0.7985170612234223,\n",
       "   'gamma': 0.7975302884073436,\n",
       "   'learning_rate': 0.14773532765971728,\n",
       "   'min_child_weight': 7},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.8998373410155408,\n",
       "  'counter': 177,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.42260685799596209,\n",
       "  'loss': 0.42260685799596209,\n",
       "  'params': {'colsample_bytree': 0.9136810918301955,\n",
       "   'gamma': 0.9425765299735885,\n",
       "   'learning_rate': 0.1327946314189776,\n",
       "   'min_child_weight': 4,\n",
       "   'reg_alpha': 0.005138198947974639,\n",
       "   'reg_lambda': 8.681411091587789},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.86093636702138077,\n",
       "  'counter': 178,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.47785106900352126,\n",
       "  'loss': 0.47785106900352126,\n",
       "  'params': {'min_child_weight': 6,\n",
       "   'reg_lambda': 7.767443441874799,\n",
       "   'subsample': 0.7284175594601359},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.89597663981813547,\n",
       "  'counter': 179,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.42833966829282427,\n",
       "  'loss': 0.42833966829282427,\n",
       "  'params': {'colsample_bylevel': 0.7952299475287194,\n",
       "   'reg_alpha': 0.006238366681012634,\n",
       "   'reg_lambda': 5.070613826733956,\n",
       "   'subsample': 0.6750444364662678},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9150351774550729,\n",
       "  'counter': 180,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.41430922825272498,\n",
       "  'loss': 0.41430922825272498,\n",
       "  'params': {'base_score': 0.11982796239914517,\n",
       "   'colsample_bylevel': 0.9006540063208943,\n",
       "   'gamma': 0.7849638119268186,\n",
       "   'reg_lambda': 7.028546565742721},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.80612714837243027,\n",
       "  'counter': 181,\n",
       "  'iterations': 12.0,\n",
       "  'log_loss': 0.51730585569618537,\n",
       "  'loss': 0.51730585569618537,\n",
       "  'params': {'colsample_bytree': 0.8906820525455121,\n",
       "   'gamma': 0.9919965406058522,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7,\n",
       "   'reg_alpha': 2.630971087487771e-06,\n",
       "   'reg_lambda': 7.530742393180813,\n",
       "   'subsample': 0.6428277096768513},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99082838497266157,\n",
       "  'counter': 182,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.12531799005674846,\n",
       "  'loss': 0.12531799005674846,\n",
       "  'params': {'learning_rate': 0.15335652010226497, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99406196719383844,\n",
       "  'counter': 183,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.16558323338112188,\n",
       "  'loss': 0.16558323338112188,\n",
       "  'params': {'base_score': 0.11852393526730474,\n",
       "   'colsample_bylevel': 0.530145500671511,\n",
       "   'colsample_bytree': 0.929166857733412,\n",
       "   'gamma': 0.6477716727429028,\n",
       "   'max_depth': 9,\n",
       "   'subsample': 0.8872303522601266},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98078468261900564,\n",
       "  'counter': 184,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.19249975500103225,\n",
       "  'loss': 0.19249975500103225,\n",
       "  'params': {'colsample_bytree': 0.8290652671941507,\n",
       "   'gamma': 0.08892960244038861,\n",
       "   'reg_alpha': 1.8713470021074604e-05},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98892743057596955,\n",
       "  'counter': 185,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.17514282152056346,\n",
       "  'loss': 0.17514282152056346,\n",
       "  'params': {'colsample_bytree': 0.8134474533279035,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1,\n",
       "   'reg_alpha': 1.5271246683621653e-09,\n",
       "   'reg_lambda': 5.336687149699236,\n",
       "   'scale_pos_weight': 2.2891982415253356,\n",
       "   'subsample': 0.864481753681435},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9878593685695809,\n",
       "  'counter': 186,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.17938096333426443,\n",
       "  'loss': 0.17938096333426443,\n",
       "  'params': {'base_score': 0.6702028305852819,\n",
       "   'colsample_bytree': 0.5607136974662824,\n",
       "   'max_depth': 10,\n",
       "   'reg_alpha': 0.008456071957485347,\n",
       "   'scale_pos_weight': 7.666934420401439,\n",
       "   'subsample': 0.8501708790123297},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9898779077743155,\n",
       "  'counter': 187,\n",
       "  'iterations': 300.0,\n",
       "  'log_loss': 0.12348258934360981,\n",
       "  'loss': 0.12348258934360981,\n",
       "  'params': {'learning_rate': 0.15335652010226497, 'max_depth': 8},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.96354870950673166,\n",
       "  'counter': 188,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.35041076800120474,\n",
       "  'loss': 0.35041076800120474,\n",
       "  'params': {'gamma': 0.1672409274246931,\n",
       "   'learning_rate': 0.1998004202276331,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 8,\n",
       "   'reg_alpha': 2.6871782403698335e-08,\n",
       "   'reg_lambda': 8.134726945825824,\n",
       "   'scale_pos_weight': 9.617390303345312,\n",
       "   'subsample': 0.989060471819201},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99478707351010243,\n",
       "  'counter': 189,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.15701062998081378,\n",
       "  'loss': 0.15701062998081378,\n",
       "  'params': {'base_score': 0.2622785478264037,\n",
       "   'colsample_bylevel': 0.5723854035794861,\n",
       "   'gamma': 0.5707814070650199,\n",
       "   'max_depth': 5,\n",
       "   'reg_alpha': 3.473066893127951e-08},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9165833774276364,\n",
       "  'counter': 190,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.3836520186302026,\n",
       "  'loss': 0.3836520186302026,\n",
       "  'params': {'colsample_bylevel': 0.7105963701971251,\n",
       "   'learning_rate': 0.02369969734410336,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5,\n",
       "   'reg_alpha': 9.588529504223723e-08},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.95931565641719085,\n",
       "  'counter': 191,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.29889618852953032,\n",
       "  'loss': 0.29889618852953032,\n",
       "  'params': {'colsample_bytree': 0.5769801908689118,\n",
       "   'gamma': 0.9915415840981632,\n",
       "   'learning_rate': 0.0679099561797972,\n",
       "   'subsample': 0.7609496593756414},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97617927763732926,\n",
       "  'counter': 192,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.22673236390512613,\n",
       "  'loss': 0.22673236390512613,\n",
       "  'params': {'colsample_bylevel': 0.6935037277917734,\n",
       "   'colsample_bytree': 0.9039406339257143,\n",
       "   'gamma': 0.15711472557780504,\n",
       "   'min_child_weight': 2,\n",
       "   'reg_lambda': 1.9811048567132132},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98615438885296025,\n",
       "  'counter': 193,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.24605863915095155,\n",
       "  'loss': 0.24605863915095155,\n",
       "  'params': {'colsample_bylevel': 0.787931705122771,\n",
       "   'gamma': 0.7893815117146127,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 2,\n",
       "   'scale_pos_weight': 6.15629582668053},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97832520038411042,\n",
       "  'counter': 194,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.19627315947281884,\n",
       "  'loss': 0.19627315947281884,\n",
       "  'params': {'learning_rate': 0.10481110639846845,\n",
       "   'subsample': 0.6924676535522483},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99199443431908596,\n",
       "  'counter': 195,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.19333921560473552,\n",
       "  'loss': 0.19333921560473552,\n",
       "  'params': {'base_score': 0.5829702386569648,\n",
       "   'colsample_bylevel': 0.79371092106521,\n",
       "   'colsample_bytree': 0.7693604022659268,\n",
       "   'gamma': 0.9273746988082666,\n",
       "   'max_depth': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.97747271052579998,\n",
       "  'counter': 196,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.23208826913982133,\n",
       "  'loss': 0.23208826913982133,\n",
       "  'params': {'gamma': 0.7268555419573427,\n",
       "   'reg_alpha': 0.029611289821749345,\n",
       "   'reg_lambda': 1.5372515017022506,\n",
       "   'scale_pos_weight': 2.978947824685109,\n",
       "   'subsample': 0.5995930141216638},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.9841848433182433,\n",
       "  'counter': 197,\n",
       "  'iterations': 60.0,\n",
       "  'log_loss': 0.24656580472882036,\n",
       "  'loss': 0.24656580472882036,\n",
       "  'params': {'base_score': 0.2808468229022125,\n",
       "   'colsample_bylevel': 0.8952822978878101,\n",
       "   'gamma': 0.8580557652825153,\n",
       "   'learning_rate': 0.13180194306682474},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99532600388029868,\n",
       "  'counter': 198,\n",
       "  'iterations': 300.0,\n",
       "  'log_loss': 0.14651853822646371,\n",
       "  'loss': 0.14651853822646371,\n",
       "  'params': {'base_score': 0.2622785478264037,\n",
       "   'colsample_bylevel': 0.5723854035794861,\n",
       "   'gamma': 0.5707814070650199,\n",
       "   'max_depth': 5,\n",
       "   'reg_alpha': 3.473066893127951e-08},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99348384188762806,\n",
       "  'counter': 199,\n",
       "  'iterations': 300.0,\n",
       "  'log_loss': 0.17346174365961606,\n",
       "  'loss': 0.17346174365961606,\n",
       "  'params': {'base_score': 0.5829702386569648,\n",
       "   'colsample_bylevel': 0.79371092106521,\n",
       "   'colsample_bytree': 0.7693604022659268,\n",
       "   'gamma': 0.9273746988082666,\n",
       "   'max_depth': 6},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.95321104513296884,\n",
       "  'counter': 200,\n",
       "  'iterations': 300,\n",
       "  'log_loss': 0.29262195904989252,\n",
       "  'loss': 0.29262195904989252,\n",
       "  'params': {'base_score': 0.6604575597559378,\n",
       "   'gamma': 0.7504880726950054,\n",
       "   'learning_rate': 0.1908412217524448,\n",
       "   'min_child_weight': 8,\n",
       "   'scale_pos_weight': 4.671215133500526,\n",
       "   'subsample': 0.8340028505968635},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.99057361788856868,\n",
       "  'counter': 201,\n",
       "  'iterations': 300,\n",
       "  'log_loss': 0.13086703138528158,\n",
       "  'loss': 0.13086703138528158,\n",
       "  'params': {'colsample_bytree': 0.7169519865507579,\n",
       "   'learning_rate': 0.056935810373963607,\n",
       "   'max_depth': 5,\n",
       "   'reg_lambda': 4.5769253162297385,\n",
       "   'scale_pos_weight': 2.484813981179239},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98911360652203739,\n",
       "  'counter': 202,\n",
       "  'iterations': 300,\n",
       "  'log_loss': 0.24222459974570335,\n",
       "  'loss': 0.24222459974570335,\n",
       "  'params': {'gamma': 0.6085776715570734,\n",
       "   'reg_alpha': 6.850400011374169e-07,\n",
       "   'scale_pos_weight': 5.854135405047377},\n",
       "  'seconds': 0},\n",
       " {'auc': 0.98395947243616122,\n",
       "  'counter': 203,\n",
       "  'iterations': 300,\n",
       "  'log_loss': 0.19190333269179757,\n",
       "  'loss': 0.19190333269179757,\n",
       "  'params': {'base_score': 0.894309363179177,\n",
       "   'colsample_bytree': 0.6523281334932186,\n",
       "   'learning_rate': 0.06432262547324338,\n",
       "   'max_depth': 7,\n",
       "   'reg_lambda': 7.4701930920912325,\n",
       "   'scale_pos_weight': 5.632727957829525,\n",
       "   'subsample': 0.7469747901053001},\n",
       "  'seconds': 0}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
